{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98e9a423",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#more description: https://github.com/dakshmittal30/Uncertainty-Quantification/blob/main/gen_selection_bias_datasets.ipynb\n",
    "import numpy as np\n",
    "from csv import writer\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "\n",
    "directory = '/shared/share_mala/yuanzhe/adaptive_sampling/pipeline_datasets/'\n",
    "\n",
    "\n",
    "def get_feat_importance(model, X_col): # get most important features, input is a randomforest classifier/regressor \n",
    "    importances = model.feature_importances_\n",
    "    forest_importances = pd.Series(importances, index = X_col)\n",
    "    forest_importances = forest_importances.nlargest(10)  #only keep most important 10 feature\n",
    "    feature_importances = list(forest_importances.index) \n",
    "    return feature_importances #return the columns\n",
    "\n",
    "\n",
    "def generate_prop_score(coeff, X_data, k):\n",
    "    prop_score = X_data @ coeff  #X_data dim = (n*N), coeff dim = (N*1)\n",
    "    prop_score = np.array([x - np.mean(prop_score) for x in prop_score]) #normalize the prop score\n",
    "    temp = [-k + 2*k * np.mean(prop_score <= x) for x in prop_score]\n",
    "    prop_score = [np.exp(x)/(1+np.exp(x)) for x in temp]\n",
    "\n",
    "    return prop_score\n",
    "\n",
    "\n",
    "\n",
    "def generate_selection_bias_random(data, data_name, X_col, seed,k, coeff = [],extra_text=''):\n",
    "    '''\n",
    "    data index has to be removed: i.e., 0,1,2,3,..\n",
    "    input: data (dataframe, contains X + Y), X_col list [assume only make prop score based on a selected X_col],  seed and data_name (data_key)\n",
    "    if want to include intercept term in the logistic model, simply add a constant in the data with X_col adding 'constant'\n",
    "    '''\n",
    "    np.random.seed(seed)\n",
    "\n",
    "\n",
    "\n",
    "    # filter out features with low variability\n",
    "    X_col_new = [] #only keep features that are not too concentrated\n",
    "    for i in X_col:\n",
    "        if np.std(data[i]) >= 0.001:\n",
    "            X_col_new.append(i)\n",
    "\n",
    "    X_col = X_col_new.copy()\n",
    "\n",
    "    # standardizes selected features in the input data\n",
    "    X_data = data[X_col]\n",
    "    X_data = stats.zscore(X_data)\n",
    "\n",
    "    N = len(X_col) #dim of X, which is the dim of prop score coeff\n",
    "\n",
    "    # generate random coefficients if coeff is empty\n",
    "    if coeff == []: #if coeff empty, we will generate one\n",
    "        coeff = np.random.uniform(-1,1,N) #random coeff, it is now Uni[-1,1] but we can try fancier version later\n",
    "\n",
    "    # generating propensity scores for each data\n",
    "    prop_score = generate_prop_score(coeff, X_data, k )\n",
    "\n",
    "    # converting propensity scores to binary values using binomial distribution\n",
    "    if_sampled = np.array([np.random.binomial(size=1, n=1, p= q )[0] for q in prop_score]) #transform prop score to a Bernoulli rv\n",
    "\n",
    "    # selects rows where binary values are non-zero, introducing selection bias\n",
    "    selected_row = list(np.nonzero(if_sampled)[0]) #the index of selected rows, will only keep these rows\n",
    "\n",
    "    # saving 2 csv files: one with selected rows and one with non-selected rows\n",
    "    df = data[data.index.isin(selected_row)]\n",
    "    df.to_csv(f\"{directory}/biased_new/{data_name}_random_prop_score_selected_{str(seed)}_{str(k)}_{extra_text}_.csv\", index=False)\n",
    "    #save dataframe\n",
    "\n",
    "    df_not = data[~data.index.isin(selected_row)]\n",
    "    df_not.to_csv(f\"{directory}/biased_new/{data_name}_random_prop_score_not_selected_{str(seed)}_{str(k)}_{extra_text}_.csv\", index=False)\n",
    "\n",
    "    #the following records our random prop score coeff\n",
    "    with open(directory + 'summaries/summary_selection_bias.csv', 'a') as f_object:\n",
    "        writer_object = writer(f_object)\n",
    "        row = ['seed',seed,'data_name',data_name,'seed',seed,'X_col',X_col,'random_coeff',coeff,'k',k,'before_shape',data.shape,'after_shape',df.shape]\n",
    "        writer_object.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92fbf6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv = 'input_dim_1_train_init_data_mean_0.0ln_1.0sig_0.1no.2000.csv'\n",
    "data_name = 'input_dim_1_train_init_data_mean_0.0ln_1.0sig_0.1no.2000'\n",
    "df = pd.read_csv(directory + train_csv)\n",
    "X_col = ['Column0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fe42ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    " for k_val in [0.05,0.25,0.5,1.0,2.0,4.0,8.0,16.0]:\n",
    "    generate_selection_bias_random(data = df, data_name = data_name, X_col = X_col, seed = 2,k = k_val, coeff = [],extra_text='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22606ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.09563386725780001\n",
      "-0.9236370532151394\n",
      "-0.0058072998057590005\n",
      "-0.00718789758756773\n"
     ]
    }
   ],
   "source": [
    "df_2 = pd.read_csv(directory + '/biased_new/input_dim_1_train_init_data_mean_0.0ln_1.0sig_0.1no.2000_random_prop_score_selected_2_16.0__.csv')\n",
    "df_2\n",
    "print(np.mean(df['Column0']))\n",
    "print(np.mean(df_2['Column0']))\n",
    "print(np.mean(df['EVENT_LABEL']))\n",
    "print(np.mean(df_2['EVENT_LABEL']))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yuanzhe_new",
   "language": "python",
   "name": "yuanzhe_new"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
