{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4cff566a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-27 13:01:35.537929: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/opt/gurobi/linux64/lib:/opt/gurobi/linux64/lib\n"
     ]
    }
   ],
   "source": [
    "#run below code twice\n",
    "import neural_testbed\n",
    "from neural_testbed.agents import factories as agent_factories\n",
    "from neural_testbed.agents.factories.sweeps import testbed_2d as agent_sweeps\n",
    "from neural_testbed import base\n",
    "from neural_testbed import generative\n",
    "from neural_testbed import leaderboard\n",
    "from typing import Callable, NamedTuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotnine as gg\n",
    "import torch\n",
    "# from acme.utils.loggers.terminal import TerminalLogger\n",
    "import dataclasses\n",
    "import chex\n",
    "import haiku as hk\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import optax\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df57f345",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = '/shared/share_mala/yuanzhe/adaptive_sampling/pipeline_datasets/'\n",
    "train_csv_name = url + 'classifier_input_dim_1_train_init_data_mean_0.0ln_1.0sig_0.1no.2000.csv'\n",
    "test_csv_name = url + 'classifier_input_dim_1_test_final_data_mean_0.0ln_1.0sig_0.1no.2000.csv'\n",
    "pool_csv_name = url + 'classifier_input_dim_1_pool_data_mean_0.0ln_1.0sig_0.1no.2000.csv'\n",
    "\n",
    "dataset_cfg = pipeline.DatasetConfig(train_csv_name, test_csv_name, pool_csv_name, \"EVENT_LABEL\")\n",
    "model_cfg = pipeline.ModelConfig(batch_size_train = 64, batch_size_test = 64, batch_size_query = 100, temp_k_subset = 0.1, hidden_sizes_weight_NN = [50,50], meta_opt_lr = 0.001, n_classes = 2, n_epoch = 10, init_train_lr = 0.001, init_train_weight_decay = 0.1, n_train_init = 20)\n",
    "train_cfg = pipeline.TrainConfig(n_train_iter = 15, n_ENN_iter = 15, ENN_opt_lr = 0.001)\n",
    "enn_cfg = pipeline.ENNConfig(basenet_hidden_sizes = [50,50],  exposed_layers = [False, True], z_dim = 8, learnable_epinet_hiddens = [15,15], hidden_sizes_prior = [5,5], seed_base = 2, seed_learnable_epinet = 1, seed_prior_epinet = 0, alpha = 0.1)\n",
    " \n",
    "\n",
    "model_predictor = torch.jit.load(url + 'predictor.pt')\n",
    "model_predictor.eval()\n",
    "\n",
    "# Example usage\n",
    "#pipeline.\n",
    "pipeline.experiment(dataset_cfg, model_cfg, train_cfg, enn_cfg, model_predictor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yuanzhe_new",
   "language": "python",
   "name": "yuanzhe_new"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
