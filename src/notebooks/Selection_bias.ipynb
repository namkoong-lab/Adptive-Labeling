{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "98e9a423",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#more description: https://github.com/dakshmittal30/Uncertainty-Quantification/blob/main/gen_selection_bias_datasets.ipynb\n",
    "import numpy as np\n",
    "from csv import writer\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "\n",
    "directory = '/shared/share_mala/yuanzhe/adaptive_sampling/pipeline_datasets/'\n",
    "\n",
    "\n",
    "def get_feat_importance(model, X_col): # get most important features, input is a randomforest classifier/regressor \n",
    "    importances = model.feature_importances_\n",
    "    forest_importances = pd.Series(importances, index = X_col)\n",
    "    forest_importances = forest_importances.nlargest(10)  #only keep most important 10 feature\n",
    "    feature_importances = list(forest_importances.index) \n",
    "    return feature_importances #return the columns\n",
    "\n",
    "\n",
    "def generate_prop_score(coeff, X_data, k):\n",
    "    prop_score = X_data @ coeff  #X_data dim = (n*N), coeff dim = (N*1)\n",
    "    prop_score = np.array([x - np.mean(prop_score) for x in prop_score]) #normalize the prop score\n",
    "    temp = [-k + 2*k * np.mean(prop_score <= x) for x in prop_score]\n",
    "    prop_score = [np.exp(x)/(1+np.exp(x)) for x in temp]\n",
    "\n",
    "    return prop_score\n",
    "\n",
    "\n",
    "\n",
    "def generate_selection_bias_random(data, data_name, X_col, seed,k, coeff = [],extra_text=''):\n",
    "    '''\n",
    "    data index has to be removed: i.e., 0,1,2,3,..\n",
    "    input: data (dataframe, contains X + Y), X_col list [assume only make prop score based on a selected X_col],  seed and data_name (data_key)\n",
    "    if want to include intercept term in the logistic model, simply add a constant in the data with X_col adding 'constant'\n",
    "    '''\n",
    "    np.random.seed(seed)\n",
    "\n",
    "\n",
    "\n",
    "    # filter out features with low variability\n",
    "    X_col_new = [] #only keep features that are not too concentrated\n",
    "    for i in X_col:\n",
    "        if np.std(data[i]) >= 0.001:\n",
    "            X_col_new.append(i)\n",
    "\n",
    "    X_col = X_col_new.copy()\n",
    "\n",
    "    # standardizes selected features in the input data\n",
    "    X_data = data[X_col]\n",
    "    X_data = stats.zscore(X_data)\n",
    "\n",
    "    N = len(X_col) #dim of X, which is the dim of prop score coeff\n",
    "\n",
    "    # generate random coefficients if coeff is empty\n",
    "    if coeff == []: #if coeff empty, we will generate one\n",
    "        coeff = np.random.uniform(-1,1,N) #random coeff, it is now Uni[-1,1] but we can try fancier version later\n",
    "\n",
    "    # generating propensity scores for each data\n",
    "    prop_score = generate_prop_score(coeff, X_data, k )\n",
    "\n",
    "    # converting propensity scores to binary values using binomial distribution\n",
    "    if_sampled = np.array([np.random.binomial(size=1, n=1, p= q )[0] for q in prop_score]) #transform prop score to a Bernoulli rv\n",
    "\n",
    "    # selects rows where binary values are non-zero, introducing selection bias\n",
    "    selected_row = list(np.nonzero(if_sampled)[0]) #the index of selected rows, will only keep these rows\n",
    "\n",
    "    # saving 2 csv files: one with selected rows and one with non-selected rows\n",
    "    df = data[data.index.isin(selected_row)]\n",
    "    df.to_csv(f\"{directory}/biased_new/{data_name}_random_prop_score_selected_{str(seed)}_{str(k)}_{extra_text}_.csv\", index=False)\n",
    "    #save dataframe\n",
    "\n",
    "    df_not = data[~data.index.isin(selected_row)]\n",
    "    df_not.to_csv(f\"{directory}/biased_new/{data_name}_random_prop_score_not_selected_{str(seed)}_{str(k)}_{extra_text}_.csv\", index=False)\n",
    "\n",
    "    #the following records our random prop score coeff\n",
    "    with open(directory + 'summaries/summary_selection_bias.csv', 'a') as f_object:\n",
    "        writer_object = writer(f_object)\n",
    "        row = ['seed',seed,'data_name',data_name,'seed',seed,'X_col',X_col,'random_coeff',coeff,'k',k,'before_shape',data.shape,'after_shape',df.shape]\n",
    "        writer_object.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4a963e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv = 'classifier_input_dim_1_train_init_data_mean_0.0ln_1.0sig_0.1no.2000.csv'\n",
    "data_name = 'classifier_input_dim_1_train_init_data_mean_0.0ln_1.0sig_0.1no.2000'\n",
    "df = pd.read_csv(directory + train_csv)\n",
    "X_col = ['Column0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9fe42ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    " for k_val in [0.05,0.25,0.5,1.0,2.0,4.0,8.0,16.0]:\n",
    "    generate_selection_bias_random(data = df, data_name = data_name, X_col = X_col, seed = 2,k = k_val, coeff = [],extra_text='')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "54a3e7b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column0</th>\n",
       "      <th>EVENT_LABEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.967892</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.060382</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.248875</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.494540</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.768679</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>-0.705735</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>-1.335675</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>-1.873685</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>-2.839641</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>-0.171974</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>260 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Column0  EVENT_LABEL\n",
       "0   -0.967892        False\n",
       "1   -2.060382        False\n",
       "2   -0.248875        False\n",
       "3   -0.494540        False\n",
       "4   -0.768679         True\n",
       "..        ...          ...\n",
       "255 -0.705735        False\n",
       "256 -1.335675         True\n",
       "257 -1.873685         True\n",
       "258 -2.839641         True\n",
       "259 -0.171974        False\n",
       "\n",
       "[260 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2 = pd.read_csv(directory + '/biased_new/classifier_input_dim_1_train_init_data_mean_0.0ln_1.0sig_0.1no.2000_random_prop_score_selected_2_8.0__.csv')\n",
    "df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c27277d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.09563386725780001\n",
      "-0.8729415065846154\n",
      "0.406\n",
      "0.38461538461538464\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(df['Column0']))\n",
    "print(np.mean(df_2['Column0']))\n",
    "print(np.mean(df['EVENT_LABEL']))\n",
    "print(np.mean(df_2['EVENT_LABEL']))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yuanzhe_new",
   "language": "python",
   "name": "yuanzhe_new"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
