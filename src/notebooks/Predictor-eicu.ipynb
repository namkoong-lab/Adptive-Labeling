{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d052b3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Define the model class\n",
    "class LinearRegressor(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(LinearRegressor, self).__init__()\n",
    "        self.linear = nn.Linear(input_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "class LogisticRegression(torch.nn.Module):    \n",
    "    # build the constructor\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential( \n",
    "#           nn.Linear(input_size, input_size),\n",
    "#           nn.ReLU(),\n",
    "#           nn.Linear(input_size, input_size),\n",
    "#           nn.ReLU(),\n",
    "          nn.Linear(input_size, output_size),\n",
    "          nn.ReLU()\n",
    "        )\n",
    "    # make predictions\n",
    "    def forward(self, x):\n",
    "        y_pred = torch.sigmoid(self.net(x))\n",
    "        \n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e93bef7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 61.822731018066406\n",
      "Epoch 10, Loss: 0.6931473612785339\n",
      "Epoch 20, Loss: 0.6931473612785339\n",
      "Epoch 30, Loss: 0.6931473612785339\n",
      "Epoch 40, Loss: 0.6931473612785339\n",
      "Epoch 50, Loss: 0.6931473612785339\n",
      "Epoch 60, Loss: 0.6931473612785339\n",
      "Epoch 70, Loss: 0.6931473612785339\n",
      "Epoch 80, Loss: 0.6931473612785339\n",
      "Epoch 90, Loss: 0.6931473612785339\n"
     ]
    }
   ],
   "source": [
    "# Example Data (Replace with your actual data)\n",
    "# X_train: tensor of shape [n_samples, n_features]\n",
    "# y_train: tensor of shape [n_samples, 1]\n",
    "#data generated from below\n",
    "#https://drive.google.com/drive/folders/1z726l_xZuSZAAPpUSljA5YM-NlcDSR8S\n",
    "#https://drive.google.com/drive/folders/1mC8UQJmgOXAD0eMCV8H0ZJBmc57KhYIp\n",
    "\n",
    "directory = '/shared/share_mala/yuanzhe/adaptive_sampling/eicu/eicu_simple_bias/important_features/'\n",
    "#below is biased training data\n",
    "csv_file =  'eicu_random_prop_score_selected2_16.0_only_important_feature_simple.csv'\n",
    "df = pd.read_csv(directory + csv_file)\n",
    "X_col = list(df.columns)\n",
    "X_col.remove('EVENT_LABEL')\n",
    "\n",
    "X_train = np.array(df[X_col])\n",
    "y_train = np.array(df[['EVENT_LABEL']])  \n",
    "\n",
    "# Convert data to PyTorch tensors if they aren't already\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "\n",
    "# Hyperparameters\n",
    "epochs = 100  # Number of training iterations\n",
    "learning_rate = 0.01\n",
    "\n",
    "# Model, Loss and Optimizer\n",
    "model = LogisticRegression(input_size=X_train.shape[1], output_size=1)\n",
    "criterion = nn.MSELoss()\n",
    "criterion = torch.nn.BCELoss()\n",
    "#optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate, betas=(0.9, 0.999))\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    # Forward pass: Compute predicted y by passing X to the model\n",
    "    y_pred = model(X_train)\n",
    "\n",
    "    # Compute and print loss\n",
    "    loss = criterion(y_pred, y_train)\n",
    "    if epoch % 10 == 0:  # Print every 10th epoch\n",
    "        print(f'Epoch {epoch}, Loss: {loss.item()}')\n",
    "\n",
    "    # Zero gradients, perform a backward pass, and update the weights.\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "#torch.save(model, url + 'predictor.pkl')\n",
    "\n",
    "model_scripted = torch.jit.script(model) # Export to TorchScript\n",
    "model_scripted.save(directory + 'predictor_eicu_0206.pt') # Save\n",
    "\n",
    "#https://stackoverflow.com/questions/55488795/unpickling-saved-pytorch-model-throws-attributeerror-cant-get-attribute-net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "adb03743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        ...,\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000]], grad_fn=<SigmoidBackward0>)\n",
      "Recall on training data tensor(1.)\n",
      "Recall on test data tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def Recall_True(x_test, y_test, model, device): #input is dataloader_test and classifier/ model c, output is true recall given labels\n",
    " \n",
    "    prediction_list = model(x_test)\n",
    "    predicted_class = torch.argmax(prediction_list)\n",
    "    predicted_class = prediction_list >= 0.5 #may need to use the previous code if model predicts probs of two classes\n",
    "\n",
    "    x = torch.sum(torch.mul(y_test, predicted_class))\n",
    "    y = torch.sum(y_test)\n",
    "    return x/y\n",
    "\n",
    "test_csv_name = '/shared/share_mala/yuanzhe/adaptive_sampling/eicu/EICU_train_test/eicu_test_final.csv'\n",
    "df_test = pd.read_csv(test_csv_name)\n",
    "X_test = np.array(df_test[X_col])\n",
    "y_test = np.array(df_test[['EVENT_LABEL']]) \n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "print(model(X_test))\n",
    "print('Recall on training data', Recall_True(X_train,y_train,model,device))\n",
    "print('Recall on test data', Recall_True(X_test,y_test,model,device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2374173a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert reg to classification, no need to run again\n",
    "# url = '/shared/share_mala/yuanzhe/adaptive_sampling/pipeline_datasets/'\n",
    "# train_csv_name = 'input_dim_1_train_init_data_mean_0.0ln_1.0sig_0.1no.2000.csv'\n",
    "# test_csv_name = 'input_dim_1_test_final_data_mean_0.0ln_1.0sig_0.1no.2000.csv'\n",
    "# pool_csv_name = 'input_dim_1_pool_data_mean_0.0ln_1.0sig_0.1no.2000.csv'\n",
    "# file_list  = [train_csv_name, test_csv_name, pool_csv_name]\n",
    "# #convert y into 0/1\n",
    "\n",
    "# for f in file_list:\n",
    "#     df = pd.read_csv(url + f)\n",
    "#     df['EVENT_LABEL'] = df['EVENT_LABEL'] > 0\n",
    "#     df.to_csv(url+'classifier_'+ f, index = False)\n",
    "# #/user/ym2865/Adaptive Sampling/src"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yuanzhe_new",
   "language": "python",
   "name": "yuanzhe_new"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
