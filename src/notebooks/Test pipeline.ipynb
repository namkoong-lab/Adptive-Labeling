{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cff566a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run below code twice\n",
    "from line_profiler import LineProfiler\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotnine as gg\n",
    "import torch\n",
    "# from acme.utils.loggers.terminal import TerminalLogger\n",
    "import dataclasses\n",
    "import chex\n",
    "import haiku as hk\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import optax\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df57f345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data count (251, 2)\n",
      "ENN_init_loss: tensor(0.7113, grad_fn=<NllLossBackward0>)\n",
      "ENN_init_loss: tensor(1.1608, grad_fn=<NllLossBackward0>)\n",
      "ENN_init_loss: tensor(1.0522, grad_fn=<NllLossBackward0>)\n",
      "ENN_init_loss: tensor(0.7585, grad_fn=<NllLossBackward0>)\n",
      "ENN_init_loss: tensor(0.7324, grad_fn=<NllLossBackward0>)\n",
      "ENN_init_loss: tensor(1.0684, grad_fn=<NllLossBackward0>)\n",
      "ENN_init_loss: tensor(0.8300, grad_fn=<NllLossBackward0>)\n",
      "ENN_init_loss: tensor(0.6578, grad_fn=<NllLossBackward0>)\n",
      "ENN_init_loss: tensor(0.6571, grad_fn=<NllLossBackward0>)\n",
      "ENN_init_loss: tensor(0.7081, grad_fn=<NllLossBackward0>)\n",
      "ENN_init_loss: tensor(0.8169, grad_fn=<NllLossBackward0>)\n",
      "ENN_init_loss: tensor(0.6960, grad_fn=<NllLossBackward0>)\n",
      "ENN_init_loss: tensor(1.3390, grad_fn=<NllLossBackward0>)\n",
      "ENN_init_loss: tensor(2.1654, grad_fn=<NllLossBackward0>)\n",
      "ENN_init_loss: tensor(0.8393, grad_fn=<NllLossBackward0>)\n",
      "ENN_init_loss: tensor(0.9923, grad_fn=<NllLossBackward0>)\n",
      "ENN_init_loss: tensor(0.6602, grad_fn=<NllLossBackward0>)\n",
      "ENN_init_loss: tensor(1.2507, grad_fn=<NllLossBackward0>)\n",
      "ENN_init_loss: tensor(0.9291, grad_fn=<NllLossBackward0>)\n",
      "ENN_init_loss: tensor(0.7050, grad_fn=<NllLossBackward0>)\n",
      "ENN_init_loss: tensor(0.6580, grad_fn=<NllLossBackward0>)\n",
      "ENN_init_loss: tensor(0.7245, grad_fn=<NllLossBackward0>)\n",
      "ENN_init_loss: tensor(0.7109, grad_fn=<NllLossBackward0>)\n",
      "ENN_init_loss: tensor(0.8189, grad_fn=<NllLossBackward0>)\n",
      "ENN_init_loss: tensor(0.6618, grad_fn=<NllLossBackward0>)\n",
      "ENN_init_loss: tensor(0.6751, grad_fn=<NllLossBackward0>)\n",
      "ENN_init_loss: tensor(0.7611, grad_fn=<NllLossBackward0>)\n",
      "ENN_init_loss: tensor(0.7073, grad_fn=<NllLossBackward0>)\n",
      "ENN_init_loss: tensor(0.6603, grad_fn=<NllLossBackward0>)\n",
      "ENN_init_loss: tensor(0.6729, grad_fn=<NllLossBackward0>)\n",
      "ENN_init_loss: tensor(0.6895, grad_fn=<NllLossBackward0>)\n",
      "ENN_init_loss: tensor(0.8302, grad_fn=<NllLossBackward0>)\n",
      "ENN_init_loss: tensor(0.6583, grad_fn=<NllLossBackward0>)\n",
      "ENN_init_loss: tensor(0.7337, grad_fn=<NllLossBackward0>)\n",
      "ENN_init_loss: tensor(0.6548, grad_fn=<NllLossBackward0>)\n",
      "ENN_init_loss: tensor(0.6585, grad_fn=<NllLossBackward0>)\n",
      "ENN_init_loss: tensor(0.6595, grad_fn=<NllLossBackward0>)\n",
      "ENN_init_loss: tensor(0.6801, grad_fn=<NllLossBackward0>)\n",
      "ENN_init_loss: tensor(0.6724, grad_fn=<NllLossBackward0>)\n",
      "ENN_init_loss: tensor(0.6557, grad_fn=<NllLossBackward0>)\n",
      "ENN_init_loss: tensor(0.6590, grad_fn=<NllLossBackward0>)\n",
      "ENN_init_loss: tensor(0.6575, grad_fn=<NllLossBackward0>)\n",
      "ENN_init_loss: tensor(0.6575, grad_fn=<NllLossBackward0>)\n",
      "ENN_init_loss: tensor(0.6726, grad_fn=<NllLossBackward0>)\n",
      "ENN_init_loss: tensor(0.6703, grad_fn=<NllLossBackward0>)\n",
      "ENN_init_loss: tensor(0.9324, grad_fn=<NllLossBackward0>)\n",
      "ENN_init_loss: tensor(0.6553, grad_fn=<NllLossBackward0>)\n",
      "ENN_init_loss: tensor(0.6556, grad_fn=<NllLossBackward0>)\n",
      "ENN_init_loss: tensor(0.6716, grad_fn=<NllLossBackward0>)\n",
      "ENN_init_loss: tensor(0.6620, grad_fn=<NllLossBackward0>)\n",
      "ENN_init_loss: tensor(0.6553, grad_fn=<NllLossBackward0>)\n",
      "ENN_init_loss: tensor(0.6702, grad_fn=<NllLossBackward0>)\n",
      "ENN_init_loss: tensor(0.6626, grad_fn=<NllLossBackward0>)\n",
      "ENN_init_loss: tensor(0.6920, grad_fn=<NllLossBackward0>)\n",
      "ENN_init_loss: tensor(0.6683, grad_fn=<NllLossBackward0>)\n",
      "ENN_init_loss: tensor(0.8131, grad_fn=<NllLossBackward0>)\n",
      "ENN_init_loss: tensor(0.6817, grad_fn=<NllLossBackward0>)\n",
      "ENN_init_loss: tensor(0.6656, grad_fn=<NllLossBackward0>)\n",
      "ENN_init_loss: tensor(0.6618, grad_fn=<NllLossBackward0>)\n",
      "ENN_init_loss: tensor(0.6928, grad_fn=<NllLossBackward0>)\n",
      "ENN_init_loss: tensor(0.6556, grad_fn=<NllLossBackward0>)\n",
      "ENN_init_loss: tensor(0.6549, grad_fn=<NllLossBackward0>)\n",
      "ENN_init_loss: tensor(0.6561, grad_fn=<NllLossBackward0>)\n",
      "ENN_init_loss: tensor(0.7328, grad_fn=<NllLossBackward0>)\n",
      "ENN_init_loss: tensor(0.6604, grad_fn=<NllLossBackward0>)\n",
      "ENN_init_loss: tensor(0.6738, grad_fn=<NllLossBackward0>)\n",
      "ENN_init_loss: tensor(0.7333, grad_fn=<NllLossBackward0>)\n",
      "ENN_init_loss: tensor(0.7611, grad_fn=<NllLossBackward0>)\n",
      "ENN_init_loss: tensor(0.6576, grad_fn=<NllLossBackward0>)\n",
      "ENN_init_loss: tensor(0.6613, grad_fn=<NllLossBackward0>)\n",
      "ENN_init_loss: tensor(0.6658, grad_fn=<NllLossBackward0>)\n",
      "ENN_init_loss: tensor(0.6736, grad_fn=<NllLossBackward0>)\n",
      "ENN_init_loss: tensor(0.6866, grad_fn=<NllLossBackward0>)\n",
      "ENN_init_loss: tensor(0.6778, grad_fn=<NllLossBackward0>)\n",
      "ENN_init_loss: tensor(0.6617, grad_fn=<NllLossBackward0>)\n",
      "ENN_init_loss: tensor(0.6578, grad_fn=<NllLossBackward0>)\n",
      "ENN_init_loss: tensor(0.6557, grad_fn=<NllLossBackward0>)\n",
      "ENN_init_loss: tensor(0.6648, grad_fn=<NllLossBackward0>)\n",
      "ENN_init_loss: tensor(0.6619, grad_fn=<NllLossBackward0>)\n",
      "ENN_init_loss: tensor(0.6568, grad_fn=<NllLossBackward0>)\n",
      "ENN_init_loss: tensor(0.6668, grad_fn=<NllLossBackward0>)\n",
      "ENN_init_loss: tensor(0.7121, grad_fn=<NllLossBackward0>)\n",
      "ENN_init_loss: tensor(0.6602, grad_fn=<NllLossBackward0>)\n",
      "ENN_init_loss: tensor(0.6595, grad_fn=<NllLossBackward0>)\n",
      "ENN_init_loss: tensor(0.6553, grad_fn=<NllLossBackward0>)\n",
      "ENN_init_loss: tensor(0.6553, grad_fn=<NllLossBackward0>)\n",
      "ENN_init_loss: tensor(0.6637, grad_fn=<NllLossBackward0>)\n",
      "ENN_init_loss: tensor(0.6750, grad_fn=<NllLossBackward0>)\n",
      "ENN_init_loss: tensor(0.6576, grad_fn=<NllLossBackward0>)\n",
      "ENN_init_loss: tensor(0.6589, grad_fn=<NllLossBackward0>)\n",
      "ENN_init_loss: tensor(0.6575, grad_fn=<NllLossBackward0>)\n",
      "ENN_init_loss: tensor(0.6627, grad_fn=<NllLossBackward0>)\n",
      "ENN_init_loss: tensor(0.6562, grad_fn=<NllLossBackward0>)\n",
      "ENN_init_loss: tensor(0.6668, grad_fn=<NllLossBackward0>)\n",
      "ENN_init_loss: tensor(0.6627, grad_fn=<NllLossBackward0>)\n",
      "ENN_init_loss: tensor(0.6892, grad_fn=<NllLossBackward0>)\n",
      "ENN_init_loss: tensor(0.6565, grad_fn=<NllLossBackward0>)\n",
      "ENN_init_loss: tensor(0.6557, grad_fn=<NllLossBackward0>)\n",
      "ENN_init_loss: tensor(0.6675, grad_fn=<NllLossBackward0>)\n",
      "ENN_init_loss: tensor(0.6548, grad_fn=<NllLossBackward0>)\n",
      "ENN_loss: tensor(0.0510, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0801, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0914, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0476, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1101, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0476, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0572, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0567, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0783, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0678, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0620, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0660, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0668, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0650, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0884, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0721, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0573, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1066, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0585, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0910, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0635, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0745, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0437, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0834, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0850, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0669, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0390, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0853, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0550, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0587, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0832, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0599, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0581, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1010, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0485, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0640, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0362, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0574, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0977, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0985, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0554, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0729, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0742, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0614, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0786, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0687, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0735, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0641, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0657, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0849, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0600, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0817, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0405, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0844, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0874, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0565, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0590, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0898, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0681, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0387, grad_fn=<MeanBackward0>)\n",
      "recall list tensor([0.5077, 0.5309, 0.4975, 0.5157, 0.5379, 0.5347, 0.5131, 0.5123, 0.4845,\n",
      "        0.5035, 0.5139, 0.5539, 0.5032, 0.4922, 0.5410, 0.5136, 0.5212, 0.5147,\n",
      "        0.5074, 0.4765, 0.5033, 0.5307, 0.5368, 0.5436, 0.5349, 0.5233, 0.5512,\n",
      "        0.5325, 0.4990, 0.5292, 0.5171, 0.4682, 0.5262, 0.5026, 0.5146, 0.5157,\n",
      "        0.4965, 0.5065, 0.4896, 0.5102, 0.5090, 0.5013, 0.5579, 0.5202, 0.5295,\n",
      "        0.5195, 0.5305, 0.5188, 0.5305, 0.5317, 0.5374, 0.4966, 0.5050, 0.5041,\n",
      "        0.5557, 0.4999, 0.4894, 0.5418, 0.5094, 0.5275, 0.5094, 0.5306, 0.5232,\n",
      "        0.5435, 0.5363, 0.5460, 0.5083, 0.5121, 0.4642, 0.5472, 0.5516, 0.5085,\n",
      "        0.5182, 0.5257, 0.5002, 0.5345, 0.5140, 0.4940, 0.5108, 0.5258, 0.4992,\n",
      "        0.5143, 0.5495, 0.5124, 0.5157, 0.5197, 0.5311, 0.5498, 0.5129, 0.4852,\n",
      "        0.5013, 0.5275, 0.5284, 0.5047, 0.4972, 0.5511, 0.5219, 0.4975, 0.5038,\n",
      "        0.5023], grad_fn=<CatBackward0>)\n",
      "var of recall: tensor(0.0004, grad_fn=<SubBackward0>)\n",
      "mean of recall tensor(0.5175, grad_fn=<MeanBackward0>)\n",
      "meta_loss: tensor(0.0004, grad_fn=<SubBackward0>)\n",
      "recall_true: tensor(0.4907)\n",
      "ENN_loss: tensor(0.0671, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0455, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0758, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0544, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0870, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0414, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0537, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0500, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0640, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0496, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0492, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0732, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0913, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0596, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0430, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0630, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0890, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0572, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0426, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0575, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0539, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0847, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0735, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0462, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0685, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0620, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0536, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0665, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0525, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0554, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0507, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0918, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0378, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0813, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0674, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0633, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0437, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0364, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1108, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0498, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0981, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0359, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0597, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0681, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0598, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0603, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0699, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0497, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1082, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0389, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0297, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0505, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0741, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0407, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0695, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0781, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0486, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0620, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0560, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0711, grad_fn=<MeanBackward0>)\n",
      "recall list tensor([0.5208, 0.5477, 0.5005, 0.4741, 0.5125, 0.5354, 0.5484, 0.4782, 0.4899,\n",
      "        0.5381, 0.4983, 0.5430, 0.4782, 0.5120, 0.5558, 0.5349, 0.5245, 0.5514,\n",
      "        0.4891, 0.4775, 0.5069, 0.4690, 0.4945, 0.5324, 0.4754, 0.5373, 0.4844,\n",
      "        0.5663, 0.4872, 0.5162, 0.5259, 0.5555, 0.5007, 0.4844, 0.5232, 0.5304,\n",
      "        0.5181, 0.5401, 0.5679, 0.5506, 0.5154, 0.4912, 0.4979, 0.4960, 0.4722,\n",
      "        0.5105, 0.5222, 0.4787, 0.5178, 0.5276, 0.4812, 0.5081, 0.5176, 0.4792,\n",
      "        0.5115, 0.5081, 0.4877, 0.4705, 0.4787, 0.5370, 0.5542, 0.5353, 0.4921,\n",
      "        0.5506, 0.5265, 0.5079, 0.4994, 0.5379, 0.4645, 0.5404, 0.4895, 0.5200,\n",
      "        0.4951, 0.5307, 0.5085, 0.5113, 0.4681, 0.4935, 0.5265, 0.5395, 0.5060,\n",
      "        0.5268, 0.5276, 0.5201, 0.5138, 0.4911, 0.4905, 0.5039, 0.5270, 0.4899,\n",
      "        0.4972, 0.4993, 0.4908, 0.4798, 0.5108, 0.5034, 0.5010, 0.4661, 0.4890,\n",
      "        0.5408], grad_fn=<CatBackward0>)\n",
      "var of recall: tensor(0.0006, grad_fn=<SubBackward0>)\n",
      "mean of recall tensor(0.5105, grad_fn=<MeanBackward0>)\n",
      "meta_loss: tensor(0.0006, grad_fn=<SubBackward0>)\n",
      "recall_true: tensor(0.4907)\n",
      "ENN_loss: tensor(0.0479, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0672, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0775, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0415, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0550, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0574, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0664, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0772, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0504, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0607, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0651, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0890, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0464, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0904, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0634, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0325, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0429, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0775, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0473, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0646, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0607, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0736, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0386, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0625, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0701, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0446, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0565, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0572, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0687, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0522, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0480, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0587, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0429, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0297, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1006, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0699, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0977, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0593, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0199, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0888, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0659, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0613, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0438, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0669, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0655, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0336, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0617, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0703, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0694, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0645, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0534, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0539, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0527, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0640, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0610, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0647, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0673, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0599, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0508, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0682, grad_fn=<MeanBackward0>)\n",
      "recall list tensor([0.5217, 0.5000, 0.5274, 0.5259, 0.5660, 0.5509, 0.5268, 0.5104, 0.5349,\n",
      "        0.4916, 0.4883, 0.5400, 0.5380, 0.4862, 0.5552, 0.5152, 0.4949, 0.5121,\n",
      "        0.4933, 0.5410, 0.5330, 0.5197, 0.5533, 0.4784, 0.5144, 0.5675, 0.5229,\n",
      "        0.5280, 0.5276, 0.5287, 0.5267, 0.5315, 0.4916, 0.5373, 0.4842, 0.5214,\n",
      "        0.5161, 0.5538, 0.4951, 0.4773, 0.5172, 0.5061, 0.5175, 0.5534, 0.4881,\n",
      "        0.5457, 0.4735, 0.5092, 0.4997, 0.5513, 0.4980, 0.5029, 0.5342, 0.5042,\n",
      "        0.5072, 0.5138, 0.4910, 0.5515, 0.5347, 0.5477, 0.5012, 0.5381, 0.5096,\n",
      "        0.4998, 0.4893, 0.4970, 0.5435, 0.4984, 0.4294, 0.4744, 0.5617, 0.5556,\n",
      "        0.5361, 0.5233, 0.4930, 0.4985, 0.5176, 0.5080, 0.5048, 0.4843, 0.4751,\n",
      "        0.5031, 0.4989, 0.5018, 0.5254, 0.4380, 0.4956, 0.5291, 0.5185, 0.5850,\n",
      "        0.5405, 0.5122, 0.5439, 0.4933, 0.5503, 0.4906, 0.5445, 0.5241, 0.5320,\n",
      "        0.5097], grad_fn=<CatBackward0>)\n",
      "var of recall: tensor(0.0007, grad_fn=<SubBackward0>)\n",
      "mean of recall tensor(0.5165, grad_fn=<MeanBackward0>)\n",
      "meta_loss: tensor(0.0007, grad_fn=<SubBackward0>)\n",
      "recall_true: tensor(0.4907)\n",
      "ENN_loss: tensor(0.0644, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0417, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0829, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0792, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0866, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0366, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0533, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0849, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1090, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0794, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0435, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0418, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0794, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0646, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0710, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0590, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0420, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0632, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0779, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1493, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0525, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0497, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0752, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0737, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0485, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0702, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0486, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0788, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0518, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0449, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0812, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0869, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0700, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1077, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0562, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0316, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0609, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0620, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0784, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0627, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0579, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0510, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1024, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0738, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0608, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0557, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0844, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0667, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0633, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0434, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0787, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0697, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0825, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0697, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0541, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0668, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0993, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0770, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0460, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0572, grad_fn=<MeanBackward0>)\n",
      "recall list tensor([0.4847, 0.5109, 0.5122, 0.5137, 0.5282, 0.4879, 0.5024, 0.4582, 0.5370,\n",
      "        0.5212, 0.5442, 0.5342, 0.5109, 0.5125, 0.4981, 0.4989, 0.4577, 0.5031,\n",
      "        0.5179, 0.5705, 0.5063, 0.5245, 0.5240, 0.4648, 0.5270, 0.4978, 0.5162,\n",
      "        0.5129, 0.5417, 0.5238, 0.5447, 0.5009, 0.5050, 0.5014, 0.5175, 0.4779,\n",
      "        0.5035, 0.4915, 0.5135, 0.5484, 0.4567, 0.5064, 0.5226, 0.5740, 0.5279,\n",
      "        0.5315, 0.5207, 0.5410, 0.4841, 0.5443, 0.5178, 0.4981, 0.5038, 0.4848,\n",
      "        0.4659, 0.4908, 0.5291, 0.4892, 0.5310, 0.5043, 0.5280, 0.4798, 0.5055,\n",
      "        0.5654, 0.5075, 0.5041, 0.5322, 0.5072, 0.5206, 0.4839, 0.5582, 0.5055,\n",
      "        0.5243, 0.5228, 0.4973, 0.5103, 0.4952, 0.5320, 0.5339, 0.5504, 0.5049,\n",
      "        0.5031, 0.4926, 0.4921, 0.5259, 0.5198, 0.5149, 0.5148, 0.5132, 0.5283,\n",
      "        0.5197, 0.5341, 0.4916, 0.5157, 0.4905, 0.5665, 0.5617, 0.4944, 0.5121,\n",
      "        0.4999], grad_fn=<CatBackward0>)\n",
      "var of recall: tensor(0.0006, grad_fn=<SubBackward0>)\n",
      "mean of recall tensor(0.5133, grad_fn=<MeanBackward0>)\n",
      "meta_loss: tensor(0.0006, grad_fn=<SubBackward0>)\n",
      "recall_true: tensor(0.4907)\n",
      "ENN_loss: tensor(0.0361, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0605, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0771, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0338, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0731, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0447, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0765, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0490, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0489, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0692, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0393, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0760, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0471, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0568, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0382, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0673, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0628, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0342, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0451, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0677, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0561, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0399, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0572, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0454, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0703, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0526, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0416, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0553, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0588, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0848, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0250, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0410, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0515, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0398, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0681, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0579, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0565, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0471, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0587, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0375, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0575, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0511, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0491, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0399, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0408, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0574, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0517, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0594, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0720, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0530, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0867, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0301, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0621, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0440, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0724, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0429, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0764, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0302, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0452, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0603, grad_fn=<MeanBackward0>)\n",
      "recall list tensor([0.5243, 0.5186, 0.5064, 0.5125, 0.5524, 0.5146, 0.5524, 0.4847, 0.5614,\n",
      "        0.5179, 0.5410, 0.4694, 0.5211, 0.4897, 0.5651, 0.4850, 0.4939, 0.5176,\n",
      "        0.5550, 0.5164, 0.5032, 0.4879, 0.5085, 0.4980, 0.5636, 0.5417, 0.5407,\n",
      "        0.5439, 0.4981, 0.4991, 0.4762, 0.5817, 0.5290, 0.4600, 0.5047, 0.4668,\n",
      "        0.4664, 0.4928, 0.4570, 0.5685, 0.5339, 0.5156, 0.4985, 0.4580, 0.5445,\n",
      "        0.4459, 0.5585, 0.4533, 0.5467, 0.5231, 0.4984, 0.5227, 0.5642, 0.4852,\n",
      "        0.4978, 0.5124, 0.5605, 0.5431, 0.4687, 0.5444, 0.5406, 0.5316, 0.5297,\n",
      "        0.4818, 0.4725, 0.5487, 0.5199, 0.4565, 0.5718, 0.5630, 0.5138, 0.5132,\n",
      "        0.5315, 0.4928, 0.5442, 0.5378, 0.5267, 0.4289, 0.5708, 0.4963, 0.5472,\n",
      "        0.5325, 0.5494, 0.5424, 0.5328, 0.5618, 0.4510, 0.5626, 0.5661, 0.5394,\n",
      "        0.5553, 0.4834, 0.5607, 0.4621, 0.5274, 0.5542, 0.6024, 0.4841, 0.4910,\n",
      "        0.4622], grad_fn=<CatBackward0>)\n",
      "var of recall: tensor(0.0013, grad_fn=<SubBackward0>)\n",
      "mean of recall tensor(0.5180, grad_fn=<MeanBackward0>)\n",
      "meta_loss: tensor(0.0013, grad_fn=<SubBackward0>)\n",
      "recall_true: tensor(0.4907)\n",
      "ENN_loss: tensor(0.0514, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0663, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0724, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0654, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0662, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0566, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0578, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0523, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0854, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0458, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0639, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0334, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0659, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0619, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0686, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0528, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0553, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0476, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0703, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0524, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0656, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0680, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0652, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0469, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0638, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0666, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0666, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0341, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0677, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0516, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0667, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0645, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0825, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0439, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0628, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0559, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0501, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0718, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0520, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0544, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0485, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0712, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0456, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0632, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0635, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0529, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0619, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0560, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0421, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0605, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0576, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0737, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0385, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0697, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0635, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0607, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0577, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0748, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0439, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0526, grad_fn=<MeanBackward0>)\n",
      "recall list tensor([0.5179, 0.4898, 0.5300, 0.5622, 0.5544, 0.5123, 0.5162, 0.5250, 0.5112,\n",
      "        0.5181, 0.5023, 0.4846, 0.5141, 0.5208, 0.5213, 0.4865, 0.4977, 0.4762,\n",
      "        0.4818, 0.5381, 0.5933, 0.5364, 0.4563, 0.5304, 0.5228, 0.5489, 0.4840,\n",
      "        0.5018, 0.5302, 0.5002, 0.5277, 0.5232, 0.5081, 0.5336, 0.5008, 0.5153,\n",
      "        0.4999, 0.5102, 0.4946, 0.5223, 0.4724, 0.5257, 0.5330, 0.5022, 0.4830,\n",
      "        0.4907, 0.5207, 0.5280, 0.5294, 0.4755, 0.5019, 0.4857, 0.5465, 0.5804,\n",
      "        0.4831, 0.5002, 0.4948, 0.4617, 0.5297, 0.4921, 0.5485, 0.5281, 0.5224,\n",
      "        0.5635, 0.4846, 0.5109, 0.5417, 0.4853, 0.4875, 0.4701, 0.5163, 0.5259,\n",
      "        0.5108, 0.4830, 0.4733, 0.5203, 0.5024, 0.4890, 0.5063, 0.5036, 0.5424,\n",
      "        0.4928, 0.5025, 0.5153, 0.5019, 0.5135, 0.5489, 0.5388, 0.5307, 0.5286,\n",
      "        0.5367, 0.5357, 0.5006, 0.5164, 0.5269, 0.5231, 0.5363, 0.5313, 0.5415,\n",
      "        0.5490], grad_fn=<CatBackward0>)\n",
      "var of recall: tensor(0.0006, grad_fn=<SubBackward0>)\n",
      "mean of recall tensor(0.5142, grad_fn=<MeanBackward0>)\n",
      "meta_loss: tensor(0.0006, grad_fn=<SubBackward0>)\n",
      "recall_true: tensor(0.4907)\n",
      "ENN_loss: tensor(0.0956, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0627, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0706, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0779, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0912, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0641, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0803, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0756, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0612, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0705, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0693, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1018, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0771, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0598, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0857, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0896, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0844, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0666, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0714, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0806, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0782, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0955, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0576, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0509, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1009, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0294, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0826, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0729, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0612, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0769, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0925, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0603, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0564, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0793, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0845, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0673, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0860, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0996, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0411, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0542, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0870, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0610, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0617, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0839, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0741, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0796, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0557, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0586, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0704, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0625, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0769, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0580, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0581, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0888, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0639, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0699, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1099, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0678, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0657, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0736, grad_fn=<MeanBackward0>)\n",
      "recall list tensor([0.5177, 0.5281, 0.5419, 0.5023, 0.5179, 0.5170, 0.4966, 0.4958, 0.4944,\n",
      "        0.5377, 0.5409, 0.5173, 0.5114, 0.5371, 0.5041, 0.5571, 0.4905, 0.5228,\n",
      "        0.5059, 0.5432, 0.5025, 0.4988, 0.5210, 0.5194, 0.5361, 0.4814, 0.5195,\n",
      "        0.5603, 0.4967, 0.4953, 0.5145, 0.5073, 0.5130, 0.4958, 0.5349, 0.5131,\n",
      "        0.5148, 0.5334, 0.5420, 0.5332, 0.5323, 0.5125, 0.5189, 0.4910, 0.5136,\n",
      "        0.5328, 0.5156, 0.5301, 0.5292, 0.5067, 0.5232, 0.5085, 0.5313, 0.5509,\n",
      "        0.5222, 0.5303, 0.4960, 0.5205, 0.5067, 0.5602, 0.5011, 0.5177, 0.5126,\n",
      "        0.5183, 0.4903, 0.5092, 0.5341, 0.4962, 0.4925, 0.4870, 0.4970, 0.5218,\n",
      "        0.5421, 0.4894, 0.5268, 0.5284, 0.4977, 0.5056, 0.5732, 0.5172, 0.5233,\n",
      "        0.5510, 0.5128, 0.5152, 0.4859, 0.5319, 0.5046, 0.5042, 0.5101, 0.4986,\n",
      "        0.5016, 0.5198, 0.5104, 0.5049, 0.5108, 0.5039, 0.5154, 0.5333, 0.5265,\n",
      "        0.5389], grad_fn=<CatBackward0>)\n",
      "var of recall: tensor(0.0003, grad_fn=<SubBackward0>)\n",
      "mean of recall tensor(0.5171, grad_fn=<MeanBackward0>)\n",
      "meta_loss: tensor(0.0003, grad_fn=<SubBackward0>)\n",
      "recall_true: tensor(0.4907)\n",
      "ENN_loss: tensor(0.0369, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0640, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0758, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1047, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0702, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0512, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0800, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0710, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0587, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1201, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0602, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0444, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0565, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0615, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0764, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0878, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0728, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0738, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0542, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0769, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0617, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0724, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0623, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0848, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0725, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0694, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0529, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0847, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1007, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0832, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0348, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0528, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0700, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0773, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1067, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0372, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0942, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0908, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0682, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0482, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0687, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0514, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0718, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0751, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0396, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0617, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0948, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0778, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0835, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0562, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0886, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0462, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0832, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0533, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0933, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0654, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0292, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1064, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0510, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0927, grad_fn=<MeanBackward0>)\n",
      "recall list tensor([0.4956, 0.4836, 0.4977, 0.5186, 0.5468, 0.4809, 0.5150, 0.5238, 0.5141,\n",
      "        0.5330, 0.4744, 0.4978, 0.5075, 0.5069, 0.5289, 0.5344, 0.5057, 0.5012,\n",
      "        0.5285, 0.5049, 0.4982, 0.5330, 0.5626, 0.5356, 0.5065, 0.4896, 0.5131,\n",
      "        0.5309, 0.4922, 0.4963, 0.5419, 0.4934, 0.5050, 0.5042, 0.4661, 0.4960,\n",
      "        0.4875, 0.5335, 0.5269, 0.5247, 0.5453, 0.5242, 0.4898, 0.5014, 0.4793,\n",
      "        0.5048, 0.4934, 0.5176, 0.5104, 0.5186, 0.4985, 0.5283, 0.4840, 0.5222,\n",
      "        0.5529, 0.4877, 0.5381, 0.5201, 0.5017, 0.4890, 0.5284, 0.5552, 0.5317,\n",
      "        0.5163, 0.5155, 0.5175, 0.5337, 0.5633, 0.5009, 0.4778, 0.5557, 0.5144,\n",
      "        0.5343, 0.5302, 0.5029, 0.5202, 0.5322, 0.5415, 0.5216, 0.4728, 0.5206,\n",
      "        0.4907, 0.5196, 0.4967, 0.5190, 0.4943, 0.5116, 0.5325, 0.5497, 0.5138,\n",
      "        0.5030, 0.5276, 0.5129, 0.4971, 0.5404, 0.4922, 0.5344, 0.5157, 0.5117,\n",
      "        0.4848], grad_fn=<CatBackward0>)\n",
      "var of recall: tensor(0.0004, grad_fn=<SubBackward0>)\n",
      "mean of recall tensor(0.5138, grad_fn=<MeanBackward0>)\n",
      "meta_loss: tensor(0.0004, grad_fn=<SubBackward0>)\n",
      "recall_true: tensor(0.4907)\n",
      "ENN_loss: tensor(0.0549, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0635, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0731, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0675, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0798, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0620, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0600, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0735, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0688, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0940, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0500, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0478, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0552, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0334, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0573, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1055, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0513, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0494, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0586, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0972, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0593, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0832, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0688, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0458, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0799, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0502, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0617, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0594, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0971, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0606, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0420, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0438, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0746, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0793, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0592, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0513, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0628, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0544, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0750, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0573, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0460, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0736, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0712, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0621, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0729, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0623, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0850, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0450, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0686, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0730, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0539, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0556, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0539, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0376, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0768, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0704, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0783, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0663, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0421, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0753, grad_fn=<MeanBackward0>)\n",
      "recall list tensor([0.4892, 0.4969, 0.5582, 0.5017, 0.5265, 0.5172, 0.4837, 0.5293, 0.5142,\n",
      "        0.5294, 0.5146, 0.4896, 0.5095, 0.5138, 0.5138, 0.5029, 0.4964, 0.5300,\n",
      "        0.5208, 0.5397, 0.4919, 0.5596, 0.5014, 0.4790, 0.5162, 0.5271, 0.5051,\n",
      "        0.5098, 0.4758, 0.4712, 0.5134, 0.5137, 0.5903, 0.5222, 0.5154, 0.5169,\n",
      "        0.5093, 0.4868, 0.5187, 0.4878, 0.5373, 0.5125, 0.5402, 0.5304, 0.4816,\n",
      "        0.5351, 0.5135, 0.5074, 0.4928, 0.5589, 0.5314, 0.5245, 0.5303, 0.4862,\n",
      "        0.4972, 0.5317, 0.5302, 0.5083, 0.4936, 0.5196, 0.5877, 0.4750, 0.4812,\n",
      "        0.4945, 0.5546, 0.5096, 0.5172, 0.5226, 0.4765, 0.5139, 0.5172, 0.5398,\n",
      "        0.4952, 0.5138, 0.5450, 0.5249, 0.5459, 0.4725, 0.5648, 0.5370, 0.4944,\n",
      "        0.4994, 0.5281, 0.5300, 0.4711, 0.5108, 0.5561, 0.5168, 0.5074, 0.5162,\n",
      "        0.5235, 0.5342, 0.4972, 0.5160, 0.4935, 0.5361, 0.5266, 0.5207, 0.4601,\n",
      "        0.5306], grad_fn=<CatBackward0>)\n",
      "var of recall: tensor(0.0006, grad_fn=<SubBackward0>)\n",
      "mean of recall tensor(0.5151, grad_fn=<MeanBackward0>)\n",
      "meta_loss: tensor(0.0006, grad_fn=<SubBackward0>)\n",
      "recall_true: tensor(0.4907)\n",
      "ENN_loss: tensor(0.0758, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0857, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0636, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0790, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0405, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1033, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0940, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0445, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0554, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0776, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0728, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0792, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0572, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0834, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0916, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0529, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0685, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0574, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0748, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0873, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1072, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0289, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0744, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0754, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0630, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0858, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0587, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0665, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0557, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0725, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0389, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1011, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1095, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0807, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0457, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0405, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0634, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0852, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0660, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0519, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0636, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0485, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0871, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0784, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0676, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0531, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0843, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0687, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1155, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0483, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0431, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0766, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0782, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0719, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0789, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0425, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0779, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0574, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0888, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0465, grad_fn=<MeanBackward0>)\n",
      "recall list tensor([0.5125, 0.5172, 0.5101, 0.4957, 0.5450, 0.5041, 0.5297, 0.5196, 0.5014,\n",
      "        0.5733, 0.5314, 0.5065, 0.4948, 0.5474, 0.4995, 0.5062, 0.5292, 0.4772,\n",
      "        0.4973, 0.5459, 0.5142, 0.5250, 0.5054, 0.4999, 0.4914, 0.5178, 0.5017,\n",
      "        0.5222, 0.4851, 0.5381, 0.5348, 0.5134, 0.4953, 0.5399, 0.5085, 0.5318,\n",
      "        0.5301, 0.5096, 0.5347, 0.5200, 0.5379, 0.5057, 0.5411, 0.5416, 0.5217,\n",
      "        0.5419, 0.5064, 0.4751, 0.5284, 0.4962, 0.5004, 0.4833, 0.5278, 0.5261,\n",
      "        0.4989, 0.5354, 0.5162, 0.5448, 0.5090, 0.5228, 0.5319, 0.5015, 0.4981,\n",
      "        0.5155, 0.5417, 0.4910, 0.5225, 0.5096, 0.5186, 0.5326, 0.5342, 0.5187,\n",
      "        0.5100, 0.5494, 0.5240, 0.5270, 0.5253, 0.4740, 0.5116, 0.5166, 0.4884,\n",
      "        0.5071, 0.5185, 0.5077, 0.4967, 0.4967, 0.5210, 0.5148, 0.5251, 0.5131,\n",
      "        0.5288, 0.4971, 0.5364, 0.5162, 0.5291, 0.4931, 0.5153, 0.5103, 0.5350,\n",
      "        0.4955], grad_fn=<CatBackward0>)\n",
      "var of recall: tensor(0.0003, grad_fn=<SubBackward0>)\n",
      "mean of recall tensor(0.5162, grad_fn=<MeanBackward0>)\n",
      "meta_loss: tensor(0.0003, grad_fn=<SubBackward0>)\n",
      "recall_true: tensor(0.4907)\n",
      "ENN_loss: tensor(0.0553, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0685, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0626, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0788, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0598, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0566, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0403, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1129, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0718, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0821, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0621, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0759, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0569, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0549, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0963, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0679, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0355, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0623, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0599, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1125, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0647, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0865, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0868, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0366, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0615, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0518, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0923, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0746, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0593, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0737, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0658, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0779, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0750, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0612, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0554, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0685, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0873, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0464, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0873, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0480, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0671, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0834, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0675, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0546, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0584, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0795, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0741, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0432, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0785, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0957, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0616, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0511, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0820, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0694, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0750, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0467, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0698, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0653, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0758, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0572, grad_fn=<MeanBackward0>)\n",
      "recall list tensor([0.5173, 0.4950, 0.4773, 0.5115, 0.5186, 0.5418, 0.5223, 0.5244, 0.4957,\n",
      "        0.4915, 0.5457, 0.5000, 0.5124, 0.5406, 0.5381, 0.5016, 0.5411, 0.5196,\n",
      "        0.5345, 0.4754, 0.5329, 0.4711, 0.5438, 0.5304, 0.5176, 0.4940, 0.5356,\n",
      "        0.5214, 0.4953, 0.5153, 0.5182, 0.4795, 0.4907, 0.4947, 0.5299, 0.5421,\n",
      "        0.5350, 0.5066, 0.5449, 0.5164, 0.5294, 0.4964, 0.5462, 0.5069, 0.5552,\n",
      "        0.5108, 0.5052, 0.4665, 0.5553, 0.5401, 0.5722, 0.5205, 0.5421, 0.5088,\n",
      "        0.4667, 0.4993, 0.5322, 0.5189, 0.5167, 0.4982, 0.5217, 0.5722, 0.5596,\n",
      "        0.5342, 0.5127, 0.5095, 0.5486, 0.5153, 0.5218, 0.5169, 0.5225, 0.5072,\n",
      "        0.5083, 0.5198, 0.5201, 0.5356, 0.5380, 0.5293, 0.5014, 0.4903, 0.5354,\n",
      "        0.5021, 0.5015, 0.4838, 0.4868, 0.5448, 0.4981, 0.4936, 0.5362, 0.5443,\n",
      "        0.4881, 0.5131, 0.4939, 0.5194, 0.5011, 0.5169, 0.5395, 0.5290, 0.5025,\n",
      "        0.5264], grad_fn=<CatBackward0>)\n",
      "var of recall: tensor(0.0005, grad_fn=<SubBackward0>)\n",
      "mean of recall tensor(0.5175, grad_fn=<MeanBackward0>)\n",
      "meta_loss: tensor(0.0005, grad_fn=<SubBackward0>)\n",
      "recall_true: tensor(0.4907)\n",
      "ENN_loss: tensor(0.0494, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0708, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0762, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0570, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0814, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1000, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0809, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0514, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0573, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0997, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0537, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0543, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0542, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0751, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0644, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0711, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0858, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0744, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0694, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0632, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0776, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0750, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0568, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0677, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0839, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0716, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0596, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0430, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0596, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0626, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1163, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0633, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0567, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1219, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0938, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0451, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0677, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0617, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0756, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0687, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0610, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1078, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0652, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0804, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0584, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0825, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0362, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0774, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0914, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0806, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0570, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0567, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0663, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0895, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0614, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0591, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0713, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0877, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0699, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0683, grad_fn=<MeanBackward0>)\n",
      "recall list tensor([0.5006, 0.5284, 0.5433, 0.5284, 0.5764, 0.4916, 0.5283, 0.4976, 0.5492,\n",
      "        0.5449, 0.4961, 0.5015, 0.5232, 0.5092, 0.4997, 0.5276, 0.5255, 0.4621,\n",
      "        0.5031, 0.4752, 0.4879, 0.4457, 0.5233, 0.4986, 0.5214, 0.5176, 0.5111,\n",
      "        0.5524, 0.5368, 0.5080, 0.5083, 0.4848, 0.4917, 0.5210, 0.5166, 0.5407,\n",
      "        0.5311, 0.5254, 0.4983, 0.5105, 0.5319, 0.4977, 0.5168, 0.4970, 0.5604,\n",
      "        0.5293, 0.5213, 0.5393, 0.5398, 0.4868, 0.4955, 0.5107, 0.5118, 0.4927,\n",
      "        0.5331, 0.4773, 0.5175, 0.5215, 0.5284, 0.5263, 0.4951, 0.5449, 0.5038,\n",
      "        0.5436, 0.4899, 0.5316, 0.5685, 0.5070, 0.4841, 0.5052, 0.5082, 0.4910,\n",
      "        0.5537, 0.5189, 0.5203, 0.5135, 0.5992, 0.5431, 0.5252, 0.5170, 0.5057,\n",
      "        0.5127, 0.4830, 0.5122, 0.4897, 0.5113, 0.5021, 0.4948, 0.5677, 0.5322,\n",
      "        0.5312, 0.5079, 0.4908, 0.4812, 0.5057, 0.5401, 0.4995, 0.5561, 0.5145,\n",
      "        0.5005], grad_fn=<CatBackward0>)\n",
      "var of recall: tensor(0.0006, grad_fn=<SubBackward0>)\n",
      "mean of recall tensor(0.5158, grad_fn=<MeanBackward0>)\n",
      "meta_loss: tensor(0.0006, grad_fn=<SubBackward0>)\n",
      "recall_true: tensor(0.4907)\n",
      "ENN_loss: tensor(0.0777, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0552, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0733, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0947, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1035, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0631, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0666, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0253, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0720, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0741, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0788, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0702, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0538, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0657, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1284, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0872, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0864, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0630, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0533, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0814, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0770, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0675, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0860, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0557, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0771, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0591, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0699, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0763, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0751, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0819, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0823, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0469, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0599, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0887, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0659, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0652, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0643, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0842, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0660, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0644, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0609, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0556, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0906, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0703, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0679, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0601, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0724, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0904, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0460, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0882, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0605, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0667, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0996, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0574, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0621, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0712, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0468, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0899, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0618, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0777, grad_fn=<MeanBackward0>)\n",
      "recall list tensor([0.5286, 0.5162, 0.5146, 0.5194, 0.5028, 0.5219, 0.5228, 0.4944, 0.5234,\n",
      "        0.5043, 0.5260, 0.5492, 0.5016, 0.5049, 0.5250, 0.5189, 0.5113, 0.5011,\n",
      "        0.5160, 0.5333, 0.5066, 0.5128, 0.5021, 0.5162, 0.4789, 0.4976, 0.5159,\n",
      "        0.5152, 0.4870, 0.4789, 0.4690, 0.5158, 0.5170, 0.5132, 0.5045, 0.5103,\n",
      "        0.5340, 0.5021, 0.5037, 0.4965, 0.5183, 0.5058, 0.5407, 0.4986, 0.5007,\n",
      "        0.5191, 0.5305, 0.4830, 0.5352, 0.4848, 0.5014, 0.5082, 0.5230, 0.4871,\n",
      "        0.4992, 0.5496, 0.5320, 0.5218, 0.5092, 0.5150, 0.5119, 0.5180, 0.5137,\n",
      "        0.5376, 0.5146, 0.5284, 0.5091, 0.4843, 0.5164, 0.5096, 0.5152, 0.4974,\n",
      "        0.5483, 0.4649, 0.5206, 0.5338, 0.5289, 0.5354, 0.5107, 0.5082, 0.4985,\n",
      "        0.4994, 0.5589, 0.5248, 0.5415, 0.4770, 0.5335, 0.4763, 0.5163, 0.5223,\n",
      "        0.5115, 0.5238, 0.5239, 0.5141, 0.5245, 0.5306, 0.5267, 0.5196, 0.5065,\n",
      "        0.5555], grad_fn=<CatBackward0>)\n",
      "var of recall: tensor(0.0003, grad_fn=<SubBackward0>)\n",
      "mean of recall tensor(0.5137, grad_fn=<MeanBackward0>)\n",
      "meta_loss: tensor(0.0003, grad_fn=<SubBackward0>)\n",
      "recall_true: tensor(0.4907)\n",
      "ENN_loss: tensor(0.0486, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0782, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0572, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0982, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0520, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0864, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0711, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0790, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0664, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0733, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0912, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0538, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0497, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0727, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0746, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0799, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1084, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0448, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0822, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0690, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0691, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0504, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0651, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0880, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0523, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1177, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0705, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0596, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0843, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0704, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0706, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0653, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0479, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0461, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1150, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0902, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0579, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0651, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0794, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0909, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0572, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1025, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0811, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0408, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0685, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0822, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0627, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0773, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0778, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0735, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0786, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0472, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0643, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0683, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0704, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0791, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0891, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0726, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1029, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0427, grad_fn=<MeanBackward0>)\n",
      "recall list tensor([0.4792, 0.5481, 0.4899, 0.5164, 0.5387, 0.5538, 0.5116, 0.5227, 0.5176,\n",
      "        0.4976, 0.4907, 0.5436, 0.5434, 0.5200, 0.5145, 0.5306, 0.4993, 0.4778,\n",
      "        0.5253, 0.5113, 0.5202, 0.5340, 0.5163, 0.5243, 0.4993, 0.5190, 0.5136,\n",
      "        0.5118, 0.5329, 0.5055, 0.4974, 0.5056, 0.5103, 0.5337, 0.5052, 0.5327,\n",
      "        0.5136, 0.4980, 0.5267, 0.5161, 0.5028, 0.5277, 0.4835, 0.5025, 0.5445,\n",
      "        0.5155, 0.5158, 0.4844, 0.5350, 0.5121, 0.5215, 0.5129, 0.5333, 0.5024,\n",
      "        0.5003, 0.4856, 0.5340, 0.4923, 0.5452, 0.5539, 0.5260, 0.5255, 0.4675,\n",
      "        0.4937, 0.5269, 0.5447, 0.4441, 0.5398, 0.4890, 0.5003, 0.4973, 0.5141,\n",
      "        0.5529, 0.5072, 0.5380, 0.4914, 0.5029, 0.5228, 0.5166, 0.5147, 0.4966,\n",
      "        0.5652, 0.4793, 0.5159, 0.5413, 0.5205, 0.5494, 0.4929, 0.5190, 0.4901,\n",
      "        0.5292, 0.5198, 0.4989, 0.5149, 0.4875, 0.5314, 0.5210, 0.5680, 0.5217,\n",
      "        0.5836], grad_fn=<CatBackward0>)\n",
      "var of recall: tensor(0.0005, grad_fn=<SubBackward0>)\n",
      "mean of recall tensor(0.5161, grad_fn=<MeanBackward0>)\n",
      "meta_loss: tensor(0.0005, grad_fn=<SubBackward0>)\n",
      "recall_true: tensor(0.4907)\n",
      "ENN_loss: tensor(0.0597, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1002, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0953, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0468, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0891, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0570, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0368, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0621, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0500, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0760, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0458, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0763, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1195, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0360, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0420, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0665, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0609, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0328, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0444, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1077, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0519, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0819, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0781, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0344, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0880, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0614, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0771, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0390, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0746, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0681, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0573, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0563, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0478, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0620, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0766, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0593, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0530, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0545, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0898, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0385, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0802, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0592, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0639, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0735, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0588, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0740, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0671, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0397, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0563, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0463, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0776, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0669, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0778, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0679, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0523, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0534, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0556, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0572, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0734, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0616, grad_fn=<MeanBackward0>)\n",
      "recall list tensor([0.5660, 0.5152, 0.4720, 0.4988, 0.5315, 0.5312, 0.5098, 0.5323, 0.5309,\n",
      "        0.4992, 0.5171, 0.5019, 0.5532, 0.5963, 0.5726, 0.5287, 0.5122, 0.5171,\n",
      "        0.4820, 0.5410, 0.5336, 0.4822, 0.5294, 0.5057, 0.4729, 0.5272, 0.5244,\n",
      "        0.4972, 0.5288, 0.5056, 0.4828, 0.4647, 0.5166, 0.5151, 0.5249, 0.5049,\n",
      "        0.5505, 0.4626, 0.5479, 0.4691, 0.4904, 0.5448, 0.5653, 0.5363, 0.5031,\n",
      "        0.5023, 0.4765, 0.5345, 0.5022, 0.5384, 0.4742, 0.5023, 0.5781, 0.5211,\n",
      "        0.5377, 0.5157, 0.5424, 0.5078, 0.5360, 0.5140, 0.4700, 0.4992, 0.5241,\n",
      "        0.5631, 0.5432, 0.5625, 0.5330, 0.5196, 0.5155, 0.5689, 0.5126, 0.4720,\n",
      "        0.5207, 0.4931, 0.4980, 0.5192, 0.5499, 0.4990, 0.4731, 0.5030, 0.4435,\n",
      "        0.5325, 0.5113, 0.5439, 0.5721, 0.5622, 0.5457, 0.5322, 0.5291, 0.5101,\n",
      "        0.5379, 0.4758, 0.5517, 0.5300, 0.4701, 0.4815, 0.4827, 0.5148, 0.4870,\n",
      "        0.4959], grad_fn=<CatBackward0>)\n",
      "var of recall: tensor(0.0009, grad_fn=<SubBackward0>)\n",
      "mean of recall tensor(0.5173, grad_fn=<MeanBackward0>)\n",
      "meta_loss: tensor(0.0009, grad_fn=<SubBackward0>)\n",
      "recall_true: tensor(0.4907)\n",
      "ENN_loss: tensor(0.0710, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0924, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0588, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0697, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0641, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1046, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0890, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0473, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0739, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0832, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0590, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0711, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0424, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0656, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0741, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0833, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0601, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0750, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0909, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0744, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0731, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0923, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0740, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0521, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0747, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0624, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0520, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0826, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0640, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0755, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0648, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0826, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0738, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0678, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0788, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0923, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0668, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0780, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0945, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0909, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0819, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0740, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0699, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0532, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0671, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0593, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1057, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0607, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0988, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0690, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0380, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0660, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0872, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0587, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0465, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0935, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0959, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0645, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0920, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0403, grad_fn=<MeanBackward0>)\n",
      "recall list tensor([0.4891, 0.5280, 0.5566, 0.5007, 0.5014, 0.4895, 0.4925, 0.5020, 0.5021,\n",
      "        0.4811, 0.5252, 0.5294, 0.5214, 0.5034, 0.5283, 0.5575, 0.4687, 0.5307,\n",
      "        0.5349, 0.5256, 0.4871, 0.5374, 0.5259, 0.5111, 0.5244, 0.5239, 0.5253,\n",
      "        0.5506, 0.5479, 0.4986, 0.5223, 0.5034, 0.5256, 0.5320, 0.5081, 0.5241,\n",
      "        0.5302, 0.5074, 0.5033, 0.5174, 0.5053, 0.5393, 0.4939, 0.5164, 0.5490,\n",
      "        0.5073, 0.5149, 0.5221, 0.5309, 0.5224, 0.5313, 0.5105, 0.5493, 0.5372,\n",
      "        0.4916, 0.4952, 0.5109, 0.5166, 0.4993, 0.5054, 0.5117, 0.5193, 0.5069,\n",
      "        0.5318, 0.5424, 0.5346, 0.5332, 0.4954, 0.5370, 0.5351, 0.4854, 0.5431,\n",
      "        0.4989, 0.5154, 0.5396, 0.5199, 0.4933, 0.4973, 0.4860, 0.4769, 0.5577,\n",
      "        0.5348, 0.5349, 0.5235, 0.5201, 0.5292, 0.5048, 0.5106, 0.5290, 0.4966,\n",
      "        0.5363, 0.5067, 0.5260, 0.5311, 0.5185, 0.5024, 0.4959, 0.5044, 0.5345,\n",
      "        0.5326], grad_fn=<CatBackward0>)\n",
      "var of recall: tensor(0.0004, grad_fn=<SubBackward0>)\n",
      "mean of recall tensor(0.5176, grad_fn=<MeanBackward0>)\n",
      "meta_loss: tensor(0.0004, grad_fn=<SubBackward0>)\n",
      "recall_true: tensor(0.4907)\n",
      "ENN_loss: tensor(0.0678, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0920, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0390, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0944, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0628, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0824, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0619, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0754, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1210, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0486, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0490, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0695, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0688, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0928, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0712, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0681, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0593, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0622, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0654, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0873, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0597, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0449, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1010, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0793, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0514, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0880, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0884, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0487, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0545, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0604, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0898, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0678, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0798, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0609, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0589, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0860, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0680, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0671, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0773, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0753, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0676, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0773, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0861, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0611, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0745, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0382, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1025, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0662, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0453, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1119, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0736, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0470, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0445, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0688, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0771, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1047, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0763, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0421, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0916, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0725, grad_fn=<MeanBackward0>)\n",
      "recall list tensor([0.4978, 0.5264, 0.5008, 0.5350, 0.5197, 0.5549, 0.5210, 0.4961, 0.5081,\n",
      "        0.5495, 0.5178, 0.4997, 0.5491, 0.4997, 0.5145, 0.4788, 0.5169, 0.4983,\n",
      "        0.5186, 0.5314, 0.4717, 0.4997, 0.5195, 0.5275, 0.5538, 0.5228, 0.5279,\n",
      "        0.5249, 0.5090, 0.4694, 0.5260, 0.5193, 0.5162, 0.5126, 0.5522, 0.5257,\n",
      "        0.5409, 0.5019, 0.4889, 0.5199, 0.5480, 0.5050, 0.5043, 0.5371, 0.5072,\n",
      "        0.4882, 0.5351, 0.5011, 0.4867, 0.4912, 0.5186, 0.5386, 0.5103, 0.5090,\n",
      "        0.5213, 0.5082, 0.4952, 0.5491, 0.4921, 0.4943, 0.5226, 0.5447, 0.5005,\n",
      "        0.5071, 0.5319, 0.5218, 0.4829, 0.5545, 0.5466, 0.5341, 0.5079, 0.5091,\n",
      "        0.5175, 0.4954, 0.4996, 0.5308, 0.5113, 0.5245, 0.5099, 0.5074, 0.5320,\n",
      "        0.5520, 0.5031, 0.5509, 0.4951, 0.5272, 0.5130, 0.5091, 0.5019, 0.5095,\n",
      "        0.5010, 0.5327, 0.5054, 0.5372, 0.5021, 0.4760, 0.4993, 0.5088, 0.4887,\n",
      "        0.5207], grad_fn=<CatBackward0>)\n",
      "var of recall: tensor(0.0004, grad_fn=<SubBackward0>)\n",
      "mean of recall tensor(0.5153, grad_fn=<MeanBackward0>)\n",
      "meta_loss: tensor(0.0004, grad_fn=<SubBackward0>)\n",
      "recall_true: tensor(0.4907)\n",
      "ENN_loss: tensor(0.0765, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0938, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0546, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0560, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0985, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0757, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0807, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0741, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0629, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0419, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0663, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0841, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0673, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0508, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0568, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0866, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0662, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0847, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0474, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0570, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0871, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0664, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0465, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0923, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0421, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0917, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0292, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1096, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0677, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0782, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0656, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0683, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0508, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0487, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1001, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0747, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0614, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0713, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0656, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0820, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0830, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0337, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0810, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0604, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0757, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0875, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0795, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0544, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0670, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0674, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0598, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0878, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0631, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0749, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0691, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0561, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0345, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0683, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0581, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0853, grad_fn=<MeanBackward0>)\n",
      "recall list tensor([0.5025, 0.5264, 0.4969, 0.4844, 0.5308, 0.5390, 0.4979, 0.4991, 0.5347,\n",
      "        0.5334, 0.5290, 0.4972, 0.5069, 0.5129, 0.5233, 0.5323, 0.5176, 0.4778,\n",
      "        0.4925, 0.5499, 0.5244, 0.5169, 0.5136, 0.5065, 0.5205, 0.5040, 0.5527,\n",
      "        0.5311, 0.5474, 0.5525, 0.5272, 0.5089, 0.5028, 0.5014, 0.4750, 0.4616,\n",
      "        0.5005, 0.4959, 0.5405, 0.5177, 0.5042, 0.4972, 0.5171, 0.5126, 0.4995,\n",
      "        0.5342, 0.5159, 0.5654, 0.5135, 0.5360, 0.5108, 0.5334, 0.5067, 0.4914,\n",
      "        0.5032, 0.5211, 0.4861, 0.5143, 0.5212, 0.5316, 0.5202, 0.5470, 0.5188,\n",
      "        0.4941, 0.5034, 0.5218, 0.5090, 0.5296, 0.5333, 0.5570, 0.5094, 0.5204,\n",
      "        0.4846, 0.5381, 0.5240, 0.5073, 0.5298, 0.5474, 0.5287, 0.5288, 0.5387,\n",
      "        0.5053, 0.5023, 0.5074, 0.5142, 0.5340, 0.5296, 0.5323, 0.5630, 0.5431,\n",
      "        0.5108, 0.5259, 0.5273, 0.4848, 0.4746, 0.5222, 0.5263, 0.5259, 0.5145,\n",
      "        0.5438], grad_fn=<CatBackward0>)\n",
      "var of recall: tensor(0.0004, grad_fn=<SubBackward0>)\n",
      "mean of recall tensor(0.5178, grad_fn=<MeanBackward0>)\n",
      "meta_loss: tensor(0.0004, grad_fn=<SubBackward0>)\n",
      "recall_true: tensor(0.4907)\n",
      "ENN_loss: tensor(0.0786, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0669, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0758, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0501, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0597, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0981, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0588, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0558, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0618, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0819, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0707, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0899, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0599, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0846, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1272, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0486, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0500, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0362, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0985, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0866, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0810, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0461, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0955, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0695, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0883, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0613, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0577, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0678, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0427, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1008, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0949, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0287, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0954, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0511, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0665, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0799, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0998, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0492, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0398, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0716, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0771, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0555, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0799, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0496, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0757, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0894, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0547, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0449, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0973, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0536, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0699, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0752, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0677, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0894, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0620, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0611, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0836, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0520, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0702, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0717, grad_fn=<MeanBackward0>)\n",
      "recall list tensor([0.5280, 0.5188, 0.4929, 0.5024, 0.5139, 0.4842, 0.5282, 0.5058, 0.5715,\n",
      "        0.5028, 0.4956, 0.5508, 0.5355, 0.5058, 0.5054, 0.5345, 0.5134, 0.5277,\n",
      "        0.5053, 0.5183, 0.5006, 0.4965, 0.4973, 0.5211, 0.5221, 0.5317, 0.5242,\n",
      "        0.5215, 0.5410, 0.5359, 0.5902, 0.5068, 0.5279, 0.5002, 0.5444, 0.5009,\n",
      "        0.5145, 0.5158, 0.4997, 0.5094, 0.5331, 0.5417, 0.5080, 0.5126, 0.5048,\n",
      "        0.4917, 0.5647, 0.5037, 0.5047, 0.4770, 0.4870, 0.5173, 0.5219, 0.5203,\n",
      "        0.5030, 0.5500, 0.4784, 0.5104, 0.5440, 0.5179, 0.5139, 0.5188, 0.5080,\n",
      "        0.5200, 0.5209, 0.5093, 0.5034, 0.5409, 0.4991, 0.5292, 0.5491, 0.4932,\n",
      "        0.5164, 0.5050, 0.5213, 0.5436, 0.5188, 0.4983, 0.5161, 0.5140, 0.5329,\n",
      "        0.5099, 0.4763, 0.5108, 0.5171, 0.5340, 0.4837, 0.5440, 0.5198, 0.5019,\n",
      "        0.5253, 0.5308, 0.5313, 0.5174, 0.5131, 0.4974, 0.5461, 0.5156, 0.4868,\n",
      "        0.5303], grad_fn=<CatBackward0>)\n",
      "var of recall: tensor(0.0004, grad_fn=<SubBackward0>)\n",
      "mean of recall tensor(0.5170, grad_fn=<MeanBackward0>)\n",
      "meta_loss: tensor(0.0004, grad_fn=<SubBackward0>)\n",
      "recall_true: tensor(0.4907)\n",
      "ENN_loss: tensor(0.0485, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0353, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0969, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0711, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0489, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0477, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0774, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1161, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0670, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0933, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0417, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0429, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0865, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0983, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0706, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0261, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0513, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0449, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0945, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0558, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0648, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0655, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0863, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0539, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0809, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0569, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0527, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0667, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0617, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0741, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0555, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0767, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0459, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0499, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0928, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0876, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0621, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0722, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0566, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0798, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0582, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0697, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0800, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0517, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0924, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0668, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0444, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0517, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0725, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0600, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0459, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0862, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0787, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0716, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0733, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0466, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0784, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0515, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0759, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0586, grad_fn=<MeanBackward0>)\n",
      "recall list tensor([0.5656, 0.5414, 0.4859, 0.5115, 0.4840, 0.5215, 0.5149, 0.5304, 0.4972,\n",
      "        0.5036, 0.5719, 0.5306, 0.5312, 0.4631, 0.5164, 0.5153, 0.4900, 0.5382,\n",
      "        0.4759, 0.5120, 0.4801, 0.4612, 0.5526, 0.5234, 0.5458, 0.5567, 0.5186,\n",
      "        0.5540, 0.5257, 0.5096, 0.5529, 0.5197, 0.5614, 0.4653, 0.4961, 0.5003,\n",
      "        0.5243, 0.5103, 0.4977, 0.5077, 0.5162, 0.4802, 0.5011, 0.4785, 0.5174,\n",
      "        0.4744, 0.4796, 0.5147, 0.4920, 0.5207, 0.4942, 0.5214, 0.4906, 0.4814,\n",
      "        0.4812, 0.5368, 0.5178, 0.4845, 0.5250, 0.5161, 0.5066, 0.5192, 0.5027,\n",
      "        0.4927, 0.5365, 0.5360, 0.5021, 0.5107, 0.5879, 0.5187, 0.5178, 0.5603,\n",
      "        0.5305, 0.5341, 0.5172, 0.5323, 0.5198, 0.5473, 0.5226, 0.5169, 0.5238,\n",
      "        0.5178, 0.5560, 0.4949, 0.4816, 0.4837, 0.4902, 0.4882, 0.5099, 0.5207,\n",
      "        0.5122, 0.4900, 0.5386, 0.5253, 0.5514, 0.5102, 0.5854, 0.5181, 0.5359,\n",
      "        0.5107], grad_fn=<CatBackward0>)\n",
      "var of recall: tensor(0.0007, grad_fn=<SubBackward0>)\n",
      "mean of recall tensor(0.5154, grad_fn=<MeanBackward0>)\n",
      "meta_loss: tensor(0.0007, grad_fn=<SubBackward0>)\n",
      "recall_true: tensor(0.4907)\n",
      "ENN_loss: tensor(0.0650, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0619, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0497, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0579, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0574, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0576, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0407, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0856, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0795, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0642, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0436, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0812, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0820, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0445, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0445, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0732, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0590, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0579, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0677, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0450, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0634, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0510, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0380, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0900, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0724, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0659, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0591, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0460, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0530, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0605, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0652, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0795, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0441, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0737, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0556, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0644, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0677, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0413, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0613, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0668, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0767, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0447, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0569, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0784, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0610, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0733, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0617, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0430, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0567, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0572, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0324, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0970, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0512, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0596, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0429, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0773, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0591, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0640, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1054, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0356, grad_fn=<MeanBackward0>)\n",
      "recall list tensor([0.5085, 0.4935, 0.5450, 0.5408, 0.5703, 0.5175, 0.5664, 0.4851, 0.5254,\n",
      "        0.5347, 0.4893, 0.4965, 0.5066, 0.5598, 0.5133, 0.5087, 0.5166, 0.5381,\n",
      "        0.5748, 0.4999, 0.5195, 0.5299, 0.5059, 0.5469, 0.5488, 0.5592, 0.5148,\n",
      "        0.4957, 0.5291, 0.5337, 0.5184, 0.5332, 0.4970, 0.5140, 0.5468, 0.4877,\n",
      "        0.4479, 0.5613, 0.5171, 0.5570, 0.4811, 0.4976, 0.4840, 0.5246, 0.4868,\n",
      "        0.4573, 0.5235, 0.5082, 0.5570, 0.5271, 0.5343, 0.4941, 0.4703, 0.4914,\n",
      "        0.5241, 0.4675, 0.5271, 0.5399, 0.5528, 0.4860, 0.4900, 0.5084, 0.5199,\n",
      "        0.5099, 0.4942, 0.5270, 0.5088, 0.5630, 0.5025, 0.4647, 0.5324, 0.5259,\n",
      "        0.4840, 0.5578, 0.5453, 0.4927, 0.5224, 0.4951, 0.5218, 0.5267, 0.5344,\n",
      "        0.5382, 0.5009, 0.4827, 0.5110, 0.5716, 0.5054, 0.5305, 0.5571, 0.5010,\n",
      "        0.5606, 0.5486, 0.5292, 0.5373, 0.5071, 0.4834, 0.5322, 0.5229, 0.5176,\n",
      "        0.4853], grad_fn=<CatBackward0>)\n",
      "var of recall: tensor(0.0007, grad_fn=<SubBackward0>)\n",
      "mean of recall tensor(0.5184, grad_fn=<MeanBackward0>)\n",
      "meta_loss: tensor(0.0007, grad_fn=<SubBackward0>)\n",
      "recall_true: tensor(0.4907)\n",
      "ENN_loss: tensor(0.0543, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0764, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0581, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0922, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1091, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0776, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0717, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0499, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0753, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0410, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0781, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0579, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0643, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0495, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0648, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0963, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0547, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0814, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0470, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0769, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0677, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0690, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0795, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0570, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0616, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0788, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0660, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0623, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0867, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0803, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0476, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0708, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1114, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0634, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0542, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0577, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0843, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0800, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0702, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0460, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1061, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0428, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0552, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0768, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0786, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0636, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0786, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0641, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0509, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0744, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0323, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1124, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0968, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0499, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0556, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0817, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0951, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0847, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0417, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0661, grad_fn=<MeanBackward0>)\n",
      "recall list tensor([0.4953, 0.5238, 0.5076, 0.5301, 0.5476, 0.4886, 0.5358, 0.5324, 0.5455,\n",
      "        0.4824, 0.5182, 0.5149, 0.5279, 0.5213, 0.4984, 0.5303, 0.5270, 0.4903,\n",
      "        0.5278, 0.4921, 0.5600, 0.5036, 0.5118, 0.5114, 0.5165, 0.5271, 0.4832,\n",
      "        0.5362, 0.5294, 0.5358, 0.5313, 0.5096, 0.4755, 0.4813, 0.4937, 0.5211,\n",
      "        0.5021, 0.5171, 0.5224, 0.5129, 0.5017, 0.5472, 0.5297, 0.5472, 0.5240,\n",
      "        0.5127, 0.5235, 0.5333, 0.5150, 0.5478, 0.5369, 0.5211, 0.5045, 0.5160,\n",
      "        0.4787, 0.4885, 0.5068, 0.5262, 0.5232, 0.4895, 0.5236, 0.5240, 0.5294,\n",
      "        0.4758, 0.5024, 0.4981, 0.5324, 0.5040, 0.5298, 0.5396, 0.5384, 0.5316,\n",
      "        0.5015, 0.5420, 0.5069, 0.5308, 0.4782, 0.4863, 0.5200, 0.5197, 0.5113,\n",
      "        0.5368, 0.5266, 0.4864, 0.5271, 0.5141, 0.5020, 0.5115, 0.4899, 0.5182,\n",
      "        0.5383, 0.5409, 0.5283, 0.5034, 0.4845, 0.5485, 0.5176, 0.4817, 0.4984,\n",
      "        0.5504], grad_fn=<CatBackward0>)\n",
      "var of recall: tensor(0.0004, grad_fn=<SubBackward0>)\n",
      "mean of recall tensor(0.5162, grad_fn=<MeanBackward0>)\n",
      "meta_loss: tensor(0.0004, grad_fn=<SubBackward0>)\n",
      "recall_true: tensor(0.4907)\n",
      "ENN_loss: tensor(0.0406, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0890, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0849, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0844, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0710, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0740, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0603, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1081, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0462, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0535, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0940, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1038, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0760, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0663, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0567, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0787, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0685, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0766, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0627, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0689, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0816, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0534, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0496, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1073, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0805, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0711, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0730, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0498, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0595, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0584, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0816, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0750, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0401, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0892, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0650, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0822, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0729, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0833, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0598, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0664, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0492, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0777, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0720, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0804, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0740, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0806, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0458, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1108, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0862, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0566, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0697, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0711, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0770, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0744, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0632, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0603, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0782, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0623, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0795, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0700, grad_fn=<MeanBackward0>)\n",
      "recall list tensor([0.5086, 0.5204, 0.5430, 0.5287, 0.5127, 0.5078, 0.5386, 0.5133, 0.5664,\n",
      "        0.5246, 0.4927, 0.5161, 0.5118, 0.5106, 0.5364, 0.4805, 0.4866, 0.5616,\n",
      "        0.5112, 0.5042, 0.5022, 0.5112, 0.5004, 0.4959, 0.5079, 0.5031, 0.5107,\n",
      "        0.4945, 0.5323, 0.5600, 0.5193, 0.5040, 0.5376, 0.5347, 0.4957, 0.5100,\n",
      "        0.4890, 0.5267, 0.5328, 0.4992, 0.5284, 0.5315, 0.5317, 0.5516, 0.5027,\n",
      "        0.5143, 0.5320, 0.4876, 0.5230, 0.4875, 0.5133, 0.5273, 0.5114, 0.5076,\n",
      "        0.5187, 0.5376, 0.5375, 0.5236, 0.5270, 0.4948, 0.5124, 0.5527, 0.5223,\n",
      "        0.5499, 0.4951, 0.5092, 0.5279, 0.4954, 0.5342, 0.5328, 0.5324, 0.5152,\n",
      "        0.5320, 0.5219, 0.4811, 0.4949, 0.5215, 0.5181, 0.5123, 0.5230, 0.5094,\n",
      "        0.5231, 0.5225, 0.5357, 0.5167, 0.5297, 0.5187, 0.5226, 0.5265, 0.5179,\n",
      "        0.5276, 0.5153, 0.5312, 0.5410, 0.4917, 0.5458, 0.5284, 0.5366, 0.4929,\n",
      "        0.5040], grad_fn=<CatBackward0>)\n",
      "var of recall: tensor(0.0003, grad_fn=<SubBackward0>)\n",
      "mean of recall tensor(0.5185, grad_fn=<MeanBackward0>)\n",
      "meta_loss: tensor(0.0003, grad_fn=<SubBackward0>)\n",
      "recall_true: tensor(0.4907)\n",
      "ENN_loss: tensor(0.0628, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0747, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0734, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0330, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0790, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0385, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0493, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0587, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0722, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0587, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0636, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0493, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0695, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0819, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0361, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0503, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0542, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0614, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0602, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0444, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0730, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0547, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0604, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0457, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0458, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0559, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0739, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0562, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0870, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0428, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0529, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0764, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0524, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0521, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0510, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0701, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1165, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0441, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0385, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0541, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0412, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0536, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0486, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0775, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0480, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0679, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0437, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0640, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0640, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0523, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0556, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0728, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0423, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0531, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0587, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0783, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0724, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0611, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0499, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0428, grad_fn=<MeanBackward0>)\n",
      "recall list tensor([0.4716, 0.5544, 0.5203, 0.5203, 0.4913, 0.5249, 0.5137, 0.4982, 0.5565,\n",
      "        0.5416, 0.5071, 0.5116, 0.4936, 0.4925, 0.5258, 0.5280, 0.4923, 0.5137,\n",
      "        0.5419, 0.5377, 0.5056, 0.5168, 0.5587, 0.5267, 0.5374, 0.5583, 0.5094,\n",
      "        0.5405, 0.4997, 0.5496, 0.5261, 0.5320, 0.5354, 0.4997, 0.4864, 0.4962,\n",
      "        0.5440, 0.4886, 0.5214, 0.5188, 0.5467, 0.5185, 0.4908, 0.5619, 0.5007,\n",
      "        0.5428, 0.4641, 0.5400, 0.5041, 0.5451, 0.5043, 0.5890, 0.5524, 0.5476,\n",
      "        0.5140, 0.5210, 0.4985, 0.5257, 0.4870, 0.5080, 0.5471, 0.5830, 0.4704,\n",
      "        0.5124, 0.4612, 0.5410, 0.5063, 0.4909, 0.4750, 0.5628, 0.5400, 0.5243,\n",
      "        0.5386, 0.4762, 0.5181, 0.5345, 0.5503, 0.4637, 0.4900, 0.5052, 0.5139,\n",
      "        0.5317, 0.5357, 0.5364, 0.4918, 0.4651, 0.5689, 0.5180, 0.4517, 0.5283,\n",
      "        0.5030, 0.4881, 0.5280, 0.5205, 0.5290, 0.5373, 0.5247, 0.5038, 0.4984,\n",
      "        0.5408], grad_fn=<CatBackward0>)\n",
      "var of recall: tensor(0.0008, grad_fn=<SubBackward0>)\n",
      "mean of recall tensor(0.5186, grad_fn=<MeanBackward0>)\n",
      "meta_loss: tensor(0.0008, grad_fn=<SubBackward0>)\n",
      "recall_true: tensor(0.4907)\n",
      "ENN_loss: tensor(0.0767, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0537, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0505, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0882, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0610, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0621, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0754, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0883, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0911, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0724, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0882, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0459, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0688, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0787, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0829, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0522, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0814, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0424, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0706, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1003, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0713, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0618, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0808, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0612, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0775, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0457, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0862, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0573, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0540, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0746, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0564, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0833, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0667, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0791, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0630, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0638, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0567, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0648, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0509, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1018, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0576, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0972, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0750, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0658, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0709, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1311, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0484, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0570, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0507, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0540, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0946, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0711, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0425, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0764, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0772, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0713, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0643, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0570, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0890, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0639, grad_fn=<MeanBackward0>)\n",
      "recall list tensor([0.5093, 0.5228, 0.4868, 0.5213, 0.4965, 0.5203, 0.4992, 0.5065, 0.5082,\n",
      "        0.5093, 0.4977, 0.5128, 0.4758, 0.5070, 0.5026, 0.4918, 0.5179, 0.5199,\n",
      "        0.5218, 0.4949, 0.5177, 0.4990, 0.5157, 0.5333, 0.5257, 0.5084, 0.5251,\n",
      "        0.5155, 0.5237, 0.5158, 0.5272, 0.5111, 0.4939, 0.4842, 0.4977, 0.5432,\n",
      "        0.5645, 0.5199, 0.5352, 0.4841, 0.5129, 0.5167, 0.5259, 0.4927, 0.5333,\n",
      "        0.4753, 0.4911, 0.4820, 0.5488, 0.4990, 0.5136, 0.5425, 0.5002, 0.4892,\n",
      "        0.5218, 0.5278, 0.5305, 0.5369, 0.5220, 0.5312, 0.5311, 0.4787, 0.4965,\n",
      "        0.5080, 0.4861, 0.4910, 0.5036, 0.4892, 0.5353, 0.5468, 0.4865, 0.5414,\n",
      "        0.5190, 0.5249, 0.5062, 0.5248, 0.4912, 0.5136, 0.5331, 0.5057, 0.4941,\n",
      "        0.5505, 0.5511, 0.5424, 0.4869, 0.5450, 0.5072, 0.5633, 0.5160, 0.5510,\n",
      "        0.4999, 0.4429, 0.5183, 0.5442, 0.5171, 0.5114, 0.5152, 0.5180, 0.5095,\n",
      "        0.4988], grad_fn=<CatBackward0>)\n",
      "var of recall: tensor(0.0004, grad_fn=<SubBackward0>)\n",
      "mean of recall tensor(0.5135, grad_fn=<MeanBackward0>)\n",
      "meta_loss: tensor(0.0004, grad_fn=<SubBackward0>)\n",
      "recall_true: tensor(0.4907)\n",
      "ENN_loss: tensor(0.0900, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0691, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0516, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0528, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0811, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0530, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0762, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0395, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0593, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0740, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0602, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0750, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0725, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0585, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0788, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0545, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0397, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0701, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0564, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0921, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0526, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0785, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0499, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0846, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0728, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0664, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0630, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0664, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0385, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0965, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0736, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0623, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0581, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0580, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0509, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1011, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0581, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0418, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0773, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1054, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0577, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0822, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0742, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0492, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0513, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0759, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0836, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0566, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0712, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0583, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0706, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0766, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0639, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0584, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0664, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0754, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0754, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0646, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0598, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0555, grad_fn=<MeanBackward0>)\n",
      "recall list tensor([0.5214, 0.5485, 0.5398, 0.5061, 0.5331, 0.5135, 0.5399, 0.5400, 0.5247,\n",
      "        0.5476, 0.5491, 0.5494, 0.5074, 0.5131, 0.5192, 0.5499, 0.5158, 0.5137,\n",
      "        0.5017, 0.5248, 0.5155, 0.4614, 0.4921, 0.4962, 0.5250, 0.5302, 0.5179,\n",
      "        0.5139, 0.5292, 0.5119, 0.5277, 0.5131, 0.5301, 0.5166, 0.4848, 0.5268,\n",
      "        0.5216, 0.4538, 0.5136, 0.5027, 0.4824, 0.5178, 0.5164, 0.5602, 0.5437,\n",
      "        0.4933, 0.4979, 0.5412, 0.5114, 0.4833, 0.4948, 0.4836, 0.5375, 0.5256,\n",
      "        0.4969, 0.5022, 0.5188, 0.5233, 0.4844, 0.5207, 0.5087, 0.5605, 0.4935,\n",
      "        0.5114, 0.5138, 0.5221, 0.5102, 0.5391, 0.5163, 0.5227, 0.4799, 0.4967,\n",
      "        0.4864, 0.5135, 0.5115, 0.5254, 0.5331, 0.4735, 0.5038, 0.5336, 0.5303,\n",
      "        0.5074, 0.4837, 0.5284, 0.4984, 0.4882, 0.5665, 0.4931, 0.5266, 0.5298,\n",
      "        0.5054, 0.5024, 0.5301, 0.5447, 0.5450, 0.5222, 0.4977, 0.5041, 0.5194,\n",
      "        0.4789], grad_fn=<CatBackward0>)\n",
      "var of recall: tensor(0.0005, grad_fn=<SubBackward0>)\n",
      "mean of recall tensor(0.5154, grad_fn=<MeanBackward0>)\n",
      "meta_loss: tensor(0.0005, grad_fn=<SubBackward0>)\n",
      "recall_true: tensor(0.4907)\n",
      "ENN_loss: tensor(0.0532, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0759, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0754, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0434, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0654, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0498, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0630, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0504, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0743, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0834, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0522, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0489, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0590, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0465, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0731, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0745, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0364, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0535, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0851, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0554, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0679, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0448, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0472, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0833, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0580, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0602, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0671, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0743, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0569, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0398, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0506, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1113, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0814, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0447, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0596, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0555, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0542, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0592, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0677, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0309, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0530, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0655, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0565, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0578, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0846, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0739, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0591, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0331, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0683, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0394, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0471, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0911, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0637, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0512, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0694, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0699, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0399, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0650, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0718, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0497, grad_fn=<MeanBackward0>)\n",
      "recall list tensor([0.4794, 0.4976, 0.5027, 0.5274, 0.5145, 0.4995, 0.5178, 0.5189, 0.5227,\n",
      "        0.5157, 0.4998, 0.5178, 0.5122, 0.5144, 0.4875, 0.5269, 0.5325, 0.4791,\n",
      "        0.4676, 0.4678, 0.5341, 0.5047, 0.5002, 0.5167, 0.4954, 0.5250, 0.5549,\n",
      "        0.5141, 0.5109, 0.4855, 0.5105, 0.5289, 0.5433, 0.5052, 0.5433, 0.5131,\n",
      "        0.5128, 0.4964, 0.5288, 0.4993, 0.5233, 0.5338, 0.5439, 0.4694, 0.5262,\n",
      "        0.4867, 0.4953, 0.4966, 0.5522, 0.5572, 0.5749, 0.5351, 0.5249, 0.5270,\n",
      "        0.5408, 0.4904, 0.5339, 0.5047, 0.4853, 0.5339, 0.5331, 0.5359, 0.5126,\n",
      "        0.5331, 0.5315, 0.5319, 0.5027, 0.5199, 0.5275, 0.5158, 0.4859, 0.4972,\n",
      "        0.5489, 0.5446, 0.5279, 0.4977, 0.5367, 0.5596, 0.5400, 0.5586, 0.5078,\n",
      "        0.5351, 0.5108, 0.5095, 0.5157, 0.4823, 0.5092, 0.4879, 0.5313, 0.5167,\n",
      "        0.4874, 0.4926, 0.5457, 0.5244, 0.5250, 0.5617, 0.5065, 0.5552, 0.5280,\n",
      "        0.5007], grad_fn=<CatBackward0>)\n",
      "var of recall: tensor(0.0005, grad_fn=<SubBackward0>)\n",
      "mean of recall tensor(0.5173, grad_fn=<MeanBackward0>)\n",
      "meta_loss: tensor(0.0005, grad_fn=<SubBackward0>)\n",
      "recall_true: tensor(0.4907)\n",
      "ENN_loss: tensor(0.0942, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0669, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0565, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0560, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0929, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0712, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0679, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0396, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1033, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0733, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0715, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0803, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0634, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0764, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0541, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0630, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0844, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0433, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0838, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0775, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0609, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0825, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0528, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0710, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0544, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1090, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0466, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0574, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0717, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0687, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0899, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0603, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0632, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0767, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0743, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0733, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0775, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0945, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0373, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0720, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0890, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0555, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0498, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1007, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0567, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0539, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0603, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0803, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0806, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0473, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0761, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0972, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0606, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0463, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0969, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0828, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0818, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0711, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0480, grad_fn=<MeanBackward0>)\n",
      "recall list tensor([0.5048, 0.5180, 0.4860, 0.5234, 0.4690, 0.5041, 0.5291, 0.5117, 0.5312,\n",
      "        0.5431, 0.5148, 0.4944, 0.5170, 0.4889, 0.4858, 0.5543, 0.5198, 0.5061,\n",
      "        0.5246, 0.4778, 0.4973, 0.4860, 0.5452, 0.5135, 0.5319, 0.5042, 0.5555,\n",
      "        0.5019, 0.5055, 0.4926, 0.5181, 0.4909, 0.5136, 0.5052, 0.5328, 0.5136,\n",
      "        0.5272, 0.5327, 0.5390, 0.4829, 0.5160, 0.5364, 0.5290, 0.5187, 0.5076,\n",
      "        0.5054, 0.5013, 0.5036, 0.5048, 0.5078, 0.5099, 0.5214, 0.5072, 0.4952,\n",
      "        0.5302, 0.5081, 0.4831, 0.5179, 0.4861, 0.5201, 0.5324, 0.4862, 0.5075,\n",
      "        0.5258, 0.5217, 0.4989, 0.4896, 0.5367, 0.4757, 0.5458, 0.5564, 0.4590,\n",
      "        0.5389, 0.5171, 0.5151, 0.5189, 0.5252, 0.4930, 0.5028, 0.5091, 0.5148,\n",
      "        0.5225, 0.5483, 0.5182, 0.5364, 0.5210, 0.5271, 0.5282, 0.5119, 0.4983,\n",
      "        0.4933, 0.5267, 0.5131, 0.5048, 0.5245, 0.5841, 0.4814, 0.5327, 0.4774,\n",
      "        0.5230], grad_fn=<CatBackward0>)\n",
      "var of recall: tensor(0.0004, grad_fn=<SubBackward0>)\n",
      "mean of recall tensor(0.5135, grad_fn=<MeanBackward0>)\n",
      "meta_loss: tensor(0.0004, grad_fn=<SubBackward0>)\n",
      "recall_true: tensor(0.4907)\n",
      "ENN_loss: tensor(0.0556, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0959, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0199, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0462, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0592, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0907, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0446, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0491, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0900, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0383, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0655, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0833, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0718, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0375, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0459, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0726, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0467, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0556, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0687, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0579, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0556, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0660, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0295, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0672, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0607, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0802, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0509, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0396, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0800, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0526, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0535, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0559, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0837, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0442, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0739, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0747, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0275, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0683, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0582, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0804, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0443, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0459, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0431, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0670, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0565, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0408, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0526, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0720, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0325, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0413, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0747, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0473, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0837, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0220, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0549, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0236, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0624, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0653, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0736, grad_fn=<MeanBackward0>)\n",
      "recall list tensor([0.5242, 0.5259, 0.4740, 0.4947, 0.4902, 0.5107, 0.5299, 0.5142, 0.4917,\n",
      "        0.5118, 0.5168, 0.5350, 0.4992, 0.5383, 0.5094, 0.5078, 0.4936, 0.5471,\n",
      "        0.4933, 0.4598, 0.5122, 0.5540, 0.4614, 0.5055, 0.5260, 0.5100, 0.4904,\n",
      "        0.4780, 0.4873, 0.5233, 0.5006, 0.5513, 0.4716, 0.5045, 0.4898, 0.5072,\n",
      "        0.5432, 0.5070, 0.4799, 0.5158, 0.5164, 0.4904, 0.5029, 0.4775, 0.5575,\n",
      "        0.5178, 0.4988, 0.4891, 0.4986, 0.5335, 0.5382, 0.5271, 0.4955, 0.5307,\n",
      "        0.4493, 0.4962, 0.5472, 0.5466, 0.5328, 0.5145, 0.5086, 0.4506, 0.5174,\n",
      "        0.5230, 0.4930, 0.4673, 0.4921, 0.4608, 0.5780, 0.5293, 0.5307, 0.5506,\n",
      "        0.5382, 0.5254, 0.5574, 0.5066, 0.5255, 0.4945, 0.5213, 0.5446, 0.5329,\n",
      "        0.4931, 0.4946, 0.4625, 0.4818, 0.5374, 0.4888, 0.5072, 0.4908, 0.5560,\n",
      "        0.4768, 0.5300, 0.5291, 0.5001, 0.5410, 0.5184, 0.4991, 0.5017, 0.5067,\n",
      "        0.4663], grad_fn=<CatBackward0>)\n",
      "var of recall: tensor(0.0007, grad_fn=<SubBackward0>)\n",
      "mean of recall tensor(0.5098, grad_fn=<MeanBackward0>)\n",
      "meta_loss: tensor(0.0007, grad_fn=<SubBackward0>)\n",
      "recall_true: tensor(0.4907)\n",
      "ENN_loss: tensor(0.0605, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0693, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0848, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0612, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0553, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0557, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0997, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0755, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0436, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0887, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0737, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0890, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0833, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0622, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0487, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0954, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0655, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0601, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0748, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0709, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0558, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0505, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0676, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1053, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0688, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0871, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0723, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0691, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0961, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0439, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0821, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0723, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0550, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0735, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0677, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0849, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0788, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0885, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0621, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0513, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0882, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0884, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0545, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0486, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0776, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0693, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0908, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0399, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0453, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0732, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0987, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0722, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1043, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0737, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0785, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0675, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0805, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0857, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0574, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0818, grad_fn=<MeanBackward0>)\n",
      "recall list tensor([0.5241, 0.5222, 0.5022, 0.5160, 0.5315, 0.4938, 0.5207, 0.5187, 0.5168,\n",
      "        0.5086, 0.5069, 0.5035, 0.5185, 0.5161, 0.5121, 0.5297, 0.5095, 0.5017,\n",
      "        0.5116, 0.4849, 0.5350, 0.5104, 0.4745, 0.4870, 0.5102, 0.5307, 0.4920,\n",
      "        0.5564, 0.4709, 0.5156, 0.5223, 0.4701, 0.5248, 0.5194, 0.5224, 0.4989,\n",
      "        0.5257, 0.5192, 0.5162, 0.5362, 0.4954, 0.5275, 0.5012, 0.5217, 0.5081,\n",
      "        0.5135, 0.4995, 0.5255, 0.5148, 0.5068, 0.5071, 0.4865, 0.5256, 0.4995,\n",
      "        0.5298, 0.5263, 0.4998, 0.5028, 0.5091, 0.4886, 0.5103, 0.5495, 0.4922,\n",
      "        0.4982, 0.5182, 0.5339, 0.5156, 0.5203, 0.5041, 0.5088, 0.5332, 0.4997,\n",
      "        0.5231, 0.5145, 0.5538, 0.4782, 0.5540, 0.5279, 0.5256, 0.5276, 0.5402,\n",
      "        0.5452, 0.5430, 0.5262, 0.4954, 0.5119, 0.5129, 0.5230, 0.5309, 0.5330,\n",
      "        0.5027, 0.5405, 0.5225, 0.5380, 0.5276, 0.5022, 0.4896, 0.5107, 0.5141,\n",
      "        0.5254], grad_fn=<CatBackward0>)\n",
      "var of recall: tensor(0.0003, grad_fn=<SubBackward0>)\n",
      "mean of recall tensor(0.5150, grad_fn=<MeanBackward0>)\n",
      "meta_loss: tensor(0.0003, grad_fn=<SubBackward0>)\n",
      "recall_true: tensor(0.4907)\n",
      "ENN_loss: tensor(0.0408, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0768, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0601, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0985, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0382, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0780, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0626, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0954, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0600, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0687, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0600, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0663, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0519, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0966, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0798, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0640, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0836, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0989, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0776, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0702, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0760, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0565, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0883, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0784, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0554, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0666, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0838, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0790, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0914, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0762, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0691, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0436, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0867, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1001, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0692, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0350, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0882, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0618, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0655, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0721, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0463, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0534, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0952, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0830, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0819, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0875, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0657, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0654, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0645, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0837, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0739, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0650, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0407, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0951, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0663, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0705, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0539, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0879, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0568, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0803, grad_fn=<MeanBackward0>)\n",
      "recall list tensor([0.5264, 0.5700, 0.5158, 0.4930, 0.5088, 0.5040, 0.5277, 0.4968, 0.4854,\n",
      "        0.5067, 0.4908, 0.5053, 0.5020, 0.5240, 0.4911, 0.5503, 0.5204, 0.5682,\n",
      "        0.5077, 0.5582, 0.5077, 0.5166, 0.5244, 0.5024, 0.5153, 0.5416, 0.4790,\n",
      "        0.4857, 0.5100, 0.5129, 0.5197, 0.5154, 0.5308, 0.4965, 0.5115, 0.5262,\n",
      "        0.5288, 0.5089, 0.5163, 0.5126, 0.5133, 0.5257, 0.5199, 0.5133, 0.5099,\n",
      "        0.5229, 0.5499, 0.5088, 0.5293, 0.5040, 0.5179, 0.5112, 0.5136, 0.5105,\n",
      "        0.4923, 0.5274, 0.5088, 0.5208, 0.4987, 0.4977, 0.4971, 0.5218, 0.5097,\n",
      "        0.5643, 0.5214, 0.4651, 0.5147, 0.5492, 0.5087, 0.5297, 0.5582, 0.5048,\n",
      "        0.5287, 0.5127, 0.5228, 0.5091, 0.5255, 0.5034, 0.4802, 0.5074, 0.5048,\n",
      "        0.4850, 0.5292, 0.5168, 0.4921, 0.5070, 0.4930, 0.5282, 0.5694, 0.5046,\n",
      "        0.5126, 0.4828, 0.5271, 0.5130, 0.5063, 0.5473, 0.5230, 0.4872, 0.5313,\n",
      "        0.5173], grad_fn=<CatBackward0>)\n",
      "var of recall: tensor(0.0004, grad_fn=<SubBackward0>)\n",
      "mean of recall tensor(0.5152, grad_fn=<MeanBackward0>)\n",
      "meta_loss: tensor(0.0004, grad_fn=<SubBackward0>)\n",
      "recall_true: tensor(0.4907)\n",
      "ENN_loss: tensor(0.0796, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0911, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0388, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0607, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0383, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1207, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0621, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0956, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1149, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0516, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0507, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0664, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0477, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1309, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0685, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0657, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0741, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1162, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0374, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0598, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0967, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0829, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0436, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0671, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0808, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0873, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0638, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0638, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0900, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0477, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0645, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0770, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0583, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0686, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0783, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0653, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0602, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0596, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0891, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0875, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0539, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0429, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0876, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0961, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0744, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0751, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0549, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0661, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0540, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0838, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0751, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0488, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0828, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0742, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0417, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0744, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0750, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0493, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1347, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0382, grad_fn=<MeanBackward0>)\n",
      "recall list tensor([0.5248, 0.5416, 0.5261, 0.5105, 0.4891, 0.5206, 0.5323, 0.4941, 0.4933,\n",
      "        0.5080, 0.5058, 0.5164, 0.5617, 0.5144, 0.5046, 0.5368, 0.5253, 0.5253,\n",
      "        0.5007, 0.5502, 0.5318, 0.5171, 0.5015, 0.4992, 0.5360, 0.5008, 0.5118,\n",
      "        0.5065, 0.5448, 0.5066, 0.5353, 0.4853, 0.5269, 0.5120, 0.5314, 0.5205,\n",
      "        0.5320, 0.4929, 0.5302, 0.5184, 0.5129, 0.5158, 0.5086, 0.4722, 0.5574,\n",
      "        0.5306, 0.4568, 0.5157, 0.5181, 0.5138, 0.5479, 0.5304, 0.4886, 0.4693,\n",
      "        0.5193, 0.4724, 0.5563, 0.5459, 0.5061, 0.5587, 0.5004, 0.5216, 0.5096,\n",
      "        0.5175, 0.5019, 0.5178, 0.5070, 0.4994, 0.4946, 0.5240, 0.5020, 0.5144,\n",
      "        0.4902, 0.5223, 0.5087, 0.5459, 0.5090, 0.5159, 0.5049, 0.5096, 0.5045,\n",
      "        0.5300, 0.5291, 0.5501, 0.5278, 0.4985, 0.5154, 0.5432, 0.5130, 0.5288,\n",
      "        0.4620, 0.5010, 0.5100, 0.4878, 0.5028, 0.5065, 0.4924, 0.5165, 0.5007,\n",
      "        0.5443], grad_fn=<CatBackward0>)\n",
      "var of recall: tensor(0.0004, grad_fn=<SubBackward0>)\n",
      "mean of recall tensor(0.5150, grad_fn=<MeanBackward0>)\n",
      "meta_loss: tensor(0.0004, grad_fn=<SubBackward0>)\n",
      "recall_true: tensor(0.4907)\n",
      "ENN_loss: tensor(0.0675, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0639, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0623, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0873, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0849, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0618, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0608, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0533, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0536, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0761, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0543, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1035, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1020, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0805, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0656, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0599, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0739, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0426, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0611, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1093, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0680, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0770, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0857, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0529, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0767, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0859, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0686, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0742, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0661, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0428, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0794, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1003, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0460, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0683, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0748, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0908, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0907, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0788, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0593, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0458, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0642, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1014, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0583, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0717, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0651, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0563, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0689, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0777, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0579, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0599, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0955, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0677, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0543, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1024, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0844, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0529, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0874, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0666, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0922, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0321, grad_fn=<MeanBackward0>)\n",
      "recall list tensor([0.5122, 0.5031, 0.5205, 0.5331, 0.4883, 0.5340, 0.5399, 0.5165, 0.5125,\n",
      "        0.5221, 0.4951, 0.5456, 0.5185, 0.5002, 0.4825, 0.5067, 0.5357, 0.5206,\n",
      "        0.5227, 0.5095, 0.5159, 0.5296, 0.5200, 0.5519, 0.5072, 0.5238, 0.5501,\n",
      "        0.4985, 0.5239, 0.5329, 0.5146, 0.5481, 0.5352, 0.5195, 0.5275, 0.5267,\n",
      "        0.5526, 0.5184, 0.5163, 0.4778, 0.5114, 0.5279, 0.5192, 0.4832, 0.5233,\n",
      "        0.4909, 0.5097, 0.5105, 0.4873, 0.5069, 0.4812, 0.5209, 0.5440, 0.5564,\n",
      "        0.4993, 0.5172, 0.5124, 0.5053, 0.5061, 0.5032, 0.5161, 0.5233, 0.5010,\n",
      "        0.5362, 0.5354, 0.5114, 0.4783, 0.5380, 0.5142, 0.5157, 0.5186, 0.4979,\n",
      "        0.4944, 0.5018, 0.4968, 0.4796, 0.5250, 0.5447, 0.5394, 0.4880, 0.5502,\n",
      "        0.5381, 0.4736, 0.5446, 0.5093, 0.5278, 0.5190, 0.5344, 0.5104, 0.4970,\n",
      "        0.4801, 0.5046, 0.5190, 0.4984, 0.5556, 0.5519, 0.4957, 0.5312, 0.5432,\n",
      "        0.5121], grad_fn=<CatBackward0>)\n",
      "var of recall: tensor(0.0004, grad_fn=<SubBackward0>)\n",
      "mean of recall tensor(0.5168, grad_fn=<MeanBackward0>)\n",
      "meta_loss: tensor(0.0004, grad_fn=<SubBackward0>)\n",
      "recall_true: tensor(0.4907)\n",
      "ENN_loss: tensor(0.0559, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0832, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0632, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0632, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0706, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0915, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0596, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0625, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0762, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0546, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0593, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0760, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0589, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1012, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0546, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0710, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0844, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0590, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0478, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0784, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0625, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0692, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0912, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0433, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0690, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0693, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0724, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0828, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0614, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0715, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0824, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0511, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0712, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0580, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0512, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0837, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0707, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0919, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0683, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0550, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0931, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0744, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0265, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0829, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0571, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0575, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0710, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0773, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0623, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0654, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0950, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0532, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0383, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0929, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0870, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0320, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0669, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0657, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0829, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0714, grad_fn=<MeanBackward0>)\n",
      "recall list tensor([0.5255, 0.5474, 0.4952, 0.4999, 0.5306, 0.5292, 0.5053, 0.5255, 0.5242,\n",
      "        0.5231, 0.5301, 0.5117, 0.5093, 0.4966, 0.5331, 0.4817, 0.4838, 0.5088,\n",
      "        0.4968, 0.5319, 0.5076, 0.5098, 0.5057, 0.5134, 0.5125, 0.5190, 0.5216,\n",
      "        0.4901, 0.5443, 0.5288, 0.4952, 0.5468, 0.4912, 0.4827, 0.5007, 0.4926,\n",
      "        0.5175, 0.5318, 0.5326, 0.5296, 0.5214, 0.5170, 0.5127, 0.5040, 0.5111,\n",
      "        0.5259, 0.4881, 0.5283, 0.5051, 0.4871, 0.5311, 0.5281, 0.5069, 0.5140,\n",
      "        0.5299, 0.5031, 0.5263, 0.5364, 0.5528, 0.5397, 0.5155, 0.5503, 0.4844,\n",
      "        0.5035, 0.5234, 0.4946, 0.5080, 0.5607, 0.5212, 0.5140, 0.5063, 0.5229,\n",
      "        0.5136, 0.5497, 0.4874, 0.5280, 0.5436, 0.5384, 0.5364, 0.5022, 0.5089,\n",
      "        0.5046, 0.5353, 0.4903, 0.5092, 0.5052, 0.5239, 0.5659, 0.5030, 0.5698,\n",
      "        0.5060, 0.5334, 0.5576, 0.5146, 0.5106, 0.5034, 0.5437, 0.5167, 0.4954,\n",
      "        0.4960], grad_fn=<CatBackward0>)\n",
      "var of recall: tensor(0.0004, grad_fn=<SubBackward0>)\n",
      "mean of recall tensor(0.5173, grad_fn=<MeanBackward0>)\n",
      "meta_loss: tensor(0.0004, grad_fn=<SubBackward0>)\n",
      "recall_true: tensor(0.4907)\n",
      "ENN_loss: tensor(0.0596, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1061, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0515, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0557, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0568, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0436, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1044, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0647, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0541, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0936, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0604, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0851, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0768, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1092, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0243, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0626, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1143, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0581, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0855, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0363, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0452, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1029, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0787, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0541, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0703, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0589, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0719, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0671, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0659, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0645, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0613, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0850, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0607, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1022, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0526, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0587, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0609, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0783, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0469, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0871, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0593, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0663, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0817, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0712, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1016, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0772, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0491, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0613, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0597, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0827, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0656, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0732, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0644, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0668, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0536, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0919, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0629, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0679, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0978, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0640, grad_fn=<MeanBackward0>)\n",
      "recall list tensor([0.4979, 0.5069, 0.5264, 0.4964, 0.5377, 0.4893, 0.5200, 0.5179, 0.5424,\n",
      "        0.5113, 0.5242, 0.5295, 0.5241, 0.5611, 0.5038, 0.5518, 0.4976, 0.5222,\n",
      "        0.5003, 0.5263, 0.5262, 0.5202, 0.5408, 0.5011, 0.5266, 0.5297, 0.5503,\n",
      "        0.4969, 0.5342, 0.5043, 0.5341, 0.4959, 0.4745, 0.5169, 0.5145, 0.5149,\n",
      "        0.4772, 0.5001, 0.5642, 0.5298, 0.4900, 0.4787, 0.4738, 0.5255, 0.5161,\n",
      "        0.5142, 0.5026, 0.5116, 0.5439, 0.5364, 0.5144, 0.5045, 0.5185, 0.5282,\n",
      "        0.5405, 0.5386, 0.4954, 0.5345, 0.4827, 0.5543, 0.5093, 0.5135, 0.5008,\n",
      "        0.4915, 0.5356, 0.5151, 0.5395, 0.5086, 0.5477, 0.4956, 0.4963, 0.5473,\n",
      "        0.5327, 0.5230, 0.4911, 0.5430, 0.5011, 0.5298, 0.4890, 0.5320, 0.5218,\n",
      "        0.4883, 0.5378, 0.5504, 0.4998, 0.5146, 0.5258, 0.5269, 0.5174, 0.5237,\n",
      "        0.5235, 0.5123, 0.5222, 0.4789, 0.5045, 0.5206, 0.5322, 0.5277, 0.4975,\n",
      "        0.5248], grad_fn=<CatBackward0>)\n",
      "var of recall: tensor(0.0004, grad_fn=<SubBackward0>)\n",
      "mean of recall tensor(0.5174, grad_fn=<MeanBackward0>)\n",
      "meta_loss: tensor(0.0004, grad_fn=<SubBackward0>)\n",
      "recall_true: tensor(0.4907)\n",
      "ENN_loss: tensor(0.0722, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0607, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0484, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0703, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0600, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0524, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0671, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0693, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0653, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0589, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0691, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0445, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0726, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0615, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0664, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0497, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0685, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0600, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0677, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0576, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0776, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0432, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0723, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0531, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0534, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0479, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0695, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0755, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0783, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0547, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0452, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0643, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0727, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0569, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0518, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0663, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0521, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0585, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0602, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0697, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0586, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0507, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0817, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0534, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0580, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0595, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0653, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0725, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0615, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0606, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0616, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0567, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0631, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0481, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0814, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0522, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0366, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0581, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0760, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0594, grad_fn=<MeanBackward0>)\n",
      "recall list tensor([0.5285, 0.4916, 0.5201, 0.5130, 0.5071, 0.4820, 0.5409, 0.4964, 0.4901,\n",
      "        0.5587, 0.5485, 0.4863, 0.5088, 0.4992, 0.5175, 0.4756, 0.5077, 0.5195,\n",
      "        0.5559, 0.4954, 0.4971, 0.5378, 0.5470, 0.5049, 0.4857, 0.4648, 0.5510,\n",
      "        0.5082, 0.4946, 0.5317, 0.5015, 0.5022, 0.5255, 0.5203, 0.5072, 0.4857,\n",
      "        0.5540, 0.5019, 0.5516, 0.4860, 0.5023, 0.4913, 0.5359, 0.5178, 0.4900,\n",
      "        0.5403, 0.4999, 0.5052, 0.5079, 0.5359, 0.4789, 0.5271, 0.5131, 0.5233,\n",
      "        0.5069, 0.4983, 0.5128, 0.4666, 0.4975, 0.4853, 0.5076, 0.4979, 0.5419,\n",
      "        0.5213, 0.4958, 0.4804, 0.4899, 0.5172, 0.4529, 0.5232, 0.5362, 0.4961,\n",
      "        0.5274, 0.4734, 0.5071, 0.4790, 0.4597, 0.5082, 0.4931, 0.4785, 0.5384,\n",
      "        0.5050, 0.5346, 0.5143, 0.5006, 0.4915, 0.5325, 0.5022, 0.5104, 0.5421,\n",
      "        0.5334, 0.5049, 0.5324, 0.5333, 0.5172, 0.5154, 0.5081, 0.5128, 0.4761,\n",
      "        0.4982], grad_fn=<CatBackward0>)\n",
      "var of recall: tensor(0.0005, grad_fn=<SubBackward0>)\n",
      "mean of recall tensor(0.5093, grad_fn=<MeanBackward0>)\n",
      "meta_loss: tensor(0.0005, grad_fn=<SubBackward0>)\n",
      "recall_true: tensor(0.4907)\n",
      "ENN_loss: tensor(0.0960, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0451, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0995, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0377, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0605, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0588, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0925, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0491, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0410, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0660, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0762, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0777, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0548, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0619, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0848, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0664, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0938, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1048, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0701, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0381, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0837, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0686, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0768, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0513, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0471, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0730, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0785, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0786, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0576, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0766, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0678, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0671, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0792, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0868, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0493, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0639, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0643, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0618, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0695, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0637, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0741, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0595, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0677, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0719, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1114, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0359, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0640, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0585, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0417, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0635, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0937, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0655, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0851, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0582, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0717, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0687, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0445, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1026, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0641, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0608, grad_fn=<MeanBackward0>)\n",
      "recall list tensor([0.5261, 0.5167, 0.5266, 0.5060, 0.5556, 0.5354, 0.4848, 0.5366, 0.5263,\n",
      "        0.5048, 0.5156, 0.5112, 0.5166, 0.5165, 0.4735, 0.4633, 0.5134, 0.5602,\n",
      "        0.5447, 0.5206, 0.5037, 0.4961, 0.5089, 0.4978, 0.5297, 0.4917, 0.5019,\n",
      "        0.4906, 0.4626, 0.5284, 0.4961, 0.4860, 0.5024, 0.4662, 0.4853, 0.5347,\n",
      "        0.4932, 0.4755, 0.5424, 0.5023, 0.5334, 0.5048, 0.5218, 0.5151, 0.5174,\n",
      "        0.5175, 0.5176, 0.5530, 0.5339, 0.5308, 0.5317, 0.4897, 0.5197, 0.5176,\n",
      "        0.5011, 0.5712, 0.5633, 0.5227, 0.5005, 0.4618, 0.4871, 0.5567, 0.5552,\n",
      "        0.4989, 0.5160, 0.5130, 0.5394, 0.4669, 0.5281, 0.5049, 0.5332, 0.5215,\n",
      "        0.4785, 0.5224, 0.5266, 0.5232, 0.4895, 0.4934, 0.5286, 0.5243, 0.5055,\n",
      "        0.5189, 0.5549, 0.5049, 0.4922, 0.4980, 0.5270, 0.5332, 0.5116, 0.4856,\n",
      "        0.5110, 0.5439, 0.5008, 0.5157, 0.5090, 0.4915, 0.5208, 0.5422, 0.5025,\n",
      "        0.4801], grad_fn=<CatBackward0>)\n",
      "var of recall: tensor(0.0006, grad_fn=<SubBackward0>)\n",
      "mean of recall tensor(0.5133, grad_fn=<MeanBackward0>)\n",
      "meta_loss: tensor(0.0006, grad_fn=<SubBackward0>)\n",
      "recall_true: tensor(0.4907)\n",
      "ENN_loss: tensor(0.0414, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0845, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0890, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0668, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0623, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0856, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0787, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0665, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0491, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1190, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0562, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0455, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0565, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0663, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0575, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0787, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0555, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0681, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0796, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0490, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0723, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0484, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0780, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0626, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0581, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0505, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0780, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0730, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0770, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0413, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0617, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0687, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0618, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0443, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0707, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0821, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0352, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0840, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0519, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0915, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0612, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0876, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0478, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0694, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0871, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0758, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0498, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0527, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0700, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0706, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0577, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0699, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0505, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0765, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0672, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0671, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0860, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0923, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0393, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0515, grad_fn=<MeanBackward0>)\n",
      "recall list tensor([0.4667, 0.5437, 0.5386, 0.5222, 0.5488, 0.4916, 0.5337, 0.5267, 0.4974,\n",
      "        0.4987, 0.5082, 0.5176, 0.5542, 0.5317, 0.5251, 0.4870, 0.5323, 0.5039,\n",
      "        0.5459, 0.5313, 0.5080, 0.4680, 0.4780, 0.4909, 0.4880, 0.4804, 0.5016,\n",
      "        0.4906, 0.5068, 0.5180, 0.5370, 0.5459, 0.4790, 0.5529, 0.5506, 0.5274,\n",
      "        0.5039, 0.5103, 0.5286, 0.5665, 0.5198, 0.4959, 0.5014, 0.4963, 0.5196,\n",
      "        0.5692, 0.5319, 0.4829, 0.5366, 0.4836, 0.5075, 0.4895, 0.5233, 0.5266,\n",
      "        0.5142, 0.4920, 0.5324, 0.5218, 0.5539, 0.4905, 0.5214, 0.5075, 0.5056,\n",
      "        0.5183, 0.5134, 0.5336, 0.5520, 0.5231, 0.5089, 0.4970, 0.5387, 0.5249,\n",
      "        0.5555, 0.5003, 0.5371, 0.5190, 0.5290, 0.4724, 0.4945, 0.5015, 0.5158,\n",
      "        0.5175, 0.5557, 0.5179, 0.5263, 0.4725, 0.4890, 0.5251, 0.5440, 0.4961,\n",
      "        0.5525, 0.4657, 0.5080, 0.5285, 0.5014, 0.4937, 0.5311, 0.5562, 0.5238,\n",
      "        0.5088], grad_fn=<CatBackward0>)\n",
      "var of recall: tensor(0.0006, grad_fn=<SubBackward0>)\n",
      "mean of recall tensor(0.5161, grad_fn=<MeanBackward0>)\n",
      "meta_loss: tensor(0.0006, grad_fn=<SubBackward0>)\n",
      "recall_true: tensor(0.4907)\n",
      "ENN_loss: tensor(0.0672, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0682, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0719, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0675, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0836, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0577, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0814, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1003, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0600, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0858, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0515, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1059, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0886, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0717, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0576, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0397, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0816, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0735, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0771, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0473, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0978, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0565, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0834, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0405, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0622, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0671, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0897, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0778, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0806, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0785, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0445, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0670, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0525, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0744, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0777, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0844, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0731, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0697, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0706, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0665, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0710, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0477, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0867, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0788, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0556, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0622, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0571, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0942, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0656, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0502, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0777, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0750, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0891, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0647, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0522, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0964, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0837, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0726, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0749, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0500, grad_fn=<MeanBackward0>)\n",
      "recall list tensor([0.5374, 0.5219, 0.5096, 0.5362, 0.5230, 0.5357, 0.5271, 0.5288, 0.5634,\n",
      "        0.5402, 0.5375, 0.5081, 0.5228, 0.5246, 0.5416, 0.5176, 0.5409, 0.5064,\n",
      "        0.5183, 0.4990, 0.5081, 0.5442, 0.5305, 0.5267, 0.5186, 0.4893, 0.4928,\n",
      "        0.5009, 0.4850, 0.5262, 0.5288, 0.4911, 0.5041, 0.4818, 0.5533, 0.5097,\n",
      "        0.5370, 0.5026, 0.5208, 0.5435, 0.4971, 0.4982, 0.5386, 0.5343, 0.5149,\n",
      "        0.5122, 0.5568, 0.5125, 0.5194, 0.5070, 0.4615, 0.5203, 0.5334, 0.5196,\n",
      "        0.4580, 0.5509, 0.4840, 0.4928, 0.5005, 0.5203, 0.5153, 0.5375, 0.5292,\n",
      "        0.5436, 0.4927, 0.5266, 0.5283, 0.5323, 0.5080, 0.5117, 0.5235, 0.5075,\n",
      "        0.5065, 0.5262, 0.5001, 0.5369, 0.5203, 0.5185, 0.5509, 0.5178, 0.4750,\n",
      "        0.5262, 0.5181, 0.5351, 0.5328, 0.5060, 0.5228, 0.5432, 0.5320, 0.5269,\n",
      "        0.5457, 0.5476, 0.5177, 0.5192, 0.4941, 0.5369, 0.5309, 0.5257, 0.5319,\n",
      "        0.4938], grad_fn=<CatBackward0>)\n",
      "var of recall: tensor(0.0004, grad_fn=<SubBackward0>)\n",
      "mean of recall tensor(0.5196, grad_fn=<MeanBackward0>)\n",
      "meta_loss: tensor(0.0004, grad_fn=<SubBackward0>)\n",
      "recall_true: tensor(0.4907)\n",
      "ENN_loss: tensor(0.0444, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0709, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0672, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0530, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0720, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0577, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0549, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0704, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0795, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0524, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0562, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0911, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0717, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0755, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0557, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0586, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0656, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0479, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0582, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0626, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0765, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0462, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0379, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0746, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0732, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0334, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0742, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0652, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0375, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0559, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0769, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0716, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0645, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0972, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0262, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0696, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0770, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0879, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0415, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0433, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0640, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0304, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1103, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0528, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0937, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0442, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0419, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0649, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0824, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0509, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0504, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0665, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0624, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0820, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0495, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0682, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0661, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0683, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0646, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0421, grad_fn=<MeanBackward0>)\n",
      "recall list tensor([0.5372, 0.5165, 0.5013, 0.5273, 0.5539, 0.5069, 0.5225, 0.5352, 0.5100,\n",
      "        0.5412, 0.5276, 0.5232, 0.5377, 0.5058, 0.5542, 0.5173, 0.5165, 0.5094,\n",
      "        0.5384, 0.5443, 0.5330, 0.5252, 0.5113, 0.5362, 0.5037, 0.4977, 0.5259,\n",
      "        0.4967, 0.4986, 0.5060, 0.4733, 0.5300, 0.5231, 0.4949, 0.4925, 0.4798,\n",
      "        0.5270, 0.5319, 0.5059, 0.5107, 0.5156, 0.4891, 0.5615, 0.5114, 0.4910,\n",
      "        0.4926, 0.5022, 0.5482, 0.5512, 0.5241, 0.5261, 0.5316, 0.5317, 0.5188,\n",
      "        0.4944, 0.4695, 0.4832, 0.5268, 0.5458, 0.5223, 0.5054, 0.5138, 0.5076,\n",
      "        0.5318, 0.5326, 0.5553, 0.4892, 0.4733, 0.5132, 0.4980, 0.5321, 0.4848,\n",
      "        0.5317, 0.5187, 0.4772, 0.5542, 0.5188, 0.5041, 0.5076, 0.5693, 0.4737,\n",
      "        0.4631, 0.5259, 0.5631, 0.5494, 0.5232, 0.5288, 0.5168, 0.5403, 0.5016,\n",
      "        0.5133, 0.5591, 0.5058, 0.4838, 0.5238, 0.5163, 0.5122, 0.5498, 0.5180,\n",
      "        0.5243], grad_fn=<CatBackward0>)\n",
      "var of recall: tensor(0.0005, grad_fn=<SubBackward0>)\n",
      "mean of recall tensor(0.5178, grad_fn=<MeanBackward0>)\n",
      "meta_loss: tensor(0.0005, grad_fn=<SubBackward0>)\n",
      "recall_true: tensor(0.4907)\n",
      "ENN_loss: tensor(0.0610, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0355, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0836, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0607, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0796, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0605, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0550, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0698, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0680, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0730, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0372, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0780, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0440, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0735, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0834, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0480, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0593, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0690, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0743, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0470, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0802, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0519, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0880, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0721, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0549, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0472, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0749, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0579, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0565, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0626, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0589, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0774, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0647, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0540, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0477, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0535, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0657, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0476, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0883, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0464, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0783, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0683, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0506, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0977, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0404, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0518, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0671, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0563, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0487, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0766, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0598, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0362, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1070, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0533, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0674, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0708, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0540, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0800, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0626, grad_fn=<MeanBackward0>)\n",
      "recall list tensor([0.5487, 0.4983, 0.5262, 0.4966, 0.5201, 0.5463, 0.5354, 0.4867, 0.4537,\n",
      "        0.5207, 0.5631, 0.4671, 0.5300, 0.5430, 0.5093, 0.4955, 0.5378, 0.5184,\n",
      "        0.5319, 0.5296, 0.4951, 0.4956, 0.5355, 0.5587, 0.5147, 0.4996, 0.5387,\n",
      "        0.5651, 0.5052, 0.5245, 0.5015, 0.5286, 0.5317, 0.5292, 0.5514, 0.5100,\n",
      "        0.4916, 0.5546, 0.5309, 0.5102, 0.4775, 0.4684, 0.5154, 0.5114, 0.5400,\n",
      "        0.5093, 0.5103, 0.5325, 0.4785, 0.5026, 0.4803, 0.4888, 0.5038, 0.5109,\n",
      "        0.5035, 0.5134, 0.4857, 0.4890, 0.5293, 0.5299, 0.4665, 0.5392, 0.5187,\n",
      "        0.4963, 0.5160, 0.4898, 0.5215, 0.4871, 0.5423, 0.5018, 0.4992, 0.5309,\n",
      "        0.5021, 0.5015, 0.5162, 0.5097, 0.5276, 0.4979, 0.5589, 0.5476, 0.5394,\n",
      "        0.5153, 0.5271, 0.5450, 0.5556, 0.4904, 0.4623, 0.4929, 0.5243, 0.5210,\n",
      "        0.5218, 0.4582, 0.4962, 0.4530, 0.5312, 0.5035, 0.5407, 0.5443, 0.5200,\n",
      "        0.5253], grad_fn=<CatBackward0>)\n",
      "var of recall: tensor(0.0006, grad_fn=<SubBackward0>)\n",
      "mean of recall tensor(0.5145, grad_fn=<MeanBackward0>)\n",
      "meta_loss: tensor(0.0006, grad_fn=<SubBackward0>)\n",
      "recall_true: tensor(0.4907)\n",
      "ENN_loss: tensor(0.0694, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0737, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0831, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0969, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0564, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0779, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0610, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0750, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0504, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0843, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0871, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0789, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0698, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0986, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0797, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0874, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0661, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0662, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1236, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0765, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0937, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0644, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0788, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0604, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0489, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0785, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0613, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1087, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0618, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0978, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0661, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0599, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0625, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0863, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0498, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0813, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0932, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0749, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0618, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0415, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0566, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0854, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0699, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0651, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0492, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0518, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0768, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0837, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0582, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0800, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0878, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0722, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0707, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0642, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0757, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0693, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0710, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0706, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0704, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0543, grad_fn=<MeanBackward0>)\n",
      "recall list tensor([0.5135, 0.5239, 0.5050, 0.5431, 0.5108, 0.4951, 0.4959, 0.5232, 0.4878,\n",
      "        0.5015, 0.5363, 0.5144, 0.5074, 0.4534, 0.5037, 0.5028, 0.5120, 0.5349,\n",
      "        0.5220, 0.4953, 0.5119, 0.5112, 0.5675, 0.5420, 0.5135, 0.4815, 0.5103,\n",
      "        0.5014, 0.5092, 0.5156, 0.4936, 0.5063, 0.5199, 0.5237, 0.5133, 0.5255,\n",
      "        0.5129, 0.5175, 0.4858, 0.5093, 0.5021, 0.5366, 0.5196, 0.5047, 0.5126,\n",
      "        0.5160, 0.5091, 0.5355, 0.5093, 0.5120, 0.5145, 0.5440, 0.5170, 0.4868,\n",
      "        0.5069, 0.4767, 0.5032, 0.5291, 0.4783, 0.5117, 0.5135, 0.5172, 0.5235,\n",
      "        0.5058, 0.5107, 0.5032, 0.5286, 0.5231, 0.5353, 0.4632, 0.5166, 0.4932,\n",
      "        0.5073, 0.5446, 0.5554, 0.4834, 0.5242, 0.5305, 0.5116, 0.5130, 0.5051,\n",
      "        0.5150, 0.5259, 0.5689, 0.5094, 0.5444, 0.5331, 0.4810, 0.5235, 0.5352,\n",
      "        0.5307, 0.5223, 0.5212, 0.4996, 0.5535, 0.5351, 0.5037, 0.5141, 0.5375,\n",
      "        0.4890], grad_fn=<CatBackward0>)\n",
      "var of recall: tensor(0.0004, grad_fn=<SubBackward0>)\n",
      "mean of recall tensor(0.5143, grad_fn=<MeanBackward0>)\n",
      "meta_loss: tensor(0.0004, grad_fn=<SubBackward0>)\n",
      "recall_true: tensor(0.4907)\n",
      "ENN_loss: tensor(0.0947, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0477, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0905, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0494, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0625, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0743, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0811, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0606, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0849, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0552, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0401, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1026, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0662, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0819, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0751, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0536, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0776, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0598, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0709, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0633, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0866, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0689, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0466, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0793, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0704, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0747, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0773, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0696, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0770, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0650, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0758, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0500, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0763, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0651, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0584, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0690, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0562, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0711, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0740, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0733, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0678, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0620, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0488, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0799, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0546, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0619, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1239, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0639, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0668, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0701, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0509, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0819, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0652, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0847, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0816, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0557, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0633, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0719, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0759, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0660, grad_fn=<MeanBackward0>)\n",
      "recall list tensor([0.5270, 0.5140, 0.5237, 0.5498, 0.5164, 0.5121, 0.5226, 0.5154, 0.5293,\n",
      "        0.4959, 0.5057, 0.4898, 0.5461, 0.4962, 0.5371, 0.4796, 0.5357, 0.5167,\n",
      "        0.5068, 0.5208, 0.5081, 0.5108, 0.5548, 0.5225, 0.5045, 0.4968, 0.4825,\n",
      "        0.5436, 0.4937, 0.5117, 0.5244, 0.5310, 0.5107, 0.5208, 0.5061, 0.4998,\n",
      "        0.5216, 0.4951, 0.5348, 0.5305, 0.5327, 0.4877, 0.5086, 0.5153, 0.5260,\n",
      "        0.4978, 0.4608, 0.5475, 0.5231, 0.5095, 0.5407, 0.5124, 0.4916, 0.5066,\n",
      "        0.4996, 0.5526, 0.5259, 0.4793, 0.5006, 0.5269, 0.4925, 0.5342, 0.5329,\n",
      "        0.5219, 0.5331, 0.5209, 0.5132, 0.5257, 0.5274, 0.5161, 0.5432, 0.5145,\n",
      "        0.5256, 0.4974, 0.5333, 0.5235, 0.5006, 0.5454, 0.5357, 0.5253, 0.5074,\n",
      "        0.5178, 0.5096, 0.5228, 0.5295, 0.4849, 0.5240, 0.5057, 0.5211, 0.5414,\n",
      "        0.5382, 0.5412, 0.5311, 0.4969, 0.4990, 0.5237, 0.5045, 0.5274, 0.5114,\n",
      "        0.4836], grad_fn=<CatBackward0>)\n",
      "var of recall: tensor(0.0003, grad_fn=<SubBackward0>)\n",
      "mean of recall tensor(0.5167, grad_fn=<MeanBackward0>)\n",
      "meta_loss: tensor(0.0003, grad_fn=<SubBackward0>)\n",
      "recall_true: tensor(0.4907)\n",
      "ENN_loss: tensor(0.0470, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0932, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0537, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0632, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0458, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0545, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0918, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0850, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0869, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0799, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0440, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0635, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0563, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0893, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0846, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0373, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0818, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0692, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0472, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0666, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0425, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0793, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0675, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0565, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0622, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0729, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0689, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0637, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0713, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0523, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0594, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0772, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0496, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0833, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0655, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0685, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0345, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0720, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0592, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0939, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0605, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0488, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0644, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0802, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0666, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0420, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0646, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0766, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0790, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0669, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0725, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0525, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0762, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0527, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0442, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0815, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0628, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0705, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0507, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0820, grad_fn=<MeanBackward0>)\n",
      "recall list tensor([0.5398, 0.5008, 0.4864, 0.5066, 0.5012, 0.4881, 0.5138, 0.4755, 0.5107,\n",
      "        0.4778, 0.4672, 0.5017, 0.5020, 0.5297, 0.5116, 0.4768, 0.4883, 0.4963,\n",
      "        0.5135, 0.4962, 0.5320, 0.5144, 0.5530, 0.4948, 0.5600, 0.5443, 0.5373,\n",
      "        0.5325, 0.4883, 0.5082, 0.5167, 0.5387, 0.4865, 0.5312, 0.5048, 0.4929,\n",
      "        0.5213, 0.5664, 0.4969, 0.5255, 0.5569, 0.4916, 0.4959, 0.5459, 0.4959,\n",
      "        0.5238, 0.4913, 0.4932, 0.5307, 0.5044, 0.4939, 0.4834, 0.5120, 0.5073,\n",
      "        0.5223, 0.5311, 0.5031, 0.4508, 0.5304, 0.4851, 0.5559, 0.4905, 0.5184,\n",
      "        0.5335, 0.4995, 0.5049, 0.5610, 0.4958, 0.4970, 0.5376, 0.5074, 0.5168,\n",
      "        0.4962, 0.5375, 0.5023, 0.5412, 0.4883, 0.4994, 0.4753, 0.5296, 0.5329,\n",
      "        0.5216, 0.5605, 0.5363, 0.5164, 0.5290, 0.5388, 0.5257, 0.5240, 0.5393,\n",
      "        0.5525, 0.5104, 0.5564, 0.4834, 0.4911, 0.5770, 0.4838, 0.5341, 0.4662,\n",
      "        0.5102], grad_fn=<CatBackward0>)\n",
      "var of recall: tensor(0.0006, grad_fn=<SubBackward0>)\n",
      "mean of recall tensor(0.5136, grad_fn=<MeanBackward0>)\n",
      "meta_loss: tensor(0.0006, grad_fn=<SubBackward0>)\n",
      "recall_true: tensor(0.4907)\n",
      "ENN_loss: tensor(0.0754, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0677, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0538, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0364, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0660, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0678, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0715, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0469, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0681, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0453, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0760, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0726, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0599, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0947, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0652, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0384, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0527, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0737, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0885, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0551, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0710, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0541, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0711, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0350, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1039, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0670, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0358, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0487, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0778, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1267, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0581, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0191, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0740, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0616, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0704, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0620, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0297, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0516, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0796, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1247, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0905, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0607, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0751, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0312, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0369, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0487, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0563, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1186, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0692, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0241, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0821, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0595, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0640, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0869, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0521, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0573, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0931, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0380, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0875, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0519, grad_fn=<MeanBackward0>)\n",
      "recall list tensor([0.5310, 0.4839, 0.4788, 0.5029, 0.5067, 0.5464, 0.5313, 0.5264, 0.5559,\n",
      "        0.5404, 0.4726, 0.5161, 0.4774, 0.4896, 0.5400, 0.5112, 0.5443, 0.5019,\n",
      "        0.5020, 0.4914, 0.5437, 0.5269, 0.5437, 0.4922, 0.5053, 0.5310, 0.5355,\n",
      "        0.5416, 0.4863, 0.5102, 0.5570, 0.5551, 0.5088, 0.5193, 0.5518, 0.4996,\n",
      "        0.4981, 0.5455, 0.5223, 0.5301, 0.4862, 0.5054, 0.5144, 0.5348, 0.4840,\n",
      "        0.5502, 0.4788, 0.5800, 0.4975, 0.4933, 0.5311, 0.5373, 0.5500, 0.5112,\n",
      "        0.5006, 0.5250, 0.5174, 0.5083, 0.4767, 0.5351, 0.4946, 0.5525, 0.5260,\n",
      "        0.4869, 0.4767, 0.5254, 0.5491, 0.5597, 0.5069, 0.5382, 0.5062, 0.4590,\n",
      "        0.5210, 0.4889, 0.5303, 0.5578, 0.5249, 0.5286, 0.4296, 0.5162, 0.4813,\n",
      "        0.5545, 0.5167, 0.5306, 0.5029, 0.5106, 0.5411, 0.4883, 0.5033, 0.5279,\n",
      "        0.5161, 0.5074, 0.4962, 0.5584, 0.5047, 0.5210, 0.5206, 0.5657, 0.5116,\n",
      "        0.5219], grad_fn=<CatBackward0>)\n",
      "var of recall: tensor(0.0007, grad_fn=<SubBackward0>)\n",
      "mean of recall tensor(0.5173, grad_fn=<MeanBackward0>)\n",
      "meta_loss: tensor(0.0007, grad_fn=<SubBackward0>)\n",
      "recall_true: tensor(0.4907)\n",
      "ENN_loss: tensor(0.0830, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0571, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1042, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0430, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0398, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0845, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0637, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0689, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0577, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0830, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0571, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0667, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0710, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0658, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0625, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0575, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0658, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0418, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0677, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0807, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0805, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0488, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0470, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0686, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0519, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0528, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0742, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0687, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0607, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0727, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0579, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0612, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0647, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0855, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0727, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0393, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0459, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0659, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0902, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0636, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0546, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0861, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0452, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0568, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0485, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0460, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0960, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0641, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0876, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0524, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0403, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0733, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0716, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0461, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0825, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0530, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0813, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0555, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0596, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0617, grad_fn=<MeanBackward0>)\n",
      "recall list tensor([0.5190, 0.4888, 0.5119, 0.5393, 0.5145, 0.4820, 0.5463, 0.5127, 0.5144,\n",
      "        0.5334, 0.5099, 0.5014, 0.4952, 0.4770, 0.5058, 0.4987, 0.5052, 0.5657,\n",
      "        0.5227, 0.4688, 0.4772, 0.5571, 0.4941, 0.4772, 0.4861, 0.5147, 0.4812,\n",
      "        0.5411, 0.5350, 0.4879, 0.5295, 0.5217, 0.5215, 0.5087, 0.5497, 0.4810,\n",
      "        0.5609, 0.4959, 0.5211, 0.5464, 0.5077, 0.5066, 0.5258, 0.5583, 0.4949,\n",
      "        0.4953, 0.5705, 0.4968, 0.5193, 0.5144, 0.5520, 0.5134, 0.5562, 0.5055,\n",
      "        0.5348, 0.4872, 0.4898, 0.5031, 0.5492, 0.4808, 0.5500, 0.5309, 0.5028,\n",
      "        0.5222, 0.5479, 0.5372, 0.5087, 0.4782, 0.5468, 0.5563, 0.5196, 0.5281,\n",
      "        0.5493, 0.5368, 0.5171, 0.5058, 0.5179, 0.5436, 0.5079, 0.4990, 0.5120,\n",
      "        0.5022, 0.5243, 0.5018, 0.5525, 0.5225, 0.5349, 0.5611, 0.5043, 0.4864,\n",
      "        0.4365, 0.5253, 0.4859, 0.5584, 0.5119, 0.4918, 0.5185, 0.5387, 0.5270,\n",
      "        0.5405], grad_fn=<CatBackward0>)\n",
      "var of recall: tensor(0.0007, grad_fn=<SubBackward0>)\n",
      "mean of recall tensor(0.5170, grad_fn=<MeanBackward0>)\n",
      "meta_loss: tensor(0.0007, grad_fn=<SubBackward0>)\n",
      "recall_true: tensor(0.4907)\n",
      "ENN_loss: tensor(0.0666, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0809, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0642, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0692, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0252, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0831, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0997, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1151, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0632, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0643, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0600, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0839, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0898, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0652, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0515, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0797, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0704, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0690, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1177, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1043, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0574, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0978, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0690, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0612, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0508, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0649, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0874, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0846, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1000, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0884, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0645, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0482, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0691, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0627, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0890, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0499, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0585, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0381, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1038, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0534, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0626, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0745, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0633, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0848, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1044, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0482, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0521, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0689, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0787, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0601, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0839, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0622, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0571, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0342, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0920, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0842, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0663, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0740, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0654, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0695, grad_fn=<MeanBackward0>)\n",
      "recall list tensor([0.5195, 0.5042, 0.5089, 0.5017, 0.5211, 0.4933, 0.5041, 0.5160, 0.4860,\n",
      "        0.5271, 0.4991, 0.5101, 0.5122, 0.5198, 0.5298, 0.5024, 0.5370, 0.5282,\n",
      "        0.5069, 0.5070, 0.5316, 0.5128, 0.5070, 0.4882, 0.5077, 0.5179, 0.5344,\n",
      "        0.4943, 0.4877, 0.5075, 0.4621, 0.5283, 0.4872, 0.5373, 0.5472, 0.5189,\n",
      "        0.5248, 0.5592, 0.5356, 0.5069, 0.5320, 0.5255, 0.5347, 0.5148, 0.5231,\n",
      "        0.5281, 0.5471, 0.5195, 0.5032, 0.5389, 0.5301, 0.5168, 0.5206, 0.5180,\n",
      "        0.5112, 0.5378, 0.5498, 0.5311, 0.5299, 0.5016, 0.5121, 0.5101, 0.5253,\n",
      "        0.5458, 0.5334, 0.5220, 0.5255, 0.4717, 0.5058, 0.5457, 0.5201, 0.4988,\n",
      "        0.5072, 0.5424, 0.5112, 0.5156, 0.4958, 0.4793, 0.5033, 0.5040, 0.4868,\n",
      "        0.4783, 0.5316, 0.5259, 0.5070, 0.4923, 0.5088, 0.4816, 0.5396, 0.5258,\n",
      "        0.5430, 0.5447, 0.5303, 0.4993, 0.5234, 0.5055, 0.5007, 0.5238, 0.5177,\n",
      "        0.5157], grad_fn=<CatBackward0>)\n",
      "var of recall: tensor(0.0003, grad_fn=<SubBackward0>)\n",
      "mean of recall tensor(0.5160, grad_fn=<MeanBackward0>)\n",
      "meta_loss: tensor(0.0003, grad_fn=<SubBackward0>)\n",
      "recall_true: tensor(0.4907)\n",
      "ENN_loss: tensor(0.0584, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0702, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0589, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0781, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0760, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0706, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0424, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0882, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0752, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0358, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0793, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0689, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0817, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0828, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0468, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0589, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0478, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0578, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0662, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0937, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0619, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0499, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0525, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1031, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0896, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0515, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0724, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0488, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0702, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0717, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0641, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0653, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0851, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0770, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0782, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0617, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0579, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0770, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0777, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0668, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0783, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0434, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0840, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0736, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0462, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0684, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0881, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0666, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0621, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0418, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0964, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0546, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0771, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0533, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0812, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0684, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0670, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0603, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0857, grad_fn=<MeanBackward0>)\n",
      "recall list tensor([0.4752, 0.5202, 0.5555, 0.4920, 0.5275, 0.5011, 0.5442, 0.5512, 0.5458,\n",
      "        0.5050, 0.4827, 0.5384, 0.5319, 0.4833, 0.5195, 0.5282, 0.5009, 0.4818,\n",
      "        0.4894, 0.5361, 0.5165, 0.4896, 0.5052, 0.4944, 0.5281, 0.5429, 0.5290,\n",
      "        0.5171, 0.5303, 0.5123, 0.5138, 0.5131, 0.5081, 0.5159, 0.4461, 0.5235,\n",
      "        0.4779, 0.5198, 0.5499, 0.5018, 0.4901, 0.5197, 0.5282, 0.5492, 0.4881,\n",
      "        0.5226, 0.5388, 0.5434, 0.4804, 0.5336, 0.5254, 0.4983, 0.5000, 0.5459,\n",
      "        0.5157, 0.5304, 0.5277, 0.4987, 0.5042, 0.5175, 0.5183, 0.4973, 0.5046,\n",
      "        0.5123, 0.5441, 0.5168, 0.5088, 0.4892, 0.5160, 0.5020, 0.4769, 0.5235,\n",
      "        0.5422, 0.5388, 0.4986, 0.5413, 0.5426, 0.5202, 0.4546, 0.5394, 0.5269,\n",
      "        0.5133, 0.5073, 0.5278, 0.4722, 0.5015, 0.5046, 0.5495, 0.5261, 0.5194,\n",
      "        0.5225, 0.5537, 0.4982, 0.5402, 0.5034, 0.4937, 0.4543, 0.5181, 0.5158,\n",
      "        0.5019], grad_fn=<CatBackward0>)\n",
      "var of recall: tensor(0.0005, grad_fn=<SubBackward0>)\n",
      "mean of recall tensor(0.5144, grad_fn=<MeanBackward0>)\n",
      "meta_loss: tensor(0.0005, grad_fn=<SubBackward0>)\n",
      "recall_true: tensor(0.4907)\n",
      "ENN_loss: tensor(0.0862, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0608, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0791, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0697, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0821, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0636, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0530, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0713, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0522, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0869, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0656, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0833, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0991, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0630, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0671, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0725, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0692, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0674, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0559, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0909, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0740, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0669, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0689, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0618, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0590, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0609, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1108, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0696, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0659, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0800, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0639, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0728, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0998, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0798, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0655, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0447, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0674, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0867, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0661, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0636, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0586, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0574, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0732, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0855, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0670, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0887, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0618, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0722, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0614, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1112, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0592, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0651, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0633, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0638, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0710, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0795, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0593, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0545, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0884, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0888, grad_fn=<MeanBackward0>)\n",
      "recall list tensor([0.5509, 0.5155, 0.5380, 0.5251, 0.5016, 0.5148, 0.4892, 0.4951, 0.5065,\n",
      "        0.5402, 0.5245, 0.5063, 0.4848, 0.4986, 0.4989, 0.5231, 0.5290, 0.4946,\n",
      "        0.5305, 0.4866, 0.5185, 0.5002, 0.5046, 0.5071, 0.5322, 0.5132, 0.4963,\n",
      "        0.5149, 0.5472, 0.4969, 0.5351, 0.5152, 0.4885, 0.5435, 0.5232, 0.4964,\n",
      "        0.5382, 0.5368, 0.4953, 0.5616, 0.5118, 0.5326, 0.5228, 0.5181, 0.4998,\n",
      "        0.5037, 0.4739, 0.5093, 0.5112, 0.5285, 0.4906, 0.5290, 0.4560, 0.5512,\n",
      "        0.5004, 0.5050, 0.5181, 0.5151, 0.5729, 0.5011, 0.5364, 0.5063, 0.5079,\n",
      "        0.5366, 0.5337, 0.5311, 0.4954, 0.4958, 0.5204, 0.4951, 0.4913, 0.5381,\n",
      "        0.5242, 0.4856, 0.5125, 0.4833, 0.5281, 0.5357, 0.5378, 0.5267, 0.5382,\n",
      "        0.5199, 0.5366, 0.5132, 0.5401, 0.4972, 0.4704, 0.5164, 0.5232, 0.5249,\n",
      "        0.5062, 0.5490, 0.5203, 0.4951, 0.5130, 0.5140, 0.5172, 0.4914, 0.5323,\n",
      "        0.4745], grad_fn=<CatBackward0>)\n",
      "var of recall: tensor(0.0004, grad_fn=<SubBackward0>)\n",
      "mean of recall tensor(0.5148, grad_fn=<MeanBackward0>)\n",
      "meta_loss: tensor(0.0004, grad_fn=<SubBackward0>)\n",
      "recall_true: tensor(0.4907)\n",
      "ENN_loss: tensor(0.0708, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0588, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0751, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0843, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0536, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0820, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0826, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0666, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0761, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0723, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0623, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0798, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0842, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0540, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0577, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0723, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0492, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0707, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0619, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0923, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0394, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0764, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0940, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0569, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0726, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0662, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0562, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0827, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0562, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0932, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0727, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0502, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0740, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0711, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0630, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0686, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0593, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0680, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0716, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0790, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0702, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0670, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0496, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0797, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0468, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0653, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0825, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0773, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0639, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0715, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0674, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0671, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0761, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0477, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0578, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0876, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0617, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0440, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1231, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0670, grad_fn=<MeanBackward0>)\n",
      "recall list tensor([0.5190, 0.5040, 0.4974, 0.5364, 0.5341, 0.5239, 0.5244, 0.5007, 0.5377,\n",
      "        0.5445, 0.5000, 0.5230, 0.4971, 0.5448, 0.5146, 0.4938, 0.5008, 0.5265,\n",
      "        0.5057, 0.5403, 0.5427, 0.5136, 0.5349, 0.5275, 0.5149, 0.5152, 0.5580,\n",
      "        0.5224, 0.5172, 0.5030, 0.5262, 0.4976, 0.5080, 0.5012, 0.4928, 0.5335,\n",
      "        0.5148, 0.5249, 0.5269, 0.5076, 0.5360, 0.5182, 0.5204, 0.5302, 0.5323,\n",
      "        0.5207, 0.5346, 0.5245, 0.4931, 0.5251, 0.5205, 0.5154, 0.5320, 0.5177,\n",
      "        0.5068, 0.4972, 0.5435, 0.4949, 0.5306, 0.5080, 0.4868, 0.5326, 0.5125,\n",
      "        0.5366, 0.5089, 0.5083, 0.5088, 0.5298, 0.5130, 0.4999, 0.5221, 0.5328,\n",
      "        0.5155, 0.5612, 0.5042, 0.4977, 0.5463, 0.5410, 0.4997, 0.5708, 0.5011,\n",
      "        0.5060, 0.5319, 0.5307, 0.5265, 0.5133, 0.5204, 0.5124, 0.5252, 0.5187,\n",
      "        0.5125, 0.4896, 0.5108, 0.5574, 0.4925, 0.5133, 0.5087, 0.5087, 0.5658,\n",
      "        0.4765], grad_fn=<CatBackward0>)\n",
      "var of recall: tensor(0.0003, grad_fn=<SubBackward0>)\n",
      "mean of recall tensor(0.5190, grad_fn=<MeanBackward0>)\n",
      "meta_loss: tensor(0.0003, grad_fn=<SubBackward0>)\n",
      "recall_true: tensor(0.4907)\n",
      "ENN_loss: tensor(0.0795, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0668, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0627, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0681, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0565, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0512, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0737, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0817, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0598, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0329, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0835, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0844, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0620, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0370, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0794, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0849, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0585, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0760, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0447, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0787, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0659, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0513, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0965, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0503, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0571, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0543, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0834, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0712, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0570, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0695, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0777, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0533, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0710, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0542, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0810, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0547, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0600, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0741, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0869, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0509, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0713, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0675, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0767, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0468, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0590, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0297, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1122, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0528, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0472, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0450, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1023, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0769, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0426, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0732, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0842, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0953, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0547, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0976, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0678, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0642, grad_fn=<MeanBackward0>)\n",
      "recall list tensor([0.5535, 0.5270, 0.5303, 0.5369, 0.4800, 0.4952, 0.5380, 0.5063, 0.5179,\n",
      "        0.4945, 0.5082, 0.4907, 0.5109, 0.4996, 0.4954, 0.4855, 0.5090, 0.5257,\n",
      "        0.5266, 0.4968, 0.5113, 0.5021, 0.5050, 0.4955, 0.5216, 0.5462, 0.5232,\n",
      "        0.4876, 0.4993, 0.5248, 0.5365, 0.4863, 0.5191, 0.5328, 0.4909, 0.5156,\n",
      "        0.5219, 0.4791, 0.4804, 0.5522, 0.5482, 0.4997, 0.4785, 0.5344, 0.5278,\n",
      "        0.5104, 0.5240, 0.5183, 0.5662, 0.5517, 0.4895, 0.5433, 0.5352, 0.5349,\n",
      "        0.5228, 0.5313, 0.5039, 0.5172, 0.4801, 0.5342, 0.5272, 0.5223, 0.5031,\n",
      "        0.4928, 0.5050, 0.5377, 0.5208, 0.5490, 0.4923, 0.4930, 0.5332, 0.4930,\n",
      "        0.4906, 0.4964, 0.5587, 0.4975, 0.5338, 0.5244, 0.5077, 0.5408, 0.5040,\n",
      "        0.5080, 0.5109, 0.5362, 0.5108, 0.5263, 0.4932, 0.5122, 0.5365, 0.4960,\n",
      "        0.5105, 0.5487, 0.5245, 0.4983, 0.5326, 0.5168, 0.5466, 0.5047, 0.5160,\n",
      "        0.5219], grad_fn=<CatBackward0>)\n",
      "var of recall: tensor(0.0004, grad_fn=<SubBackward0>)\n",
      "mean of recall tensor(0.5159, grad_fn=<MeanBackward0>)\n",
      "meta_loss: tensor(0.0004, grad_fn=<SubBackward0>)\n",
      "recall_true: tensor(0.4907)\n",
      "ENN_loss: tensor(0.0585, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1092, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0940, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0775, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0541, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0812, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0546, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0856, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0703, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0426, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0715, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1084, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0723, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0719, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0521, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0863, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0648, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0774, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0693, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0659, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0626, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0821, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0614, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0725, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0799, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0975, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0302, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0828, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1120, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0279, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0802, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0637, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0658, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0377, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0721, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1026, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1067, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0537, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0545, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0692, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0543, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0917, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0696, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0762, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0569, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0625, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0839, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0779, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0620, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0605, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0620, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0963, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1015, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0481, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0830, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0419, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0565, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0894, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0560, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1125, grad_fn=<MeanBackward0>)\n",
      "recall list tensor([0.4916, 0.4960, 0.5305, 0.4949, 0.5136, 0.4916, 0.5282, 0.5127, 0.5058,\n",
      "        0.5359, 0.5177, 0.5012, 0.5128, 0.5334, 0.4957, 0.5213, 0.5242, 0.5166,\n",
      "        0.5418, 0.5201, 0.5179, 0.5025, 0.5300, 0.5033, 0.5227, 0.5036, 0.5262,\n",
      "        0.4938, 0.5102, 0.5021, 0.5167, 0.5102, 0.4965, 0.5110, 0.5289, 0.4893,\n",
      "        0.5100, 0.5099, 0.5313, 0.5291, 0.5162, 0.5040, 0.4861, 0.5108, 0.5144,\n",
      "        0.4994, 0.5423, 0.5146, 0.5409, 0.5047, 0.5176, 0.5070, 0.5252, 0.4970,\n",
      "        0.5124, 0.5021, 0.5369, 0.5043, 0.4761, 0.5134, 0.5246, 0.5146, 0.5023,\n",
      "        0.5373, 0.5445, 0.5300, 0.5428, 0.5247, 0.5153, 0.5272, 0.5111, 0.5290,\n",
      "        0.5202, 0.4984, 0.5146, 0.5113, 0.5078, 0.4949, 0.5227, 0.5199, 0.4961,\n",
      "        0.4915, 0.5082, 0.5177, 0.4997, 0.5018, 0.5288, 0.5031, 0.4911, 0.4951,\n",
      "        0.5163, 0.5026, 0.5467, 0.4894, 0.4977, 0.5261, 0.4980, 0.5345, 0.4914,\n",
      "        0.5068], grad_fn=<CatBackward0>)\n",
      "var of recall: tensor(0.0002, grad_fn=<SubBackward0>)\n",
      "mean of recall tensor(0.5129, grad_fn=<MeanBackward0>)\n",
      "meta_loss: tensor(0.0002, grad_fn=<SubBackward0>)\n",
      "recall_true: tensor(0.4907)\n",
      "ENN_loss: tensor(0.0812, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0553, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0522, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0731, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0485, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0672, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0578, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0523, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0527, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0653, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0528, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0626, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0609, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0445, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0539, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0539, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0397, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0605, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0450, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0691, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0411, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0732, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0523, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0615, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0662, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0477, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0542, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0634, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0707, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0501, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0480, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0734, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0471, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0804, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0439, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0602, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0616, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0651, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0589, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0341, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0654, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0453, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0687, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0460, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0455, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0739, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0553, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0458, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0524, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0667, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0411, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0849, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0609, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0340, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1079, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0366, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0607, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0589, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0484, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0608, grad_fn=<MeanBackward0>)\n",
      "recall list tensor([0.4925, 0.5353, 0.5007, 0.5000, 0.5070, 0.4882, 0.5279, 0.4668, 0.5458,\n",
      "        0.5286, 0.4750, 0.4877, 0.5364, 0.5391, 0.5845, 0.5673, 0.4884, 0.5372,\n",
      "        0.5316, 0.5142, 0.5690, 0.5229, 0.5126, 0.5204, 0.5159, 0.5292, 0.5604,\n",
      "        0.5037, 0.5190, 0.5057, 0.5432, 0.5419, 0.4956, 0.5030, 0.5127, 0.5654,\n",
      "        0.5830, 0.4748, 0.5146, 0.5310, 0.4814, 0.5075, 0.5289, 0.5353, 0.5575,\n",
      "        0.5616, 0.5235, 0.5284, 0.6184, 0.5461, 0.4934, 0.5427, 0.5074, 0.4968,\n",
      "        0.5397, 0.4798, 0.5390, 0.5360, 0.4500, 0.5368, 0.5291, 0.4966, 0.5371,\n",
      "        0.5282, 0.4972, 0.5052, 0.4829, 0.4951, 0.5646, 0.5461, 0.5434, 0.5027,\n",
      "        0.5189, 0.4876, 0.5093, 0.4615, 0.5079, 0.4809, 0.4730, 0.5277, 0.4676,\n",
      "        0.5360, 0.5214, 0.5534, 0.5489, 0.5214, 0.5353, 0.5425, 0.4867, 0.5225,\n",
      "        0.5016, 0.4806, 0.4771, 0.5084, 0.4679, 0.5219, 0.5159, 0.5595, 0.5371,\n",
      "        0.5303], grad_fn=<CatBackward0>)\n",
      "var of recall: tensor(0.0009, grad_fn=<SubBackward0>)\n",
      "mean of recall tensor(0.5192, grad_fn=<MeanBackward0>)\n",
      "meta_loss: tensor(0.0009, grad_fn=<SubBackward0>)\n",
      "recall_true: tensor(0.4907)\n",
      "ENN_loss: tensor(0.0801, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0533, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0608, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0519, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0672, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0676, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0465, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0470, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0747, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0509, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0507, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0460, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0653, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0505, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0598, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0583, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0511, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0608, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0807, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0450, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0754, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0194, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0621, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0745, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0452, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0560, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0566, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0568, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0474, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0572, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0568, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0471, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0682, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0551, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0760, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0325, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0340, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0636, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0749, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0551, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0589, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0384, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0352, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0863, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0439, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0568, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0705, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0725, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0759, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0457, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0404, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0794, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0267, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0502, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0721, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0661, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0617, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0817, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0355, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0467, grad_fn=<MeanBackward0>)\n",
      "recall list tensor([0.4649, 0.5068, 0.5184, 0.5467, 0.5270, 0.5312, 0.5075, 0.5299, 0.4925,\n",
      "        0.4806, 0.5155, 0.5056, 0.4929, 0.4978, 0.5295, 0.5273, 0.5422, 0.4978,\n",
      "        0.4952, 0.5283, 0.4599, 0.5243, 0.5042, 0.5321, 0.4631, 0.5030, 0.5167,\n",
      "        0.5719, 0.4972, 0.4545, 0.4820, 0.5159, 0.5527, 0.5416, 0.5352, 0.5409,\n",
      "        0.5107, 0.5023, 0.5349, 0.5007, 0.5390, 0.5619, 0.5248, 0.5708, 0.5236,\n",
      "        0.5479, 0.5121, 0.5268, 0.5755, 0.5386, 0.5019, 0.4602, 0.4583, 0.4950,\n",
      "        0.5668, 0.5178, 0.5348, 0.4674, 0.4886, 0.5245, 0.4830, 0.5243, 0.4516,\n",
      "        0.5115, 0.5199, 0.5190, 0.5121, 0.5056, 0.5184, 0.4525, 0.5559, 0.5022,\n",
      "        0.4887, 0.5500, 0.4767, 0.5070, 0.5325, 0.4914, 0.4860, 0.5082, 0.5520,\n",
      "        0.5674, 0.4885, 0.5354, 0.5264, 0.5355, 0.4729, 0.5122, 0.4881, 0.5735,\n",
      "        0.5741, 0.5298, 0.5178, 0.5490, 0.5312, 0.5493, 0.4910, 0.5279, 0.5814,\n",
      "        0.5154], grad_fn=<CatBackward0>)\n",
      "var of recall: tensor(0.0009, grad_fn=<SubBackward0>)\n",
      "mean of recall tensor(0.5163, grad_fn=<MeanBackward0>)\n",
      "meta_loss: tensor(0.0009, grad_fn=<SubBackward0>)\n",
      "recall_true: tensor(0.4907)\n",
      "ENN_loss: tensor(0.0514, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1218, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0714, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0952, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0714, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0695, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0934, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0587, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0584, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0884, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0659, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1100, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0765, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0667, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0670, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0648, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0883, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0483, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0796, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0504, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0863, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0500, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0683, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0965, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0765, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0661, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0596, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0594, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0706, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0664, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0718, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0681, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0634, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0808, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0382, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0750, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0969, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0505, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0658, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0767, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0540, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0419, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0970, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0739, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0671, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0673, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0718, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0917, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0578, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0552, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0898, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0608, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0683, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0706, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0492, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0680, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0684, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0541, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0644, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0704, grad_fn=<MeanBackward0>)\n",
      "recall list tensor([0.5177, 0.5387, 0.4961, 0.5274, 0.5129, 0.5142, 0.5122, 0.5254, 0.5094,\n",
      "        0.5371, 0.5088, 0.5311, 0.5077, 0.4957, 0.5011, 0.5046, 0.5120, 0.5025,\n",
      "        0.5232, 0.5084, 0.5054, 0.5426, 0.5174, 0.5477, 0.4969, 0.4974, 0.5236,\n",
      "        0.4798, 0.5182, 0.4895, 0.4985, 0.5167, 0.5251, 0.5227, 0.5389, 0.5104,\n",
      "        0.5072, 0.5082, 0.5026, 0.4988, 0.5037, 0.5221, 0.5288, 0.5073, 0.5202,\n",
      "        0.5301, 0.5354, 0.5141, 0.5099, 0.5367, 0.5019, 0.5192, 0.5227, 0.5337,\n",
      "        0.4962, 0.5248, 0.5137, 0.5022, 0.5286, 0.5016, 0.5367, 0.5110, 0.5397,\n",
      "        0.5321, 0.5016, 0.5156, 0.5153, 0.5071, 0.5046, 0.4998, 0.5259, 0.5128,\n",
      "        0.5057, 0.5259, 0.5143, 0.5004, 0.5152, 0.5194, 0.5091, 0.5310, 0.4979,\n",
      "        0.5100, 0.5191, 0.5202, 0.4994, 0.5179, 0.5256, 0.4952, 0.5210, 0.5203,\n",
      "        0.5096, 0.4888, 0.4957, 0.5236, 0.5302, 0.5457, 0.4874, 0.5357, 0.5006,\n",
      "        0.5266], grad_fn=<CatBackward0>)\n",
      "var of recall: tensor(0.0002, grad_fn=<SubBackward0>)\n",
      "mean of recall tensor(0.5148, grad_fn=<MeanBackward0>)\n",
      "meta_loss: tensor(0.0002, grad_fn=<SubBackward0>)\n",
      "recall_true: tensor(0.4907)\n",
      "ENN_loss: tensor(0.0454, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0470, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0759, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0641, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0638, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0453, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0703, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0462, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0736, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0765, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0211, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0624, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0526, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0767, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0583, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0540, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0404, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0859, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0410, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0999, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0592, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0353, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0767, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0537, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0618, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0846, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0536, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0396, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0523, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0572, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0814, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0521, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0506, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0667, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0665, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0512, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0654, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1016, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0398, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0443, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0816, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0359, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0612, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0575, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0590, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0524, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0680, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0435, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0537, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0742, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0551, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0491, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0440, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0459, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0378, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1112, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0588, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0600, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0789, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0656, grad_fn=<MeanBackward0>)\n",
      "recall list tensor([0.4865, 0.5363, 0.5067, 0.5141, 0.4957, 0.4794, 0.5680, 0.5307, 0.5325,\n",
      "        0.5257, 0.5326, 0.5076, 0.5110, 0.5325, 0.4864, 0.5089, 0.4878, 0.5258,\n",
      "        0.4988, 0.5365, 0.4779, 0.5255, 0.4904, 0.5213, 0.4785, 0.4772, 0.5161,\n",
      "        0.5022, 0.5165, 0.5430, 0.4789, 0.5571, 0.5138, 0.5293, 0.4832, 0.5216,\n",
      "        0.4857, 0.5064, 0.4987, 0.5107, 0.5342, 0.5283, 0.5382, 0.5538, 0.5223,\n",
      "        0.5102, 0.4878, 0.5679, 0.4840, 0.5077, 0.5407, 0.5306, 0.5411, 0.5014,\n",
      "        0.5409, 0.4945, 0.5494, 0.5148, 0.5211, 0.5165, 0.4678, 0.5250, 0.5263,\n",
      "        0.4905, 0.5322, 0.5460, 0.4760, 0.5132, 0.5344, 0.5478, 0.5129, 0.4692,\n",
      "        0.4997, 0.4855, 0.5194, 0.5325, 0.5589, 0.5056, 0.5148, 0.5105, 0.5419,\n",
      "        0.5552, 0.4886, 0.5191, 0.5617, 0.6067, 0.5579, 0.5492, 0.4775, 0.5153,\n",
      "        0.5338, 0.5353, 0.5665, 0.5144, 0.5369, 0.5418, 0.5212, 0.4676, 0.5383,\n",
      "        0.5020], grad_fn=<CatBackward0>)\n",
      "var of recall: tensor(0.0007, grad_fn=<SubBackward0>)\n",
      "mean of recall tensor(0.5182, grad_fn=<MeanBackward0>)\n",
      "meta_loss: tensor(0.0007, grad_fn=<SubBackward0>)\n",
      "recall_true: tensor(0.4907)\n",
      "ENN_loss: tensor(0.0837, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0537, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0617, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0524, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0749, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0619, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0406, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0777, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0452, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0755, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0557, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0724, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0540, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0649, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0632, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0769, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0569, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0739, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0856, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0450, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0605, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0862, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0428, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0476, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0755, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0414, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0694, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0665, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0686, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1075, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0464, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0458, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0559, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0714, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0770, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0347, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0901, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0579, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0528, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0545, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0563, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0629, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0849, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0699, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0429, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0832, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0660, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0631, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0715, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0784, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0412, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0632, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0771, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0747, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0660, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0356, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0549, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0538, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0770, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0864, grad_fn=<MeanBackward0>)\n",
      "recall list tensor([0.5200, 0.5034, 0.5307, 0.4787, 0.5628, 0.4908, 0.4700, 0.5308, 0.5235,\n",
      "        0.5143, 0.5153, 0.5013, 0.5270, 0.5447, 0.5006, 0.5138, 0.5117, 0.5556,\n",
      "        0.5037, 0.5062, 0.5201, 0.5061, 0.4958, 0.5092, 0.4824, 0.5178, 0.5238,\n",
      "        0.5276, 0.4743, 0.5142, 0.5440, 0.5401, 0.5555, 0.5284, 0.5142, 0.4806,\n",
      "        0.5130, 0.5342, 0.5342, 0.5304, 0.5532, 0.4643, 0.5158, 0.5555, 0.5145,\n",
      "        0.4826, 0.5260, 0.5315, 0.5323, 0.4834, 0.5118, 0.5494, 0.5118, 0.5246,\n",
      "        0.4797, 0.4760, 0.5398, 0.5038, 0.4833, 0.5415, 0.5086, 0.5451, 0.5063,\n",
      "        0.5137, 0.4916, 0.5220, 0.5168, 0.4895, 0.5002, 0.4997, 0.5216, 0.4966,\n",
      "        0.5262, 0.4900, 0.5596, 0.5049, 0.5037, 0.5537, 0.5176, 0.5115, 0.4893,\n",
      "        0.5127, 0.5034, 0.4812, 0.4990, 0.4996, 0.4995, 0.5362, 0.5403, 0.5344,\n",
      "        0.4698, 0.4854, 0.5056, 0.5552, 0.5484, 0.5300, 0.4968, 0.4958, 0.5177,\n",
      "        0.5151], grad_fn=<CatBackward0>)\n",
      "var of recall: tensor(0.0005, grad_fn=<SubBackward0>)\n",
      "mean of recall tensor(0.5143, grad_fn=<MeanBackward0>)\n",
      "meta_loss: tensor(0.0005, grad_fn=<SubBackward0>)\n",
      "recall_true: tensor(0.4907)\n",
      "ENN_loss: tensor(0.1201, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0596, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0397, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0788, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0440, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0738, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0824, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0917, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0322, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1031, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0942, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0676, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1334, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0624, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0375, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0635, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0900, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0405, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0751, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0925, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0680, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0767, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0636, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0704, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0632, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0770, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0758, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0662, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0818, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0662, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0717, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0581, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0687, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0796, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0862, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0652, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0707, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0471, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0861, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0859, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0311, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1091, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0594, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0719, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0618, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0791, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0551, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0838, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0618, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0463, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0946, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0855, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0464, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0547, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1021, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0669, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0816, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0588, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0823, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0672, grad_fn=<MeanBackward0>)\n",
      "recall list tensor([0.5242, 0.5500, 0.5221, 0.5184, 0.5671, 0.4829, 0.5240, 0.4792, 0.4932,\n",
      "        0.5196, 0.5144, 0.5173, 0.5249, 0.5183, 0.5146, 0.5407, 0.5187, 0.5164,\n",
      "        0.5350, 0.5084, 0.5251, 0.5342, 0.4991, 0.5209, 0.5238, 0.5095, 0.5335,\n",
      "        0.5164, 0.5269, 0.5490, 0.4953, 0.5304, 0.5066, 0.4946, 0.4957, 0.4985,\n",
      "        0.5009, 0.5178, 0.5227, 0.5108, 0.5383, 0.5142, 0.5262, 0.5431, 0.5251,\n",
      "        0.5509, 0.5239, 0.4936, 0.5155, 0.5017, 0.5252, 0.5028, 0.5056, 0.5282,\n",
      "        0.5447, 0.5259, 0.5244, 0.5161, 0.4972, 0.5177, 0.5262, 0.5362, 0.5277,\n",
      "        0.5509, 0.5268, 0.4868, 0.5147, 0.5309, 0.4874, 0.5063, 0.5234, 0.5175,\n",
      "        0.5155, 0.4995, 0.5341, 0.5281, 0.4768, 0.4996, 0.4912, 0.5031, 0.5487,\n",
      "        0.5219, 0.4860, 0.5518, 0.5394, 0.4953, 0.5110, 0.5358, 0.5140, 0.5210,\n",
      "        0.4920, 0.4834, 0.4851, 0.5471, 0.5165, 0.5304, 0.4845, 0.5008, 0.5026,\n",
      "        0.5079], grad_fn=<CatBackward0>)\n",
      "var of recall: tensor(0.0004, grad_fn=<SubBackward0>)\n",
      "mean of recall tensor(0.5168, grad_fn=<MeanBackward0>)\n",
      "meta_loss: tensor(0.0004, grad_fn=<SubBackward0>)\n",
      "recall_true: tensor(0.4907)\n",
      "ENN_loss: tensor(0.0347, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1313, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0925, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0513, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0751, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0616, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0607, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0832, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0674, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0667, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0686, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0738, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0796, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0709, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0456, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0724, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0756, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0831, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0501, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0837, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0371, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0827, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0825, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0710, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0583, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0844, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0650, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0736, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0797, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0749, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0672, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0736, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0763, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0522, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0482, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0961, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0446, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0731, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0942, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0725, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0391, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0794, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0681, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0758, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0774, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0786, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0815, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0503, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0475, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0779, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0819, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0725, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0988, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0787, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0613, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0582, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0729, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0781, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0763, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0745, grad_fn=<MeanBackward0>)\n",
      "recall list tensor([0.5068, 0.5048, 0.5303, 0.5275, 0.4981, 0.5008, 0.5343, 0.4857, 0.4958,\n",
      "        0.5467, 0.4764, 0.5232, 0.4950, 0.5143, 0.5246, 0.5047, 0.4747, 0.5691,\n",
      "        0.5030, 0.4896, 0.5464, 0.5314, 0.4857, 0.5323, 0.5273, 0.4831, 0.5223,\n",
      "        0.5331, 0.5027, 0.5190, 0.5204, 0.5116, 0.5107, 0.5185, 0.5215, 0.5440,\n",
      "        0.5305, 0.5172, 0.5123, 0.5274, 0.5082, 0.5158, 0.5134, 0.5321, 0.5289,\n",
      "        0.5222, 0.5087, 0.5330, 0.5259, 0.5062, 0.5527, 0.4873, 0.5277, 0.5296,\n",
      "        0.5033, 0.4956, 0.4848, 0.4870, 0.5707, 0.5265, 0.5086, 0.4842, 0.5232,\n",
      "        0.4887, 0.4993, 0.5047, 0.4965, 0.4959, 0.5475, 0.5164, 0.5108, 0.5157,\n",
      "        0.5449, 0.5305, 0.5252, 0.5201, 0.5001, 0.4796, 0.5283, 0.4835, 0.5308,\n",
      "        0.4675, 0.5093, 0.4937, 0.5236, 0.5630, 0.5062, 0.5395, 0.5049, 0.5274,\n",
      "        0.5055, 0.5307, 0.4844, 0.5315, 0.5265, 0.5347, 0.5060, 0.5430, 0.5091,\n",
      "        0.5294], grad_fn=<CatBackward0>)\n",
      "var of recall: tensor(0.0004, grad_fn=<SubBackward0>)\n",
      "mean of recall tensor(0.5153, grad_fn=<MeanBackward0>)\n",
      "meta_loss: tensor(0.0004, grad_fn=<SubBackward0>)\n",
      "recall_true: tensor(0.4907)\n",
      "ENN_loss: tensor(0.0748, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0779, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0847, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0679, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0675, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0566, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0693, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0886, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0489, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0720, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0738, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0771, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0668, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0841, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0689, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0538, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0914, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0704, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0415, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0736, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1010, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1641, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0614, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0460, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0459, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0929, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0652, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0662, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0587, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0635, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0537, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0822, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0340, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1057, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0805, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0716, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0786, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0702, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0449, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0799, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0835, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0599, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0503, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0738, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0758, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0598, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0731, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0558, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0571, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0667, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0817, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0749, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0711, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0641, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0610, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0687, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0782, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0566, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0639, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0828, grad_fn=<MeanBackward0>)\n",
      "recall list tensor([0.5186, 0.5105, 0.5108, 0.5220, 0.5599, 0.5251, 0.5071, 0.5502, 0.5156,\n",
      "        0.4844, 0.5292, 0.5215, 0.5422, 0.4775, 0.5121, 0.5236, 0.4818, 0.5553,\n",
      "        0.5172, 0.5150, 0.5329, 0.5452, 0.4990, 0.5258, 0.5222, 0.5213, 0.5366,\n",
      "        0.5260, 0.5234, 0.5140, 0.5248, 0.4862, 0.5501, 0.5317, 0.4969, 0.5225,\n",
      "        0.5232, 0.4993, 0.5341, 0.5388, 0.4929, 0.4792, 0.5023, 0.4934, 0.5054,\n",
      "        0.5143, 0.5314, 0.5056, 0.5238, 0.4861, 0.5219, 0.5241, 0.5322, 0.4956,\n",
      "        0.5371, 0.4955, 0.4919, 0.4926, 0.4942, 0.4832, 0.4733, 0.5028, 0.5480,\n",
      "        0.4931, 0.5234, 0.5041, 0.4989, 0.5431, 0.5240, 0.5091, 0.5000, 0.5411,\n",
      "        0.4729, 0.5433, 0.4883, 0.5513, 0.5209, 0.4836, 0.5103, 0.4986, 0.5087,\n",
      "        0.5385, 0.4689, 0.5575, 0.5237, 0.5157, 0.5382, 0.5131, 0.5057, 0.4917,\n",
      "        0.5485, 0.5401, 0.5204, 0.5059, 0.4950, 0.5214, 0.5248, 0.5460, 0.5021,\n",
      "        0.5728], grad_fn=<CatBackward0>)\n",
      "var of recall: tensor(0.0005, grad_fn=<SubBackward0>)\n",
      "mean of recall tensor(0.5161, grad_fn=<MeanBackward0>)\n",
      "meta_loss: tensor(0.0005, grad_fn=<SubBackward0>)\n",
      "recall_true: tensor(0.4907)\n",
      "ENN_loss: tensor(0.1023, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0583, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0478, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0337, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0723, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0436, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0453, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0640, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0523, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0389, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0481, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0783, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0823, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0385, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0330, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0445, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0715, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0288, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0326, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0760, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0670, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0414, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0569, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0617, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0561, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0494, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0656, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0453, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0663, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0341, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0490, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0576, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0306, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0513, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0579, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0803, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0616, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0506, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0354, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0615, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0467, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0446, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0614, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0520, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0407, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0865, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0371, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0419, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0483, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0652, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0421, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0543, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0440, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0396, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0738, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0516, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0355, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0528, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0784, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0341, grad_fn=<MeanBackward0>)\n",
      "recall list tensor([0.5053, 0.5049, 0.5329, 0.4454, 0.4871, 0.5233, 0.5326, 0.5084, 0.5029,\n",
      "        0.5206, 0.5284, 0.5157, 0.4805, 0.4819, 0.5933, 0.4952, 0.5240, 0.4960,\n",
      "        0.5071, 0.4595, 0.5087, 0.4919, 0.5039, 0.5171, 0.4848, 0.4980, 0.5261,\n",
      "        0.4835, 0.5005, 0.5513, 0.5623, 0.5287, 0.5259, 0.5548, 0.4881, 0.5309,\n",
      "        0.5710, 0.4849, 0.5385, 0.5004, 0.5527, 0.5106, 0.5803, 0.5066, 0.5159,\n",
      "        0.5274, 0.5116, 0.4520, 0.5249, 0.5013, 0.5754, 0.4853, 0.4708, 0.4898,\n",
      "        0.5192, 0.4660, 0.5251, 0.5223, 0.4647, 0.5305, 0.5247, 0.5271, 0.5470,\n",
      "        0.5218, 0.5013, 0.5645, 0.5052, 0.5050, 0.5197, 0.5431, 0.5263, 0.5170,\n",
      "        0.5633, 0.5087, 0.5277, 0.5551, 0.5420, 0.5345, 0.4871, 0.4874, 0.5460,\n",
      "        0.5223, 0.5057, 0.5114, 0.5601, 0.4853, 0.5264, 0.5158, 0.5109, 0.5181,\n",
      "        0.5550, 0.5253, 0.4946, 0.4821, 0.4944, 0.4368, 0.5132, 0.5433, 0.5308,\n",
      "        0.5273], grad_fn=<CatBackward0>)\n",
      "var of recall: tensor(0.0008, grad_fn=<SubBackward0>)\n",
      "mean of recall tensor(0.5154, grad_fn=<MeanBackward0>)\n",
      "meta_loss: tensor(0.0008, grad_fn=<SubBackward0>)\n",
      "recall_true: tensor(0.4907)\n",
      "ENN_loss: tensor(0.0956, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0714, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0635, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0426, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0586, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0880, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0341, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0986, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0821, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0538, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0424, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0994, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0941, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0650, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0480, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0642, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0998, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0664, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0707, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0471, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0558, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1002, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0561, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0588, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1092, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0655, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0575, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0531, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0254, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0672, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0795, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0939, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0690, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0921, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0737, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0459, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0801, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0497, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0710, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0706, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0777, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0823, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0660, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0510, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0864, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0557, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0709, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0776, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0565, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0585, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0796, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0854, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0451, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0871, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0765, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0812, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0697, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0664, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0791, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0586, grad_fn=<MeanBackward0>)\n",
      "recall list tensor([0.4951, 0.4949, 0.5128, 0.5223, 0.5324, 0.5243, 0.4989, 0.5485, 0.4828,\n",
      "        0.5202, 0.4902, 0.5228, 0.5381, 0.5452, 0.5444, 0.5080, 0.5166, 0.5555,\n",
      "        0.5216, 0.5425, 0.4937, 0.5376, 0.5559, 0.5225, 0.5183, 0.5021, 0.5345,\n",
      "        0.5324, 0.5100, 0.5245, 0.5139, 0.5359, 0.5178, 0.5098, 0.5229, 0.5332,\n",
      "        0.4988, 0.5594, 0.5003, 0.5483, 0.5353, 0.5006, 0.4942, 0.5270, 0.5271,\n",
      "        0.5138, 0.5063, 0.4867, 0.5512, 0.5205, 0.5370, 0.5146, 0.5068, 0.5263,\n",
      "        0.5155, 0.5300, 0.5185, 0.5107, 0.4989, 0.4855, 0.5035, 0.5148, 0.5237,\n",
      "        0.5090, 0.5284, 0.5087, 0.5178, 0.5362, 0.5156, 0.4869, 0.5239, 0.5303,\n",
      "        0.5315, 0.5085, 0.5180, 0.5304, 0.5364, 0.5236, 0.5233, 0.5050, 0.5289,\n",
      "        0.5065, 0.5083, 0.4935, 0.4800, 0.5408, 0.5089, 0.5562, 0.4653, 0.4701,\n",
      "        0.5200, 0.5201, 0.5488, 0.5200, 0.4957, 0.5003, 0.4923, 0.4732, 0.5261,\n",
      "        0.5255], grad_fn=<CatBackward0>)\n",
      "var of recall: tensor(0.0004, grad_fn=<SubBackward0>)\n",
      "mean of recall tensor(0.5175, grad_fn=<MeanBackward0>)\n",
      "meta_loss: tensor(0.0004, grad_fn=<SubBackward0>)\n",
      "recall_true: tensor(0.4907)\n",
      "ENN_loss: tensor(0.0853, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0514, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0648, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0507, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0411, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0829, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0697, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0584, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0620, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0727, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0635, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0762, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0686, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0647, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0436, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0840, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0684, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0642, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0683, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0810, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0609, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0465, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0963, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0639, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0361, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0816, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0736, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0670, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0836, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0583, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0466, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0689, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0639, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0636, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0710, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0679, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0719, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0457, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1052, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0673, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0683, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0365, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0406, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1781, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0775, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0588, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0820, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0578, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0819, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0476, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0547, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0871, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0342, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0591, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0970, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0597, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0661, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0960, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0659, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0624, grad_fn=<MeanBackward0>)\n",
      "recall list tensor([0.4982, 0.5161, 0.4716, 0.5660, 0.4891, 0.4903, 0.5345, 0.5345, 0.4730,\n",
      "        0.4886, 0.5236, 0.5255, 0.5455, 0.5080, 0.4841, 0.5110, 0.5209, 0.5121,\n",
      "        0.5026, 0.5963, 0.5413, 0.5244, 0.4728, 0.5252, 0.4768, 0.5096, 0.4824,\n",
      "        0.5143, 0.5405, 0.5097, 0.4936, 0.4963, 0.4811, 0.4808, 0.4744, 0.4938,\n",
      "        0.5257, 0.5000, 0.5495, 0.4964, 0.5268, 0.4997, 0.5577, 0.4961, 0.5342,\n",
      "        0.4942, 0.5309, 0.5119, 0.5463, 0.5163, 0.5245, 0.5087, 0.5024, 0.5205,\n",
      "        0.4943, 0.5253, 0.5553, 0.4761, 0.4845, 0.5311, 0.5602, 0.5196, 0.5424,\n",
      "        0.5140, 0.4917, 0.5218, 0.5261, 0.5181, 0.4954, 0.5196, 0.5072, 0.4960,\n",
      "        0.4941, 0.5063, 0.5288, 0.5080, 0.4879, 0.4964, 0.5292, 0.5173, 0.4936,\n",
      "        0.5130, 0.4899, 0.5378, 0.5133, 0.5287, 0.5309, 0.4990, 0.5323, 0.5567,\n",
      "        0.5375, 0.5431, 0.4946, 0.5333, 0.4778, 0.5267, 0.5032, 0.4877, 0.5226,\n",
      "        0.5101], grad_fn=<CatBackward0>)\n",
      "var of recall: tensor(0.0006, grad_fn=<SubBackward0>)\n",
      "mean of recall tensor(0.5133, grad_fn=<MeanBackward0>)\n",
      "meta_loss: tensor(0.0006, grad_fn=<SubBackward0>)\n",
      "recall_true: tensor(0.4907)\n",
      "ENN_loss: tensor(0.0803, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0494, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0611, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0663, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0950, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0680, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0636, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0775, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0611, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0607, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0872, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0626, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1247, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0566, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0647, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0572, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1252, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0711, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0686, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0570, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0888, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0731, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0633, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0663, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0714, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0758, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0546, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0649, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0657, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0707, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0876, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0579, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0454, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0892, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0755, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0580, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1001, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0628, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0376, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0630, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0962, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0417, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0608, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0791, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0639, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0789, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0882, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0530, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0630, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0835, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0713, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0676, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0640, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0834, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0605, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0592, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0824, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0726, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0724, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0609, grad_fn=<MeanBackward0>)\n",
      "recall list tensor([0.5155, 0.5125, 0.4932, 0.5404, 0.5240, 0.5289, 0.5344, 0.5029, 0.5099,\n",
      "        0.4948, 0.4879, 0.5412, 0.4931, 0.4975, 0.4942, 0.5359, 0.4945, 0.5329,\n",
      "        0.5336, 0.5129, 0.5036, 0.5251, 0.5055, 0.5052, 0.5311, 0.4994, 0.4743,\n",
      "        0.5135, 0.5485, 0.5124, 0.5304, 0.5310, 0.5182, 0.5164, 0.4740, 0.5176,\n",
      "        0.5325, 0.5670, 0.5255, 0.5199, 0.5133, 0.5177, 0.4758, 0.4655, 0.5189,\n",
      "        0.4839, 0.4903, 0.4990, 0.5412, 0.5443, 0.4898, 0.4947, 0.5173, 0.5161,\n",
      "        0.4704, 0.5062, 0.5563, 0.5309, 0.5169, 0.5047, 0.5315, 0.4958, 0.5115,\n",
      "        0.5352, 0.5180, 0.4973, 0.5607, 0.5261, 0.4928, 0.5151, 0.5351, 0.5387,\n",
      "        0.5193, 0.4997, 0.5395, 0.5034, 0.5340, 0.4789, 0.4924, 0.5246, 0.4741,\n",
      "        0.4949, 0.5356, 0.5141, 0.4814, 0.5058, 0.5511, 0.5380, 0.4979, 0.5027,\n",
      "        0.5208, 0.4877, 0.4934, 0.5214, 0.4831, 0.4965, 0.5189, 0.5296, 0.5165,\n",
      "        0.5068], grad_fn=<CatBackward0>)\n",
      "var of recall: tensor(0.0004, grad_fn=<SubBackward0>)\n",
      "mean of recall tensor(0.5130, grad_fn=<MeanBackward0>)\n",
      "meta_loss: tensor(0.0004, grad_fn=<SubBackward0>)\n",
      "recall_true: tensor(0.4907)\n",
      "ENN_loss: tensor(0.0607, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0467, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0430, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0942, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0972, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0494, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0536, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0686, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0770, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0273, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0794, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0799, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0487, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0803, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0737, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0698, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0708, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0974, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0755, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0525, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0817, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0584, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0659, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0581, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0787, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0846, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0415, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0644, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0668, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0595, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0469, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0871, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0674, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0530, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0361, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0938, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0567, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0550, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0813, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0643, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0715, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0545, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0797, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0533, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0717, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0675, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0593, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0637, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0547, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0812, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0762, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0437, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0679, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0859, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0563, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0495, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0398, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0400, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0838, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0959, grad_fn=<MeanBackward0>)\n",
      "recall list tensor([0.5197, 0.4985, 0.5197, 0.5281, 0.5012, 0.4946, 0.5705, 0.4834, 0.5312,\n",
      "        0.5506, 0.5239, 0.5118, 0.5195, 0.5279, 0.5177, 0.5196, 0.5251, 0.5014,\n",
      "        0.5683, 0.4785, 0.5216, 0.5416, 0.4975, 0.5055, 0.4975, 0.5075, 0.5137,\n",
      "        0.5134, 0.5569, 0.4932, 0.5287, 0.4955, 0.4951, 0.5138, 0.5105, 0.5351,\n",
      "        0.5205, 0.4907, 0.5236, 0.5279, 0.5487, 0.4979, 0.5027, 0.4766, 0.5146,\n",
      "        0.4881, 0.4906, 0.5303, 0.5127, 0.5253, 0.5264, 0.5117, 0.5235, 0.4721,\n",
      "        0.5151, 0.5077, 0.4864, 0.5095, 0.5246, 0.5089, 0.4965, 0.5283, 0.4952,\n",
      "        0.4708, 0.5202, 0.5513, 0.5704, 0.5537, 0.5281, 0.5176, 0.4954, 0.5195,\n",
      "        0.5422, 0.5097, 0.5113, 0.4793, 0.5003, 0.5328, 0.4973, 0.5022, 0.5065,\n",
      "        0.5111, 0.5354, 0.5095, 0.4967, 0.5193, 0.4802, 0.5376, 0.5323, 0.5390,\n",
      "        0.5183, 0.5178, 0.5294, 0.4707, 0.5222, 0.5177, 0.5108, 0.5473, 0.4723,\n",
      "        0.5115], grad_fn=<CatBackward0>)\n",
      "var of recall: tensor(0.0005, grad_fn=<SubBackward0>)\n",
      "mean of recall tensor(0.5146, grad_fn=<MeanBackward0>)\n",
      "meta_loss: tensor(0.0005, grad_fn=<SubBackward0>)\n",
      "recall_true: tensor(0.4907)\n",
      "ENN_loss: tensor(0.0335, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0546, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0544, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0768, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0462, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0828, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0382, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0568, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0530, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0583, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0661, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0518, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0335, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0480, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0519, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0947, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0935, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0660, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0342, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0574, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0431, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0515, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0817, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0312, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0705, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0296, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0505, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0647, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0568, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0563, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0664, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0453, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0459, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0697, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0487, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0728, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0498, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0632, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0670, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0415, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0705, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0649, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0376, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0592, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0702, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0414, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0543, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0524, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0454, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0493, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0626, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0636, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0420, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0509, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0457, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0731, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0603, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0586, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0329, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0592, grad_fn=<MeanBackward0>)\n",
      "recall list tensor([0.5265, 0.4982, 0.5441, 0.5433, 0.4820, 0.4555, 0.5155, 0.5306, 0.4811,\n",
      "        0.5492, 0.4964, 0.5267, 0.5262, 0.4959, 0.5053, 0.5300, 0.5093, 0.5319,\n",
      "        0.4723, 0.4771, 0.5031, 0.5098, 0.4841, 0.5128, 0.5101, 0.4768, 0.5117,\n",
      "        0.4915, 0.5190, 0.5305, 0.5121, 0.5607, 0.5213, 0.5334, 0.5304, 0.5240,\n",
      "        0.5199, 0.5121, 0.5398, 0.5342, 0.5267, 0.5123, 0.5141, 0.5430, 0.5463,\n",
      "        0.4817, 0.5175, 0.5635, 0.4947, 0.4938, 0.5030, 0.5646, 0.5055, 0.4550,\n",
      "        0.4719, 0.4988, 0.5272, 0.5581, 0.5227, 0.5141, 0.4938, 0.5258, 0.5553,\n",
      "        0.4901, 0.5727, 0.5104, 0.5401, 0.5244, 0.5292, 0.5150, 0.5472, 0.5121,\n",
      "        0.5664, 0.4596, 0.5132, 0.4995, 0.5112, 0.5228, 0.5020, 0.5278, 0.5112,\n",
      "        0.4553, 0.4974, 0.5114, 0.4464, 0.5447, 0.5563, 0.5407, 0.5038, 0.5445,\n",
      "        0.5174, 0.5023, 0.5019, 0.4831, 0.5352, 0.5063, 0.5025, 0.4791, 0.5315,\n",
      "        0.5274], grad_fn=<CatBackward0>)\n",
      "var of recall: tensor(0.0007, grad_fn=<SubBackward0>)\n",
      "mean of recall tensor(0.5147, grad_fn=<MeanBackward0>)\n",
      "meta_loss: tensor(0.0007, grad_fn=<SubBackward0>)\n",
      "recall_true: tensor(0.4907)\n",
      "ENN_loss: tensor(0.0663, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0580, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0843, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0562, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0796, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0536, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0758, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0733, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0627, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0741, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0575, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1119, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1057, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0409, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0693, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0701, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1013, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0523, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0590, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0692, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0702, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0947, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0464, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0697, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0676, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0674, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0753, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0663, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0894, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0691, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0652, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0572, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1097, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0653, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0767, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0470, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0613, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0782, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0499, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0915, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0636, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0539, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0775, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0865, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1032, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0420, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0482, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0944, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0341, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1046, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0463, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0720, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0899, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0856, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0622, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0739, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0752, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0724, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0944, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0610, grad_fn=<MeanBackward0>)\n",
      "recall list tensor([0.5221, 0.5119, 0.5039, 0.4958, 0.5422, 0.5466, 0.5047, 0.5399, 0.5257,\n",
      "        0.5006, 0.5121, 0.5614, 0.5300, 0.5206, 0.5179, 0.5279, 0.5141, 0.5251,\n",
      "        0.5273, 0.5110, 0.4968, 0.5051, 0.5444, 0.5172, 0.4800, 0.5262, 0.5379,\n",
      "        0.5104, 0.5453, 0.4885, 0.5382, 0.5258, 0.5141, 0.5385, 0.5433, 0.5083,\n",
      "        0.5123, 0.5117, 0.5214, 0.5087, 0.5028, 0.5045, 0.5500, 0.5207, 0.5000,\n",
      "        0.4930, 0.5141, 0.5276, 0.5188, 0.5000, 0.5158, 0.5010, 0.4993, 0.5262,\n",
      "        0.5317, 0.4751, 0.5240, 0.5135, 0.5199, 0.5536, 0.5053, 0.5120, 0.5188,\n",
      "        0.4937, 0.5305, 0.5371, 0.5318, 0.4914, 0.5349, 0.5334, 0.4681, 0.5526,\n",
      "        0.5090, 0.5179, 0.5663, 0.4973, 0.5276, 0.5248, 0.5057, 0.5119, 0.5399,\n",
      "        0.5115, 0.5074, 0.4968, 0.5341, 0.5650, 0.5212, 0.5316, 0.4778, 0.5380,\n",
      "        0.4976, 0.5011, 0.5354, 0.5036, 0.5513, 0.5245, 0.5280, 0.5105, 0.5236,\n",
      "        0.5078], grad_fn=<CatBackward0>)\n",
      "var of recall: tensor(0.0004, grad_fn=<SubBackward0>)\n",
      "mean of recall tensor(0.5188, grad_fn=<MeanBackward0>)\n",
      "meta_loss: tensor(0.0004, grad_fn=<SubBackward0>)\n",
      "recall_true: tensor(0.4907)\n",
      "ENN_loss: tensor(0.0465, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0840, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0902, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0824, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0885, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0744, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0534, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0797, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0893, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0549, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0904, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0552, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0863, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0524, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0779, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0693, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1190, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0371, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0844, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0650, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0650, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0781, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0610, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0837, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0988, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0595, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0438, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0898, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0432, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0754, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0414, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1116, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0549, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0328, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1217, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0656, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0751, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0952, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0443, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0838, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0673, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0728, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0679, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0776, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0651, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0775, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0546, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0895, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0539, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0693, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0839, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0722, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1234, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0656, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0647, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0508, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0708, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0424, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0760, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0868, grad_fn=<MeanBackward0>)\n",
      "recall list tensor([0.5187, 0.4963, 0.5082, 0.4731, 0.5262, 0.5410, 0.5412, 0.5526, 0.5206,\n",
      "        0.5494, 0.4903, 0.5260, 0.5375, 0.5285, 0.4845, 0.4914, 0.4956, 0.5381,\n",
      "        0.5172, 0.5148, 0.5393, 0.5187, 0.5547, 0.4847, 0.5146, 0.5064, 0.5229,\n",
      "        0.5034, 0.5498, 0.5033, 0.4805, 0.5368, 0.5124, 0.5324, 0.5300, 0.5117,\n",
      "        0.5258, 0.5266, 0.5403, 0.5428, 0.5192, 0.5650, 0.4976, 0.5170, 0.5339,\n",
      "        0.4828, 0.5236, 0.5165, 0.5175, 0.4944, 0.5409, 0.5459, 0.5261, 0.5006,\n",
      "        0.5298, 0.5335, 0.5322, 0.5250, 0.5066, 0.4774, 0.5285, 0.5613, 0.5108,\n",
      "        0.5431, 0.5054, 0.5040, 0.5347, 0.4982, 0.5158, 0.5061, 0.4724, 0.5317,\n",
      "        0.5254, 0.5357, 0.5514, 0.5227, 0.5116, 0.5355, 0.5166, 0.4984, 0.5212,\n",
      "        0.5381, 0.5334, 0.4998, 0.4846, 0.5278, 0.4837, 0.5479, 0.5097, 0.5198,\n",
      "        0.5276, 0.5278, 0.5425, 0.5384, 0.5354, 0.5237, 0.5072, 0.5042, 0.5255,\n",
      "        0.5061], grad_fn=<CatBackward0>)\n",
      "var of recall: tensor(0.0004, grad_fn=<SubBackward0>)\n",
      "mean of recall tensor(0.5199, grad_fn=<MeanBackward0>)\n",
      "meta_loss: tensor(0.0004, grad_fn=<SubBackward0>)\n",
      "recall_true: tensor(0.4907)\n",
      "ENN_loss: tensor(0.0366, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0614, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0382, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0980, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0740, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0355, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0381, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0797, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0561, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0377, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0557, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0655, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0380, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0772, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0356, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0532, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0499, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0700, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0319, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0590, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0648, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0427, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0486, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0561, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0682, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0372, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0414, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0685, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0286, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0569, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0494, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0602, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0510, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0486, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0763, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0446, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0425, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0699, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0508, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0480, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0574, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0482, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0712, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0298, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0473, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0466, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0565, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0552, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0756, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0281, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0578, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0414, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0457, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0577, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0657, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0248, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0560, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0488, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0549, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0498, grad_fn=<MeanBackward0>)\n",
      "recall list tensor([0.5270, 0.4883, 0.4347, 0.4909, 0.4970, 0.5397, 0.5188, 0.5369, 0.5352,\n",
      "        0.4810, 0.5120, 0.5135, 0.5228, 0.4765, 0.5027, 0.5008, 0.4867, 0.5702,\n",
      "        0.5055, 0.5215, 0.4629, 0.5579, 0.5381, 0.4816, 0.5024, 0.5004, 0.5138,\n",
      "        0.5074, 0.4847, 0.5264, 0.4799, 0.4673, 0.5541, 0.5212, 0.4982, 0.4947,\n",
      "        0.5415, 0.5612, 0.5048, 0.5448, 0.4766, 0.4980, 0.5116, 0.5442, 0.5597,\n",
      "        0.4532, 0.5317, 0.5350, 0.4914, 0.4642, 0.5436, 0.4845, 0.5493, 0.4764,\n",
      "        0.5038, 0.5021, 0.5042, 0.5258, 0.5371, 0.5081, 0.5509, 0.5693, 0.5701,\n",
      "        0.4937, 0.5146, 0.5117, 0.4945, 0.4872, 0.4967, 0.5195, 0.5082, 0.5531,\n",
      "        0.4698, 0.4783, 0.5567, 0.4959, 0.5420, 0.5723, 0.5060, 0.5202, 0.4696,\n",
      "        0.5273, 0.4926, 0.5132, 0.5013, 0.5166, 0.5142, 0.5554, 0.4847, 0.5362,\n",
      "        0.5054, 0.5274, 0.5059, 0.5749, 0.5554, 0.4858, 0.5204, 0.5213, 0.5298,\n",
      "        0.5176], grad_fn=<CatBackward0>)\n",
      "var of recall: tensor(0.0008, grad_fn=<SubBackward0>)\n",
      "mean of recall tensor(0.5137, grad_fn=<MeanBackward0>)\n",
      "meta_loss: tensor(0.0008, grad_fn=<SubBackward0>)\n",
      "recall_true: tensor(0.4907)\n",
      "ENN_loss: tensor(0.0291, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0532, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0700, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1159, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0560, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0625, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0595, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0820, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0825, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0606, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0457, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0714, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0640, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0778, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0496, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0741, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0878, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0643, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0669, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0887, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0676, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0594, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0751, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0558, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0602, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0585, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1037, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0482, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0494, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0939, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0520, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0712, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0505, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0641, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0742, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0676, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0589, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0642, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0770, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0606, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0594, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0676, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0773, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0669, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0698, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0681, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0673, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0540, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0773, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0524, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0824, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0475, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0710, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0695, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0672, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0480, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0681, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0555, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0731, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0548, grad_fn=<MeanBackward0>)\n",
      "recall list tensor([0.5292, 0.4944, 0.5565, 0.5000, 0.4793, 0.5174, 0.5396, 0.5003, 0.5218,\n",
      "        0.4865, 0.4860, 0.4823, 0.5162, 0.5690, 0.5160, 0.5118, 0.5176, 0.5188,\n",
      "        0.4897, 0.4493, 0.5333, 0.5136, 0.5307, 0.5341, 0.4996, 0.5444, 0.4795,\n",
      "        0.4974, 0.5295, 0.5377, 0.5407, 0.5194, 0.5206, 0.5405, 0.5079, 0.5062,\n",
      "        0.6011, 0.5272, 0.4973, 0.5346, 0.5458, 0.5164, 0.5116, 0.5564, 0.5593,\n",
      "        0.4888, 0.5499, 0.5469, 0.5311, 0.5246, 0.5253, 0.4886, 0.4759, 0.4941,\n",
      "        0.5223, 0.4754, 0.5508, 0.4912, 0.4890, 0.5016, 0.5210, 0.5215, 0.5382,\n",
      "        0.4846, 0.4878, 0.4825, 0.5192, 0.5213, 0.5143, 0.5293, 0.5392, 0.5243,\n",
      "        0.5623, 0.5101, 0.5122, 0.4521, 0.5050, 0.5119, 0.4776, 0.4930, 0.5090,\n",
      "        0.4879, 0.4948, 0.5071, 0.5255, 0.5665, 0.5021, 0.5240, 0.5116, 0.4746,\n",
      "        0.4956, 0.5356, 0.4671, 0.5086, 0.4948, 0.5041, 0.5390, 0.5349, 0.5161,\n",
      "        0.4841], grad_fn=<CatBackward0>)\n",
      "var of recall: tensor(0.0007, grad_fn=<SubBackward0>)\n",
      "mean of recall tensor(0.5141, grad_fn=<MeanBackward0>)\n",
      "meta_loss: tensor(0.0007, grad_fn=<SubBackward0>)\n",
      "recall_true: tensor(0.4907)\n",
      "ENN_loss: tensor(0.0719, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0804, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0778, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0688, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0707, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0791, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0788, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0648, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0875, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0722, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0402, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0793, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0592, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0625, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0894, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0701, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0669, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0951, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0795, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0337, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0753, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0840, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0852, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0501, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0857, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0464, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0930, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0733, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0515, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0774, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0798, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0778, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0691, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0579, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0640, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0812, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0936, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0623, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0837, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0435, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0888, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0718, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0725, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0763, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0544, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0817, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0618, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0821, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0651, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1011, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0628, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0524, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0725, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0685, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0596, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0926, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0681, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0807, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0706, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0517, grad_fn=<MeanBackward0>)\n",
      "recall list tensor([0.5080, 0.5083, 0.5471, 0.5138, 0.4981, 0.5369, 0.5376, 0.5104, 0.5453,\n",
      "        0.5316, 0.5148, 0.4755, 0.4770, 0.5361, 0.5166, 0.4951, 0.5284, 0.5308,\n",
      "        0.4789, 0.5479, 0.5169, 0.5352, 0.5119, 0.5064, 0.5007, 0.5330, 0.5230,\n",
      "        0.5252, 0.5238, 0.4781, 0.5174, 0.5234, 0.5105, 0.5204, 0.5205, 0.5433,\n",
      "        0.5330, 0.5249, 0.5343, 0.5013, 0.4985, 0.5330, 0.5356, 0.5058, 0.5044,\n",
      "        0.4781, 0.4959, 0.5094, 0.5273, 0.5206, 0.5025, 0.5348, 0.5252, 0.4833,\n",
      "        0.5006, 0.5437, 0.5493, 0.5060, 0.5271, 0.5119, 0.4992, 0.5423, 0.5181,\n",
      "        0.5511, 0.5320, 0.5422, 0.5123, 0.4909, 0.5396, 0.5157, 0.5476, 0.5177,\n",
      "        0.5421, 0.5350, 0.5101, 0.5178, 0.5164, 0.5172, 0.5018, 0.5034, 0.4879,\n",
      "        0.5135, 0.5036, 0.5480, 0.5355, 0.4972, 0.5308, 0.5073, 0.4974, 0.5375,\n",
      "        0.5084, 0.5159, 0.5101, 0.5681, 0.5144, 0.5104, 0.4953, 0.5086, 0.4746,\n",
      "        0.5032], grad_fn=<CatBackward0>)\n",
      "var of recall: tensor(0.0004, grad_fn=<SubBackward0>)\n",
      "mean of recall tensor(0.5174, grad_fn=<MeanBackward0>)\n",
      "meta_loss: tensor(0.0004, grad_fn=<SubBackward0>)\n",
      "recall_true: tensor(0.4907)\n",
      "ENN_loss: tensor(0.0501, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0617, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0943, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0812, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0894, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0528, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0876, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0683, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0477, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1081, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0745, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0700, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0537, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0817, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0723, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0767, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0612, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0659, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0690, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0764, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0826, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0689, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0661, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0616, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0630, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0733, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0658, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0760, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0419, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0722, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0514, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1234, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0790, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0570, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0900, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0502, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0811, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0503, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0756, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0722, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0898, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0702, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0671, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0625, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1046, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0551, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0504, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0682, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0724, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0661, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0544, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0935, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0726, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0587, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0846, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0612, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0485, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0942, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0614, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0815, grad_fn=<MeanBackward0>)\n",
      "recall list tensor([0.5302, 0.5087, 0.5140, 0.5525, 0.4971, 0.5372, 0.5408, 0.5241, 0.4583,\n",
      "        0.5021, 0.5445, 0.4783, 0.5595, 0.5118, 0.4811, 0.5304, 0.4818, 0.4917,\n",
      "        0.5347, 0.4566, 0.5356, 0.5591, 0.5203, 0.4979, 0.4981, 0.4933, 0.4906,\n",
      "        0.5168, 0.4933, 0.5187, 0.5067, 0.5034, 0.4797, 0.5038, 0.5093, 0.5316,\n",
      "        0.4840, 0.5467, 0.5031, 0.5578, 0.5361, 0.4597, 0.4932, 0.4922, 0.4937,\n",
      "        0.5283, 0.5025, 0.5091, 0.5098, 0.5125, 0.5142, 0.5378, 0.5306, 0.4970,\n",
      "        0.4916, 0.4982, 0.4894, 0.5116, 0.5112, 0.5296, 0.5192, 0.5062, 0.5187,\n",
      "        0.4983, 0.5216, 0.4958, 0.5603, 0.5534, 0.4716, 0.5022, 0.4930, 0.5197,\n",
      "        0.5128, 0.4779, 0.5146, 0.4875, 0.4952, 0.5171, 0.5194, 0.5115, 0.5169,\n",
      "        0.5105, 0.5203, 0.4876, 0.5411, 0.5227, 0.5050, 0.5067, 0.5417, 0.5272,\n",
      "        0.5404, 0.5284, 0.5440, 0.5258, 0.5032, 0.5045, 0.4939, 0.5430, 0.5213,\n",
      "        0.5133], grad_fn=<CatBackward0>)\n",
      "var of recall: tensor(0.0005, grad_fn=<SubBackward0>)\n",
      "mean of recall tensor(0.5123, grad_fn=<MeanBackward0>)\n",
      "meta_loss: tensor(0.0005, grad_fn=<SubBackward0>)\n",
      "recall_true: tensor(0.4907)\n",
      "ENN_loss: tensor(0.0479, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0944, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0641, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0462, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0617, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0497, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0608, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0660, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0659, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0646, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0268, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0745, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0572, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0406, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0621, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0730, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0604, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0412, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0749, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0488, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0494, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0821, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0683, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0414, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0363, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0763, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0380, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0680, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0703, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0473, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0617, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0580, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0690, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0524, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0451, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0490, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0663, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0567, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0600, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0413, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0449, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0769, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0728, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0338, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0690, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0462, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0403, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0688, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0609, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0633, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0491, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0678, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0434, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0588, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0644, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0705, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0497, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0556, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0528, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0582, grad_fn=<MeanBackward0>)\n",
      "recall list tensor([0.4945, 0.5157, 0.4824, 0.5193, 0.5620, 0.5461, 0.5172, 0.4951, 0.4962,\n",
      "        0.5012, 0.5715, 0.5132, 0.5249, 0.5324, 0.5092, 0.5386, 0.5250, 0.5331,\n",
      "        0.4824, 0.5685, 0.5533, 0.4999, 0.5277, 0.5220, 0.5112, 0.4920, 0.4967,\n",
      "        0.5363, 0.5229, 0.5316, 0.5256, 0.4805, 0.5113, 0.5203, 0.4912, 0.4887,\n",
      "        0.5357, 0.4849, 0.5135, 0.5728, 0.4681, 0.4650, 0.5509, 0.5546, 0.5240,\n",
      "        0.5701, 0.5418, 0.4906, 0.6054, 0.5152, 0.4972, 0.5636, 0.5255, 0.5409,\n",
      "        0.5364, 0.5012, 0.5355, 0.4730, 0.4791, 0.5185, 0.5622, 0.4744, 0.5231,\n",
      "        0.5193, 0.5147, 0.5065, 0.5358, 0.5270, 0.5108, 0.5263, 0.4692, 0.4931,\n",
      "        0.4881, 0.4986, 0.5190, 0.4822, 0.5016, 0.4917, 0.4827, 0.5094, 0.5490,\n",
      "        0.5354, 0.5121, 0.5632, 0.5804, 0.5243, 0.5300, 0.4938, 0.5775, 0.4782,\n",
      "        0.4810, 0.5439, 0.4771, 0.5092, 0.5062, 0.5195, 0.5360, 0.4842, 0.5010,\n",
      "        0.4868], grad_fn=<CatBackward0>)\n",
      "var of recall: tensor(0.0008, grad_fn=<SubBackward0>)\n",
      "mean of recall tensor(0.5173, grad_fn=<MeanBackward0>)\n",
      "meta_loss: tensor(0.0008, grad_fn=<SubBackward0>)\n",
      "recall_true: tensor(0.4907)\n",
      "ENN_loss: tensor(0.0538, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0737, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0917, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0567, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0676, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0747, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0820, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0440, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0759, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0510, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0697, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0726, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0546, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0473, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0732, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0756, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1000, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0694, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0552, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0301, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0909, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0600, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0572, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0551, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0865, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0987, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0462, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0819, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0440, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0619, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0727, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0745, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0522, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0700, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0735, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0603, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0648, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0698, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0593, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0626, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0522, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0435, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1012, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0748, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0491, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0671, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0829, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0571, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0882, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0810, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0542, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0451, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0752, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0590, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0581, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0755, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0481, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0787, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0474, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0783, grad_fn=<MeanBackward0>)\n",
      "recall list tensor([0.4632, 0.5350, 0.5337, 0.5010, 0.5223, 0.5332, 0.5116, 0.5219, 0.4895,\n",
      "        0.5564, 0.5125, 0.5546, 0.5561, 0.5185, 0.4972, 0.5178, 0.4992, 0.5448,\n",
      "        0.4516, 0.5370, 0.5131, 0.5332, 0.4908, 0.4725, 0.5573, 0.5317, 0.5142,\n",
      "        0.4711, 0.5148, 0.5265, 0.5250, 0.5302, 0.4969, 0.5318, 0.5273, 0.5129,\n",
      "        0.5330, 0.5156, 0.5284, 0.4960, 0.5413, 0.4870, 0.5034, 0.5085, 0.5157,\n",
      "        0.5182, 0.5121, 0.5222, 0.5053, 0.5118, 0.4792, 0.5059, 0.5450, 0.5220,\n",
      "        0.5239, 0.5188, 0.5140, 0.5610, 0.5200, 0.5581, 0.4694, 0.4998, 0.5288,\n",
      "        0.5566, 0.4840, 0.5412, 0.5467, 0.4990, 0.5397, 0.4786, 0.5047, 0.5192,\n",
      "        0.5058, 0.5357, 0.5186, 0.5285, 0.5248, 0.5079, 0.5067, 0.5055, 0.5233,\n",
      "        0.5046, 0.5067, 0.4913, 0.4810, 0.5275, 0.5045, 0.4957, 0.5110, 0.5013,\n",
      "        0.5067, 0.5031, 0.5465, 0.5535, 0.5188, 0.5026, 0.5454, 0.5385, 0.4961,\n",
      "        0.5167], grad_fn=<CatBackward0>)\n",
      "var of recall: tensor(0.0005, grad_fn=<SubBackward0>)\n",
      "mean of recall tensor(0.5163, grad_fn=<MeanBackward0>)\n",
      "meta_loss: tensor(0.0005, grad_fn=<SubBackward0>)\n",
      "recall_true: tensor(0.4907)\n",
      "ENN_loss: tensor(0.0914, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0451, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0619, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0833, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0572, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0396, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0782, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1102, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0801, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0666, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0579, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0665, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0529, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0693, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1003, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0637, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0902, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0554, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0640, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1038, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0845, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0615, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0885, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0685, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0785, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0640, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0762, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0775, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1299, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0427, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0591, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0675, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0624, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0712, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0370, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1229, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0527, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0885, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0793, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0639, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0349, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0829, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0632, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1111, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0586, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0736, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0670, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0700, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0863, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0571, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0950, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0573, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0754, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0619, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0938, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0679, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0697, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0750, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0619, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0638, grad_fn=<MeanBackward0>)\n",
      "recall list tensor([0.5219, 0.5025, 0.5377, 0.5248, 0.5004, 0.5270, 0.5401, 0.5113, 0.5208,\n",
      "        0.5524, 0.5198, 0.4979, 0.5172, 0.5038, 0.5333, 0.4949, 0.5001, 0.5023,\n",
      "        0.5428, 0.4989, 0.5278, 0.4771, 0.5261, 0.5379, 0.4888, 0.5448, 0.5206,\n",
      "        0.5271, 0.4949, 0.5160, 0.4985, 0.4912, 0.5152, 0.5030, 0.5367, 0.5264,\n",
      "        0.5393, 0.5171, 0.5436, 0.5353, 0.5227, 0.5329, 0.5011, 0.5254, 0.4885,\n",
      "        0.5144, 0.5083, 0.5120, 0.5146, 0.5164, 0.4969, 0.5294, 0.5338, 0.5059,\n",
      "        0.5309, 0.5238, 0.5393, 0.5148, 0.5154, 0.5107, 0.5246, 0.5068, 0.4778,\n",
      "        0.5116, 0.5186, 0.5109, 0.5520, 0.5333, 0.4832, 0.4745, 0.5169, 0.4950,\n",
      "        0.5245, 0.5013, 0.5345, 0.5133, 0.5210, 0.5242, 0.5375, 0.4945, 0.5066,\n",
      "        0.5035, 0.5181, 0.4822, 0.4952, 0.4959, 0.4898, 0.5441, 0.5051, 0.4925,\n",
      "        0.5063, 0.5158, 0.5263, 0.5165, 0.4936, 0.5052, 0.5205, 0.4930, 0.5216,\n",
      "        0.5175], grad_fn=<CatBackward0>)\n",
      "var of recall: tensor(0.0003, grad_fn=<SubBackward0>)\n",
      "mean of recall tensor(0.5146, grad_fn=<MeanBackward0>)\n",
      "meta_loss: tensor(0.0003, grad_fn=<SubBackward0>)\n",
      "recall_true: tensor(0.4907)\n",
      "ENN_loss: tensor(0.0532, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1024, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0540, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0811, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0627, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0811, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0464, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0921, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0364, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1133, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0734, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0944, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0634, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0782, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1824, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0690, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0567, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0664, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0648, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0891, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0842, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0746, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0744, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0592, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0522, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0686, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0944, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0763, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0863, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0267, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0685, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0927, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0532, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0852, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0859, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0651, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0820, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0725, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0938, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0570, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0771, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0501, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0803, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0999, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0542, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0898, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0627, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0722, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0768, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0763, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0501, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0800, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0784, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0747, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0838, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0482, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0728, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0502, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0698, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1012, grad_fn=<MeanBackward0>)\n",
      "recall list tensor([0.5255, 0.5066, 0.5424, 0.5308, 0.5120, 0.5017, 0.5112, 0.5343, 0.5166,\n",
      "        0.4897, 0.5114, 0.4903, 0.5236, 0.5261, 0.5210, 0.5280, 0.5305, 0.4951,\n",
      "        0.4753, 0.5140, 0.5179, 0.5221, 0.5235, 0.5177, 0.5306, 0.5351, 0.5186,\n",
      "        0.5229, 0.5059, 0.5382, 0.5095, 0.4936, 0.5056, 0.5060, 0.4826, 0.5242,\n",
      "        0.4982, 0.4907, 0.4982, 0.4720, 0.5290, 0.5054, 0.5011, 0.5003, 0.5145,\n",
      "        0.5130, 0.5445, 0.5026, 0.5183, 0.5211, 0.5202, 0.5079, 0.4970, 0.5070,\n",
      "        0.5213, 0.5375, 0.5367, 0.5364, 0.5186, 0.4973, 0.5005, 0.5094, 0.5335,\n",
      "        0.5150, 0.5311, 0.5240, 0.5069, 0.5173, 0.5255, 0.5003, 0.5373, 0.5330,\n",
      "        0.5418, 0.5278, 0.5101, 0.5330, 0.5121, 0.5165, 0.5185, 0.5314, 0.5161,\n",
      "        0.5469, 0.4967, 0.5122, 0.4972, 0.5121, 0.5002, 0.5187, 0.5324, 0.4817,\n",
      "        0.5211, 0.5400, 0.5063, 0.4944, 0.5051, 0.5354, 0.5119, 0.5182, 0.5159,\n",
      "        0.5391], grad_fn=<CatBackward0>)\n",
      "var of recall: tensor(0.0003, grad_fn=<SubBackward0>)\n",
      "mean of recall tensor(0.5156, grad_fn=<MeanBackward0>)\n",
      "meta_loss: tensor(0.0003, grad_fn=<SubBackward0>)\n",
      "recall_true: tensor(0.4907)\n",
      "ENN_loss: tensor(0.0602, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0875, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0531, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0977, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0779, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0796, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0621, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0533, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0651, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0587, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1077, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0507, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0543, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1012, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0483, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0722, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0710, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0666, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0429, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1071, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0518, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0474, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0935, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0949, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0736, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0677, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0837, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0600, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0851, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0648, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0547, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0815, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0814, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0690, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0516, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0713, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0668, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0802, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0508, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0968, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0960, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0458, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0558, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0840, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0721, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0457, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0836, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0785, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0820, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0614, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0824, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0531, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0659, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0767, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0812, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0538, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0656, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0611, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0669, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0861, grad_fn=<MeanBackward0>)\n",
      "recall list tensor([0.4830, 0.4957, 0.4976, 0.5406, 0.4695, 0.5303, 0.5119, 0.5335, 0.5137,\n",
      "        0.5211, 0.4730, 0.4981, 0.5467, 0.5371, 0.5043, 0.5242, 0.5164, 0.5598,\n",
      "        0.5446, 0.4916, 0.5308, 0.5192, 0.5246, 0.5250, 0.5229, 0.5080, 0.4993,\n",
      "        0.5138, 0.5230, 0.4921, 0.5303, 0.5140, 0.5242, 0.5026, 0.4764, 0.5293,\n",
      "        0.5272, 0.4875, 0.4952, 0.5446, 0.5503, 0.5154, 0.5188, 0.5109, 0.5296,\n",
      "        0.5135, 0.5202, 0.5576, 0.5202, 0.4924, 0.5248, 0.5195, 0.5210, 0.5271,\n",
      "        0.5020, 0.5194, 0.5532, 0.5403, 0.4854, 0.5157, 0.4970, 0.5292, 0.5000,\n",
      "        0.5234, 0.5065, 0.4979, 0.5023, 0.4812, 0.4959, 0.5109, 0.5406, 0.5080,\n",
      "        0.5024, 0.5217, 0.5235, 0.5066, 0.5253, 0.5174, 0.5122, 0.5433, 0.5328,\n",
      "        0.5077, 0.5058, 0.5271, 0.5450, 0.5099, 0.5159, 0.5017, 0.5122, 0.4920,\n",
      "        0.5240, 0.4878, 0.5046, 0.5338, 0.5049, 0.4839, 0.4919, 0.5032, 0.5254,\n",
      "        0.5267], grad_fn=<CatBackward0>)\n",
      "var of recall: tensor(0.0004, grad_fn=<SubBackward0>)\n",
      "mean of recall tensor(0.5150, grad_fn=<MeanBackward0>)\n",
      "meta_loss: tensor(0.0004, grad_fn=<SubBackward0>)\n",
      "recall_true: tensor(0.4907)\n",
      "ENN_loss: tensor(0.0213, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1052, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0795, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0953, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0588, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0832, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0490, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0938, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0636, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1048, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0578, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0629, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0668, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1036, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0682, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0575, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0774, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0709, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0822, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0687, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0896, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0400, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0596, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0928, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0890, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0509, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0777, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0540, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0723, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0837, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0798, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0521, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0972, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0636, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0392, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0693, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0504, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0833, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0645, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0876, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0825, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0614, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0510, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0836, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0763, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0823, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0618, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0649, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0740, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0805, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0475, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0955, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0604, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0827, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0851, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0702, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0699, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0733, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0422, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0757, grad_fn=<MeanBackward0>)\n",
      "recall list tensor([0.5112, 0.5368, 0.5110, 0.5157, 0.5211, 0.5389, 0.5373, 0.5000, 0.4936,\n",
      "        0.5253, 0.5279, 0.4792, 0.5287, 0.4942, 0.5169, 0.5140, 0.5041, 0.5238,\n",
      "        0.4652, 0.5317, 0.5247, 0.5120, 0.5420, 0.5382, 0.5417, 0.5288, 0.5392,\n",
      "        0.5277, 0.5101, 0.5373, 0.5136, 0.5218, 0.4926, 0.5468, 0.4858, 0.5425,\n",
      "        0.5208, 0.5360, 0.4677, 0.5056, 0.5307, 0.5039, 0.5241, 0.5120, 0.5556,\n",
      "        0.5385, 0.5205, 0.5130, 0.5157, 0.5240, 0.4951, 0.5031, 0.5123, 0.5630,\n",
      "        0.5106, 0.5015, 0.5351, 0.5170, 0.5250, 0.4820, 0.5227, 0.4913, 0.5114,\n",
      "        0.4905, 0.5366, 0.5026, 0.5345, 0.4983, 0.5179, 0.5249, 0.5180, 0.5362,\n",
      "        0.5061, 0.5158, 0.5160, 0.5204, 0.5218, 0.5408, 0.5222, 0.5121, 0.5090,\n",
      "        0.5330, 0.5525, 0.5361, 0.5322, 0.5388, 0.5149, 0.5080, 0.5300, 0.5217,\n",
      "        0.5452, 0.5165, 0.5020, 0.5282, 0.5196, 0.5184, 0.4994, 0.5349, 0.5316,\n",
      "        0.5173], grad_fn=<CatBackward0>)\n",
      "var of recall: tensor(0.0003, grad_fn=<SubBackward0>)\n",
      "mean of recall tensor(0.5192, grad_fn=<MeanBackward0>)\n",
      "meta_loss: tensor(0.0003, grad_fn=<SubBackward0>)\n",
      "recall_true: tensor(0.4907)\n",
      "ENN_loss: tensor(0.1106, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0403, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0812, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0690, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0571, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0810, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0503, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0652, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0633, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0848, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0783, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0619, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0732, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0495, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0689, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0898, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0713, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0726, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0935, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0629, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0733, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0644, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0543, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0873, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1113, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0700, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0532, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0575, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0796, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0932, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0895, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0546, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0896, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0766, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0518, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0593, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0629, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0724, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0777, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0861, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0742, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0664, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0583, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0861, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0616, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0617, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0749, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0916, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0929, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0579, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0628, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0778, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0612, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0852, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0676, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0924, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0394, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0833, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0917, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0767, grad_fn=<MeanBackward0>)\n",
      "recall list tensor([0.5249, 0.5284, 0.5028, 0.5108, 0.5114, 0.4850, 0.5289, 0.5331, 0.5247,\n",
      "        0.5128, 0.5200, 0.4935, 0.5144, 0.5178, 0.5200, 0.4885, 0.5319, 0.5044,\n",
      "        0.4907, 0.5446, 0.5150, 0.5047, 0.5121, 0.5410, 0.4863, 0.5262, 0.5184,\n",
      "        0.5292, 0.5366, 0.5148, 0.5274, 0.5219, 0.5028, 0.5254, 0.5229, 0.5189,\n",
      "        0.5179, 0.5261, 0.5164, 0.5396, 0.5319, 0.5158, 0.5376, 0.5015, 0.5375,\n",
      "        0.5203, 0.5161, 0.5508, 0.5138, 0.5067, 0.5409, 0.5012, 0.5164, 0.5537,\n",
      "        0.5343, 0.4925, 0.5095, 0.4892, 0.5169, 0.5350, 0.5236, 0.4808, 0.5103,\n",
      "        0.5170, 0.5105, 0.5112, 0.5246, 0.4970, 0.5048, 0.5180, 0.5111, 0.5082,\n",
      "        0.5113, 0.5117, 0.5206, 0.5429, 0.4890, 0.5419, 0.5197, 0.5640, 0.5367,\n",
      "        0.5138, 0.5350, 0.5089, 0.5190, 0.5143, 0.5297, 0.5074, 0.5102, 0.5479,\n",
      "        0.5086, 0.4844, 0.4716, 0.5406, 0.5272, 0.5245, 0.5243, 0.5525, 0.5151,\n",
      "        0.4944], grad_fn=<CatBackward0>)\n",
      "var of recall: tensor(0.0003, grad_fn=<SubBackward0>)\n",
      "mean of recall tensor(0.5180, grad_fn=<MeanBackward0>)\n",
      "meta_loss: tensor(0.0003, grad_fn=<SubBackward0>)\n",
      "recall_true: tensor(0.4907)\n",
      "ENN_loss: tensor(0.0490, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0509, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0842, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0674, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0779, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0764, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0374, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0763, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0719, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0648, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0638, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0698, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0300, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1714, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0406, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0823, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0625, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0832, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0628, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0875, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0536, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0886, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0479, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1084, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0801, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0687, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0547, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0435, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1263, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0380, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0594, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0398, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0624, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0564, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0868, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0863, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0683, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0675, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0551, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0765, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0650, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0693, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0736, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0694, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1088, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0518, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0791, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0598, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0570, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0565, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0995, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0675, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0540, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0793, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0673, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0657, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0410, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0694, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0651, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0780, grad_fn=<MeanBackward0>)\n",
      "recall list tensor([0.5302, 0.5175, 0.5094, 0.5193, 0.5138, 0.5447, 0.5096, 0.5006, 0.5042,\n",
      "        0.5133, 0.5468, 0.5335, 0.5141, 0.4944, 0.4987, 0.4882, 0.4753, 0.5261,\n",
      "        0.5061, 0.5364, 0.5260, 0.4865, 0.5276, 0.5279, 0.5102, 0.5367, 0.5184,\n",
      "        0.5062, 0.5617, 0.5318, 0.5188, 0.5285, 0.4948, 0.5464, 0.4911, 0.5145,\n",
      "        0.5099, 0.4726, 0.5110, 0.5290, 0.5162, 0.4762, 0.4865, 0.4985, 0.5012,\n",
      "        0.5311, 0.4874, 0.5182, 0.5150, 0.5391, 0.5080, 0.5072, 0.5106, 0.5347,\n",
      "        0.5213, 0.5127, 0.5463, 0.5193, 0.5063, 0.4637, 0.5665, 0.5337, 0.5276,\n",
      "        0.5284, 0.5171, 0.5476, 0.5384, 0.5388, 0.5190, 0.5358, 0.4657, 0.5064,\n",
      "        0.5180, 0.5405, 0.5028, 0.5238, 0.4729, 0.5245, 0.5155, 0.4928, 0.5100,\n",
      "        0.4946, 0.5143, 0.5170, 0.4917, 0.4839, 0.4919, 0.5059, 0.5021, 0.5688,\n",
      "        0.5284, 0.5239, 0.4964, 0.5395, 0.5184, 0.5022, 0.5310, 0.5035, 0.4877,\n",
      "        0.4936], grad_fn=<CatBackward0>)\n",
      "var of recall: tensor(0.0004, grad_fn=<SubBackward0>)\n",
      "mean of recall tensor(0.5145, grad_fn=<MeanBackward0>)\n",
      "meta_loss: tensor(0.0004, grad_fn=<SubBackward0>)\n",
      "recall_true: tensor(0.4907)\n",
      "ENN_loss: tensor(0.0486, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1025, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0710, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0778, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1021, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0646, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0736, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0520, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0609, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0954, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0964, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0652, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0721, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0798, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0596, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0676, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0799, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0584, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0761, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0740, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0667, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0686, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0605, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0892, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0964, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0555, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0872, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0442, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0998, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0378, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0777, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0508, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0576, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0954, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0603, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0841, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0703, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0685, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0889, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0646, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0705, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0890, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0748, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0581, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0722, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0726, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1071, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0394, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0830, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0601, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0797, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0568, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0841, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0511, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0913, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0498, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0819, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0981, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0762, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0353, grad_fn=<MeanBackward0>)\n",
      "recall list tensor([0.5337, 0.5242, 0.5263, 0.4836, 0.5215, 0.5101, 0.5070, 0.5240, 0.5503,\n",
      "        0.5643, 0.5208, 0.5006, 0.4983, 0.5068, 0.5038, 0.5468, 0.5001, 0.5242,\n",
      "        0.5109, 0.5114, 0.5182, 0.5092, 0.5019, 0.5206, 0.5210, 0.5046, 0.5165,\n",
      "        0.5227, 0.4960, 0.5088, 0.4951, 0.5173, 0.4912, 0.4950, 0.5000, 0.5383,\n",
      "        0.5025, 0.5480, 0.5240, 0.4978, 0.5142, 0.5208, 0.4924, 0.5049, 0.5031,\n",
      "        0.5321, 0.5294, 0.4896, 0.5206, 0.5297, 0.5193, 0.5031, 0.5463, 0.5298,\n",
      "        0.5103, 0.5266, 0.4850, 0.5078, 0.5194, 0.5053, 0.4847, 0.5385, 0.4998,\n",
      "        0.5225, 0.5182, 0.5256, 0.5167, 0.5257, 0.5092, 0.4993, 0.4933, 0.5153,\n",
      "        0.5180, 0.5344, 0.5428, 0.5321, 0.5164, 0.5043, 0.5035, 0.5003, 0.4975,\n",
      "        0.5362, 0.5228, 0.5448, 0.5114, 0.5090, 0.5275, 0.5033, 0.5071, 0.5154,\n",
      "        0.5072, 0.5008, 0.5671, 0.4974, 0.4965, 0.5227, 0.4974, 0.5184, 0.5315,\n",
      "        0.4637], grad_fn=<CatBackward0>)\n",
      "var of recall: tensor(0.0003, grad_fn=<SubBackward0>)\n",
      "mean of recall tensor(0.5147, grad_fn=<MeanBackward0>)\n",
      "meta_loss: tensor(0.0003, grad_fn=<SubBackward0>)\n",
      "recall_true: tensor(0.4907)\n",
      "ENN_loss: tensor(0.0684, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0455, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0604, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0748, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0569, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0366, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1182, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0884, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0318, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0586, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0845, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0746, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0594, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0932, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0929, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0449, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0595, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0840, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0992, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0416, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0588, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0958, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0664, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0319, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0576, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1082, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0467, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0749, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0508, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0821, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0421, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1015, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0754, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0435, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0479, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0853, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0712, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1340, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0361, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0478, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0811, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0848, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0578, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0484, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0662, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0660, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0634, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0608, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0639, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0628, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0631, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0584, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0565, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0618, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0865, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0494, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0840, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0621, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0652, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0340, grad_fn=<MeanBackward0>)\n",
      "recall list tensor([0.5690, 0.5411, 0.5156, 0.5132, 0.5258, 0.5383, 0.5218, 0.5223, 0.5306,\n",
      "        0.5135, 0.5182, 0.5368, 0.4746, 0.5091, 0.5146, 0.4876, 0.5231, 0.5135,\n",
      "        0.4990, 0.5128, 0.5015, 0.5047, 0.5128, 0.5249, 0.4846, 0.5333, 0.5068,\n",
      "        0.5568, 0.5107, 0.5110, 0.5266, 0.5554, 0.5438, 0.5375, 0.5076, 0.5319,\n",
      "        0.5087, 0.5063, 0.5273, 0.5140, 0.4904, 0.5117, 0.5441, 0.5228, 0.5266,\n",
      "        0.4744, 0.5614, 0.5219, 0.5163, 0.4839, 0.5128, 0.5538, 0.5075, 0.4916,\n",
      "        0.4971, 0.5373, 0.5209, 0.4627, 0.4958, 0.4718, 0.4962, 0.5351, 0.5107,\n",
      "        0.5129, 0.5316, 0.5192, 0.4973, 0.4751, 0.5153, 0.4777, 0.5244, 0.5185,\n",
      "        0.5015, 0.5445, 0.5315, 0.5231, 0.5213, 0.5394, 0.5384, 0.5186, 0.4970,\n",
      "        0.5236, 0.5266, 0.4982, 0.5179, 0.5430, 0.4997, 0.5211, 0.4678, 0.5467,\n",
      "        0.4858, 0.4899, 0.5057, 0.5025, 0.5303, 0.5318, 0.4924, 0.5135, 0.4841,\n",
      "        0.5314], grad_fn=<CatBackward0>)\n",
      "var of recall: tensor(0.0005, grad_fn=<SubBackward0>)\n",
      "mean of recall tensor(0.5153, grad_fn=<MeanBackward0>)\n",
      "meta_loss: tensor(0.0005, grad_fn=<SubBackward0>)\n",
      "recall_true: tensor(0.4907)\n",
      "ENN_loss: tensor(0.0591, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0902, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0695, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0487, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0635, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0594, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0348, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0731, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0508, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0589, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0534, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0584, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0226, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0710, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0759, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0730, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0527, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0714, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0639, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0510, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0380, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0671, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0474, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0623, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0569, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0631, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0432, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0616, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0570, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0600, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0730, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0495, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0373, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0521, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0634, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0531, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0272, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0743, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0469, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0557, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0403, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0567, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0484, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0625, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0526, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0642, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0666, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0526, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0637, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0540, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0598, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0486, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0592, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0311, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0791, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0488, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0785, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0271, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0381, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0836, grad_fn=<MeanBackward0>)\n",
      "recall list tensor([0.5881, 0.4685, 0.5733, 0.5294, 0.5134, 0.5196, 0.5026, 0.5208, 0.4877,\n",
      "        0.5256, 0.5481, 0.5247, 0.4871, 0.5684, 0.5054, 0.4857, 0.5330, 0.5484,\n",
      "        0.5168, 0.5043, 0.4782, 0.5313, 0.5116, 0.5339, 0.4799, 0.5554, 0.4721,\n",
      "        0.5021, 0.5472, 0.5881, 0.4932, 0.5470, 0.5641, 0.5587, 0.5109, 0.5040,\n",
      "        0.5864, 0.5887, 0.5253, 0.5415, 0.5419, 0.5163, 0.5886, 0.5277, 0.4988,\n",
      "        0.5394, 0.5195, 0.5028, 0.5179, 0.4914, 0.5667, 0.5215, 0.5294, 0.5171,\n",
      "        0.5496, 0.5410, 0.5379, 0.5355, 0.5044, 0.4901, 0.5191, 0.5485, 0.5280,\n",
      "        0.4812, 0.4482, 0.4896, 0.5311, 0.5368, 0.5158, 0.5694, 0.5443, 0.5353,\n",
      "        0.4729, 0.5064, 0.4853, 0.5519, 0.5531, 0.5325, 0.4816, 0.5092, 0.5491,\n",
      "        0.4908, 0.5144, 0.5644, 0.4891, 0.4922, 0.5080, 0.5315, 0.5651, 0.5213,\n",
      "        0.5611, 0.5047, 0.5643, 0.5324, 0.5090, 0.5132, 0.4736, 0.5196, 0.4297,\n",
      "        0.5185], grad_fn=<CatBackward0>)\n",
      "var of recall: tensor(0.0010, grad_fn=<SubBackward0>)\n",
      "mean of recall tensor(0.5230, grad_fn=<MeanBackward0>)\n",
      "meta_loss: tensor(0.0010, grad_fn=<SubBackward0>)\n",
      "recall_true: tensor(0.4907)\n",
      "ENN_loss: tensor(0.0474, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0851, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0607, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0908, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0402, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0833, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0831, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0440, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0586, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0551, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0748, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0684, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0522, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0573, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0717, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1062, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0512, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0791, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0612, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0722, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0654, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0770, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0332, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0831, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0797, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0569, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0770, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0621, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0752, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0551, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0849, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0831, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0666, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0793, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0593, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0501, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0958, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0559, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0568, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0602, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0622, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0910, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0510, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0653, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0706, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0554, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0944, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0570, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0682, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0796, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0878, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0356, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0891, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0775, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0417, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0632, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0733, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0619, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0699, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0597, grad_fn=<MeanBackward0>)\n",
      "recall list tensor([0.5120, 0.4810, 0.5405, 0.5004, 0.5413, 0.5250, 0.5580, 0.4786, 0.5210,\n",
      "        0.5225, 0.5271, 0.4935, 0.5043, 0.5208, 0.4870, 0.5275, 0.5137, 0.4882,\n",
      "        0.5180, 0.5278, 0.5145, 0.5442, 0.5376, 0.5033, 0.4913, 0.4937, 0.5188,\n",
      "        0.4950, 0.5037, 0.5376, 0.4944, 0.4833, 0.5074, 0.5223, 0.4835, 0.4828,\n",
      "        0.4958, 0.5261, 0.5118, 0.4945, 0.5036, 0.4984, 0.5651, 0.5537, 0.5105,\n",
      "        0.4877, 0.4833, 0.5337, 0.4848, 0.5173, 0.4923, 0.4875, 0.5109, 0.5580,\n",
      "        0.4695, 0.5165, 0.5317, 0.4688, 0.5093, 0.5214, 0.5407, 0.5058, 0.4688,\n",
      "        0.5127, 0.4811, 0.4987, 0.5494, 0.5559, 0.5503, 0.5160, 0.4886, 0.5162,\n",
      "        0.5140, 0.4815, 0.5370, 0.5109, 0.4866, 0.5190, 0.5818, 0.5154, 0.5190,\n",
      "        0.5579, 0.5278, 0.5029, 0.5767, 0.4905, 0.5285, 0.5000, 0.5448, 0.5495,\n",
      "        0.5446, 0.5384, 0.5074, 0.5252, 0.4929, 0.5507, 0.5335, 0.4957, 0.5005,\n",
      "        0.5029], grad_fn=<CatBackward0>)\n",
      "var of recall: tensor(0.0006, grad_fn=<SubBackward0>)\n",
      "mean of recall tensor(0.5145, grad_fn=<MeanBackward0>)\n",
      "meta_loss: tensor(0.0006, grad_fn=<SubBackward0>)\n",
      "recall_true: tensor(0.4907)\n",
      "ENN_loss: tensor(0.0899, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0544, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0682, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0615, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1089, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0354, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0798, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0627, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0473, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0738, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0519, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0878, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1054, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0809, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0600, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0316, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0669, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0666, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0709, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0824, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0667, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0587, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0788, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0702, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0527, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0960, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0689, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0657, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0444, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1157, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0582, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0740, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0598, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0848, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0666, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0689, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0622, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0675, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0515, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1020, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0760, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0950, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0580, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0527, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0859, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0578, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0797, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0508, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0679, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0518, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0630, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0933, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0707, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0800, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0542, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0659, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0515, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0683, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0644, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0851, grad_fn=<MeanBackward0>)\n",
      "recall list tensor([0.5121, 0.5147, 0.5228, 0.5089, 0.4900, 0.5136, 0.5245, 0.5116, 0.5175,\n",
      "        0.5064, 0.5076, 0.5492, 0.5316, 0.5124, 0.5319, 0.4928, 0.5082, 0.4893,\n",
      "        0.5007, 0.5285, 0.5132, 0.5316, 0.5089, 0.5236, 0.5388, 0.5455, 0.5235,\n",
      "        0.5209, 0.5521, 0.5246, 0.5172, 0.4862, 0.5082, 0.4839, 0.5443, 0.5061,\n",
      "        0.4958, 0.4926, 0.4923, 0.4958, 0.5103, 0.5245, 0.4973, 0.4748, 0.5568,\n",
      "        0.4969, 0.5228, 0.5101, 0.4892, 0.5098, 0.5333, 0.5321, 0.5353, 0.5079,\n",
      "        0.5363, 0.5238, 0.5366, 0.5765, 0.4957, 0.5317, 0.5174, 0.5085, 0.4642,\n",
      "        0.4899, 0.5230, 0.5190, 0.4815, 0.4737, 0.4934, 0.5059, 0.5335, 0.5237,\n",
      "        0.5072, 0.4987, 0.5052, 0.5153, 0.5063, 0.5372, 0.5076, 0.5315, 0.5145,\n",
      "        0.5189, 0.5186, 0.4994, 0.5051, 0.4973, 0.5146, 0.5239, 0.5109, 0.4841,\n",
      "        0.5199, 0.4994, 0.5097, 0.5264, 0.5350, 0.5323, 0.5118, 0.5237, 0.5157,\n",
      "        0.5044], grad_fn=<CatBackward0>)\n",
      "var of recall: tensor(0.0004, grad_fn=<SubBackward0>)\n",
      "mean of recall tensor(0.5139, grad_fn=<MeanBackward0>)\n",
      "meta_loss: tensor(0.0004, grad_fn=<SubBackward0>)\n",
      "recall_true: tensor(0.4907)\n",
      "ENN_loss: tensor(0.0575, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0900, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0823, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0668, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0752, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0675, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0589, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0908, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0690, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0746, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0645, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0682, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0644, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1236, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0655, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0623, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0596, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0795, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0505, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0966, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0776, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0732, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0787, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0401, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0812, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1174, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0553, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0447, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0616, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0640, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0695, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0697, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0612, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0786, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0993, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0388, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0693, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0809, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0650, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0541, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0550, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0792, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0786, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0504, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0659, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0673, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0635, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0623, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0541, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0786, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0648, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0766, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0446, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0763, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0659, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0911, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0657, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0816, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0512, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0670, grad_fn=<MeanBackward0>)\n",
      "recall list tensor([0.5249, 0.5050, 0.5300, 0.5332, 0.5084, 0.5526, 0.4936, 0.5210, 0.4986,\n",
      "        0.5298, 0.5008, 0.5516, 0.4964, 0.5433, 0.4649, 0.4983, 0.5138, 0.5057,\n",
      "        0.5278, 0.5140, 0.4673, 0.5351, 0.4976, 0.5337, 0.5240, 0.5214, 0.5230,\n",
      "        0.5464, 0.5312, 0.5378, 0.4954, 0.4887, 0.5074, 0.4762, 0.5089, 0.5213,\n",
      "        0.5385, 0.5045, 0.5098, 0.5126, 0.5114, 0.4929, 0.5233, 0.5312, 0.5018,\n",
      "        0.5203, 0.4897, 0.5267, 0.5205, 0.5140, 0.5445, 0.4747, 0.5250, 0.5227,\n",
      "        0.5293, 0.5123, 0.5278, 0.5392, 0.5528, 0.5295, 0.5080, 0.5315, 0.5380,\n",
      "        0.5328, 0.5275, 0.4834, 0.4864, 0.4989, 0.5178, 0.5203, 0.4961, 0.5167,\n",
      "        0.5515, 0.5053, 0.5321, 0.4878, 0.5192, 0.4846, 0.5282, 0.5345, 0.5156,\n",
      "        0.5219, 0.5094, 0.5048, 0.5104, 0.5278, 0.4952, 0.5237, 0.5011, 0.4719,\n",
      "        0.4982, 0.4946, 0.5238, 0.4954, 0.5215, 0.4696, 0.5277, 0.5059, 0.5698,\n",
      "        0.5111], grad_fn=<CatBackward0>)\n",
      "var of recall: tensor(0.0004, grad_fn=<SubBackward0>)\n",
      "mean of recall tensor(0.5148, grad_fn=<MeanBackward0>)\n",
      "meta_loss: tensor(0.0004, grad_fn=<SubBackward0>)\n",
      "recall_true: tensor(0.4907)\n",
      "ENN_loss: tensor(0.0350, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1526, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0945, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0530, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0494, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0911, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0431, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0969, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0869, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0713, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0616, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0392, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0834, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0988, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0529, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0364, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0399, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0840, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1059, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0442, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0897, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0597, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0679, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0447, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0805, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0628, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0439, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0918, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0683, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0719, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0864, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0637, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0481, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0929, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0647, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0725, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0746, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0718, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0846, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0523, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0566, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0637, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0801, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0673, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0516, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0634, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0833, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0843, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0547, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0516, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0898, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0732, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1070, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0577, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0592, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0558, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1021, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0603, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0669, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0472, grad_fn=<MeanBackward0>)\n",
      "recall list tensor([0.5401, 0.4969, 0.4906, 0.4995, 0.5116, 0.5326, 0.4816, 0.4969, 0.4981,\n",
      "        0.4961, 0.5192, 0.5290, 0.5573, 0.5284, 0.5152, 0.4639, 0.5339, 0.5145,\n",
      "        0.5104, 0.5080, 0.5150, 0.4966, 0.4625, 0.5193, 0.5192, 0.4907, 0.4881,\n",
      "        0.5082, 0.4947, 0.5334, 0.4950, 0.5076, 0.4626, 0.5085, 0.5397, 0.5137,\n",
      "        0.5172, 0.5490, 0.5144, 0.4613, 0.4712, 0.5054, 0.5131, 0.5104, 0.5051,\n",
      "        0.5196, 0.5161, 0.4845, 0.5267, 0.4950, 0.4977, 0.5151, 0.4742, 0.4849,\n",
      "        0.5130, 0.5152, 0.5106, 0.5194, 0.5133, 0.5160, 0.5429, 0.4928, 0.5181,\n",
      "        0.5250, 0.5056, 0.4760, 0.5101, 0.4799, 0.5413, 0.5421, 0.5057, 0.4726,\n",
      "        0.4914, 0.5099, 0.5106, 0.5305, 0.5265, 0.5334, 0.5202, 0.5075, 0.5469,\n",
      "        0.4988, 0.5244, 0.5318, 0.5118, 0.5293, 0.5064, 0.5374, 0.4959, 0.4920,\n",
      "        0.5111, 0.5346, 0.5744, 0.5322, 0.5566, 0.5195, 0.5415, 0.5355, 0.5249,\n",
      "        0.5113], grad_fn=<CatBackward0>)\n",
      "var of recall: tensor(0.0005, grad_fn=<SubBackward0>)\n",
      "mean of recall tensor(0.5119, grad_fn=<MeanBackward0>)\n",
      "meta_loss: tensor(0.0005, grad_fn=<SubBackward0>)\n",
      "recall_true: tensor(0.4907)\n",
      "ENN_loss: tensor(0.0531, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0681, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1289, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0587, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0851, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1186, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0520, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0740, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1242, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0936, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0480, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0725, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0739, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0859, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0637, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0764, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0536, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0683, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0703, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0954, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0686, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0624, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0723, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0719, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0382, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0555, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1005, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0830, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0762, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0696, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0837, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0547, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0864, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0458, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0701, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0642, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0592, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0794, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0627, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0757, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0673, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0857, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0785, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0580, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0926, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0923, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0522, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0674, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1136, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0358, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0814, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0588, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0904, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0789, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0947, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0543, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0688, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0996, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0538, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0761, grad_fn=<MeanBackward0>)\n",
      "recall list tensor([0.5413, 0.5121, 0.4909, 0.5006, 0.5005, 0.5041, 0.5450, 0.4945, 0.5334,\n",
      "        0.5434, 0.5278, 0.5319, 0.5142, 0.5170, 0.5584, 0.4644, 0.5311, 0.4912,\n",
      "        0.4964, 0.4892, 0.5036, 0.4797, 0.5190, 0.4952, 0.5049, 0.5120, 0.5289,\n",
      "        0.5162, 0.5144, 0.5113, 0.5560, 0.5213, 0.5176, 0.5098, 0.5509, 0.5066,\n",
      "        0.4952, 0.5151, 0.5097, 0.5061, 0.5461, 0.5270, 0.5117, 0.5083, 0.5186,\n",
      "        0.5445, 0.5321, 0.4975, 0.4838, 0.5381, 0.5176, 0.5211, 0.5096, 0.5094,\n",
      "        0.5508, 0.5103, 0.5010, 0.5051, 0.5342, 0.5206, 0.5062, 0.5384, 0.5084,\n",
      "        0.5381, 0.5311, 0.5076, 0.5317, 0.5380, 0.5407, 0.5095, 0.5413, 0.5137,\n",
      "        0.5100, 0.4931, 0.5135, 0.5044, 0.5121, 0.5084, 0.5344, 0.5191, 0.5348,\n",
      "        0.4999, 0.4943, 0.5252, 0.5312, 0.5116, 0.5399, 0.5200, 0.5238, 0.5386,\n",
      "        0.5247, 0.5493, 0.5244, 0.5239, 0.5569, 0.5067, 0.5245, 0.5108, 0.5358,\n",
      "        0.5269], grad_fn=<CatBackward0>)\n",
      "var of recall: tensor(0.0003, grad_fn=<SubBackward0>)\n",
      "mean of recall tensor(0.5185, grad_fn=<MeanBackward0>)\n",
      "meta_loss: tensor(0.0003, grad_fn=<SubBackward0>)\n",
      "recall_true: tensor(0.4907)\n",
      "ENN_loss: tensor(0.0822, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0606, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0886, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0647, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0786, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0811, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0650, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0791, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0527, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0862, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0432, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0832, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0725, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1145, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0608, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0805, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0771, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0498, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0741, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0761, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0660, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0622, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0648, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0740, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0829, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1074, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0595, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0772, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0579, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0710, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0830, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0676, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0721, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0533, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1013, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0795, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0599, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0779, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0868, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0738, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1085, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0457, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0455, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0692, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0633, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0445, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0859, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1067, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0659, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0823, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0616, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0742, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0809, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0651, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0942, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0582, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0729, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0671, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0471, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0832, grad_fn=<MeanBackward0>)\n",
      "recall list tensor([0.5284, 0.4991, 0.5133, 0.5317, 0.5290, 0.5486, 0.5426, 0.5146, 0.5217,\n",
      "        0.5196, 0.5101, 0.4967, 0.5372, 0.5189, 0.4922, 0.4845, 0.5329, 0.4908,\n",
      "        0.5290, 0.5012, 0.5181, 0.4962, 0.5265, 0.5118, 0.5328, 0.4938, 0.5153,\n",
      "        0.5088, 0.5110, 0.5291, 0.4731, 0.5086, 0.5155, 0.5275, 0.5289, 0.5332,\n",
      "        0.5345, 0.5317, 0.5326, 0.5148, 0.5095, 0.5311, 0.5003, 0.5103, 0.4986,\n",
      "        0.5024, 0.4902, 0.5578, 0.4956, 0.4952, 0.5328, 0.5362, 0.5302, 0.5246,\n",
      "        0.5164, 0.5189, 0.5352, 0.5573, 0.5349, 0.4548, 0.5040, 0.5301, 0.5250,\n",
      "        0.5429, 0.5345, 0.5192, 0.5136, 0.4920, 0.5185, 0.5186, 0.5139, 0.5151,\n",
      "        0.5107, 0.5037, 0.5079, 0.5090, 0.5470, 0.5462, 0.5191, 0.5201, 0.5021,\n",
      "        0.5059, 0.5441, 0.4907, 0.5209, 0.5120, 0.5046, 0.4960, 0.5503, 0.5159,\n",
      "        0.5101, 0.5168, 0.5457, 0.5461, 0.4957, 0.5437, 0.5330, 0.5305, 0.5209,\n",
      "        0.5426], grad_fn=<CatBackward0>)\n",
      "var of recall: tensor(0.0003, grad_fn=<SubBackward0>)\n",
      "mean of recall tensor(0.5184, grad_fn=<MeanBackward0>)\n",
      "meta_loss: tensor(0.0003, grad_fn=<SubBackward0>)\n",
      "recall_true: tensor(0.4907)\n",
      "ENN_loss: tensor(0.0781, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0362, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1032, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0747, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0537, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1305, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0451, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0588, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0638, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1177, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0373, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0598, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0544, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0873, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0923, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0477, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0511, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1229, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0796, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0310, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0661, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0634, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0771, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0750, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0706, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0790, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0741, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0531, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1314, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0566, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0617, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0305, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0802, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0697, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0680, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0617, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0578, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0390, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1036, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0746, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0625, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0513, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0904, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1093, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0841, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0685, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0606, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0771, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0269, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1075, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0574, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0918, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0515, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0682, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0939, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0657, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0507, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0682, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0854, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0724, grad_fn=<MeanBackward0>)\n",
      "recall list tensor([0.5041, 0.5469, 0.5075, 0.5359, 0.5140, 0.4615, 0.4933, 0.4926, 0.5311,\n",
      "        0.5016, 0.5027, 0.4833, 0.5121, 0.5138, 0.5289, 0.5174, 0.5298, 0.5488,\n",
      "        0.5227, 0.4791, 0.5147, 0.5248, 0.5138, 0.5002, 0.5051, 0.5121, 0.5258,\n",
      "        0.5365, 0.4796, 0.5333, 0.5083, 0.4990, 0.5193, 0.5186, 0.5156, 0.5197,\n",
      "        0.4761, 0.5433, 0.5252, 0.5170, 0.4814, 0.4554, 0.5058, 0.4857, 0.5180,\n",
      "        0.5152, 0.4947, 0.5272, 0.4867, 0.5066, 0.5152, 0.4999, 0.5243, 0.5125,\n",
      "        0.5094, 0.4978, 0.5402, 0.5549, 0.5043, 0.4888, 0.4986, 0.5177, 0.5009,\n",
      "        0.5039, 0.5119, 0.5182, 0.5468, 0.5216, 0.5118, 0.5182, 0.5182, 0.5275,\n",
      "        0.4931, 0.5551, 0.5452, 0.5307, 0.5196, 0.5479, 0.5198, 0.5323, 0.5316,\n",
      "        0.5205, 0.5152, 0.5206, 0.5306, 0.5085, 0.4900, 0.5164, 0.4915, 0.4873,\n",
      "        0.5227, 0.5484, 0.5128, 0.5098, 0.4982, 0.4809, 0.5429, 0.4885, 0.5426,\n",
      "        0.4988], grad_fn=<CatBackward0>)\n",
      "var of recall: tensor(0.0004, grad_fn=<SubBackward0>)\n",
      "mean of recall tensor(0.5134, grad_fn=<MeanBackward0>)\n",
      "meta_loss: tensor(0.0004, grad_fn=<SubBackward0>)\n",
      "recall_true: tensor(0.4907)\n",
      "ENN_loss: tensor(0.0902, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0594, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0963, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0405, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0720, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0489, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0787, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0864, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0761, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0710, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1011, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0511, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1296, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0602, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0842, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0476, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0372, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0705, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0670, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0998, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0748, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0515, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0602, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0964, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0602, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0786, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0611, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0768, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0816, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0621, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0536, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0912, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0418, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0732, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0903, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0738, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0538, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0745, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0708, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0713, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0732, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0738, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0625, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0598, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0642, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0654, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0740, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0747, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0853, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0898, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0468, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0577, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0619, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0476, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0662, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1061, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0871, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0768, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0723, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0428, grad_fn=<MeanBackward0>)\n",
      "recall list tensor([0.4991, 0.5227, 0.5177, 0.5546, 0.5412, 0.5584, 0.5112, 0.5128, 0.5568,\n",
      "        0.5195, 0.5182, 0.5189, 0.4925, 0.5018, 0.5437, 0.5108, 0.5045, 0.5509,\n",
      "        0.5239, 0.5004, 0.5511, 0.5398, 0.5169, 0.5029, 0.4856, 0.5153, 0.5160,\n",
      "        0.5104, 0.5007, 0.5498, 0.4952, 0.4895, 0.5390, 0.5116, 0.5152, 0.5207,\n",
      "        0.5532, 0.5037, 0.5194, 0.5208, 0.5126, 0.5203, 0.4994, 0.4880, 0.4982,\n",
      "        0.4723, 0.5071, 0.5090, 0.5108, 0.5294, 0.5085, 0.5366, 0.5040, 0.5215,\n",
      "        0.4947, 0.5393, 0.4811, 0.5137, 0.5420, 0.5108, 0.5364, 0.5035, 0.5207,\n",
      "        0.4929, 0.4919, 0.5135, 0.5255, 0.4968, 0.5027, 0.5352, 0.4878, 0.5159,\n",
      "        0.4978, 0.5295, 0.5304, 0.5232, 0.5166, 0.5343, 0.5315, 0.5091, 0.5041,\n",
      "        0.4976, 0.5051, 0.4987, 0.5151, 0.5504, 0.4951, 0.5176, 0.5171, 0.4783,\n",
      "        0.5434, 0.5200, 0.5203, 0.4946, 0.5054, 0.5146, 0.4968, 0.5089, 0.5458,\n",
      "        0.5083], grad_fn=<CatBackward0>)\n",
      "var of recall: tensor(0.0004, grad_fn=<SubBackward0>)\n",
      "mean of recall tensor(0.5155, grad_fn=<MeanBackward0>)\n",
      "meta_loss: tensor(0.0004, grad_fn=<SubBackward0>)\n",
      "recall_true: tensor(0.4907)\n",
      "ENN_loss: tensor(0.0507, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0528, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0584, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0700, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0423, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0673, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0406, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0659, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0556, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0384, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0565, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0759, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0725, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1012, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0437, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0385, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0561, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0334, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0425, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0816, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0475, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0526, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0594, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0733, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0388, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0602, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0721, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0561, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0577, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0772, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0406, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0700, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0744, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0301, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0405, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0818, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0546, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0347, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0453, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0930, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0449, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0789, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0480, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0637, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0846, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0350, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0437, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0588, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1021, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0615, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0466, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0403, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0509, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0933, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0369, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0550, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0552, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0717, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0577, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0403, grad_fn=<MeanBackward0>)\n",
      "recall list tensor([0.5183, 0.5060, 0.5012, 0.5773, 0.5255, 0.4922, 0.5428, 0.4990, 0.5383,\n",
      "        0.5525, 0.4980, 0.5311, 0.5379, 0.5147, 0.5164, 0.4920, 0.5096, 0.5921,\n",
      "        0.5224, 0.5364, 0.5184, 0.5069, 0.5100, 0.5526, 0.5052, 0.5196, 0.4842,\n",
      "        0.4913, 0.5804, 0.4919, 0.4970, 0.4970, 0.5312, 0.5008, 0.4280, 0.5037,\n",
      "        0.4929, 0.5495, 0.5321, 0.5051, 0.5770, 0.4810, 0.5014, 0.5266, 0.5273,\n",
      "        0.5216, 0.5093, 0.4972, 0.5037, 0.4985, 0.4662, 0.5228, 0.5462, 0.5310,\n",
      "        0.5208, 0.5169, 0.5594, 0.5402, 0.5290, 0.5115, 0.5551, 0.5245, 0.5119,\n",
      "        0.5487, 0.5715, 0.5099, 0.5005, 0.5097, 0.5239, 0.5472, 0.5156, 0.5039,\n",
      "        0.5317, 0.5312, 0.5434, 0.5506, 0.5027, 0.4929, 0.5045, 0.5223, 0.5196,\n",
      "        0.5038, 0.5033, 0.4870, 0.5071, 0.4963, 0.4628, 0.5026, 0.4986, 0.5155,\n",
      "        0.5093, 0.5151, 0.4917, 0.5157, 0.5244, 0.4712, 0.5329, 0.5041, 0.5517,\n",
      "        0.4995], grad_fn=<CatBackward0>)\n",
      "var of recall: tensor(0.0007, grad_fn=<SubBackward0>)\n",
      "mean of recall tensor(0.5170, grad_fn=<MeanBackward0>)\n",
      "meta_loss: tensor(0.0007, grad_fn=<SubBackward0>)\n",
      "recall_true: tensor(0.4907)\n",
      "ENN_loss: tensor(0.0870, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0468, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0533, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0832, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0820, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0793, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0371, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0592, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0533, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0789, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0477, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0820, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0806, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0513, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0652, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0729, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0640, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0849, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0717, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0432, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0840, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0709, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0551, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0476, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0843, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0687, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0610, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0518, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0735, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0611, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0649, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0559, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0768, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0939, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0479, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0556, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0410, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0683, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0774, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0727, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0756, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0431, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0782, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0721, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0763, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0736, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0768, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0470, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0771, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0596, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0382, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0837, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0318, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0678, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0762, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0895, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0759, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0581, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0601, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0513, grad_fn=<MeanBackward0>)\n",
      "recall list tensor([0.4958, 0.5243, 0.5040, 0.5218, 0.5135, 0.5038, 0.5178, 0.4981, 0.4805,\n",
      "        0.5177, 0.5128, 0.4971, 0.5894, 0.5652, 0.5185, 0.5128, 0.4939, 0.5609,\n",
      "        0.5290, 0.5242, 0.5341, 0.5299, 0.5235, 0.5170, 0.5339, 0.4925, 0.5373,\n",
      "        0.4988, 0.5229, 0.4986, 0.5402, 0.5146, 0.5226, 0.5317, 0.4998, 0.5133,\n",
      "        0.5199, 0.5373, 0.4857, 0.5267, 0.5049, 0.4948, 0.4991, 0.5194, 0.5027,\n",
      "        0.4777, 0.5368, 0.5199, 0.5256, 0.5309, 0.5245, 0.5414, 0.5198, 0.5309,\n",
      "        0.5330, 0.5037, 0.5157, 0.5288, 0.5125, 0.5221, 0.4690, 0.5087, 0.5403,\n",
      "        0.5479, 0.5238, 0.5486, 0.4724, 0.5232, 0.5453, 0.5113, 0.5101, 0.4934,\n",
      "        0.5104, 0.4991, 0.5351, 0.5084, 0.5099, 0.5220, 0.4979, 0.5332, 0.5390,\n",
      "        0.5008, 0.5921, 0.5185, 0.5197, 0.4896, 0.5032, 0.4719, 0.5097, 0.5131,\n",
      "        0.5478, 0.5148, 0.5040, 0.5255, 0.5446, 0.4896, 0.5302, 0.4953, 0.4669,\n",
      "        0.5035], grad_fn=<CatBackward0>)\n",
      "var of recall: tensor(0.0005, grad_fn=<SubBackward0>)\n",
      "mean of recall tensor(0.5169, grad_fn=<MeanBackward0>)\n",
      "meta_loss: tensor(0.0005, grad_fn=<SubBackward0>)\n",
      "recall_true: tensor(0.4907)\n",
      "ENN_loss: tensor(0.0977, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0515, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0648, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0504, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0630, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0644, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0556, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0825, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0583, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0519, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0716, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0781, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0825, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0639, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0580, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0639, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0509, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0747, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0782, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0573, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0410, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1041, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0929, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0431, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0753, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0476, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0600, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0854, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0503, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0691, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0717, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0689, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0790, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0958, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0556, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0450, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0905, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0485, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0613, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0641, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0750, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0744, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0810, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0451, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0799, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0365, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0736, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1002, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0475, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0559, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0990, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0691, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0767, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0442, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0796, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0659, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0713, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0592, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0756, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0605, grad_fn=<MeanBackward0>)\n",
      "recall list tensor([0.5022, 0.5367, 0.4788, 0.5500, 0.5181, 0.5325, 0.5210, 0.5246, 0.5012,\n",
      "        0.5416, 0.5102, 0.4831, 0.4834, 0.5096, 0.5302, 0.5660, 0.5088, 0.4879,\n",
      "        0.5195, 0.5294, 0.5056, 0.4951, 0.5266, 0.5166, 0.5210, 0.5413, 0.4728,\n",
      "        0.4886, 0.5076, 0.5062, 0.5052, 0.5134, 0.5225, 0.4431, 0.4942, 0.4950,\n",
      "        0.5024, 0.5196, 0.5300, 0.5287, 0.5478, 0.5211, 0.4466, 0.5309, 0.5544,\n",
      "        0.4932, 0.5274, 0.5065, 0.5176, 0.5064, 0.5205, 0.4544, 0.5501, 0.5078,\n",
      "        0.4834, 0.5149, 0.5234, 0.5041, 0.5119, 0.5495, 0.5185, 0.5117, 0.5196,\n",
      "        0.5690, 0.4856, 0.4943, 0.5482, 0.5161, 0.5005, 0.5007, 0.5095, 0.4965,\n",
      "        0.5394, 0.4707, 0.5149, 0.4911, 0.5146, 0.5602, 0.5375, 0.4973, 0.5067,\n",
      "        0.5107, 0.5799, 0.5153, 0.5182, 0.4912, 0.5369, 0.5321, 0.5592, 0.5078,\n",
      "        0.4973, 0.5079, 0.5151, 0.4918, 0.4843, 0.5315, 0.5423, 0.4933, 0.5171,\n",
      "        0.5006], grad_fn=<CatBackward0>)\n",
      "var of recall: tensor(0.0006, grad_fn=<SubBackward0>)\n",
      "mean of recall tensor(0.5138, grad_fn=<MeanBackward0>)\n",
      "meta_loss: tensor(0.0006, grad_fn=<SubBackward0>)\n",
      "recall_true: tensor(0.4907)\n",
      "ENN_loss: tensor(0.0548, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0816, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0658, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0758, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0720, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0566, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1065, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0365, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0940, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0499, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0850, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0611, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1129, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0779, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0384, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0832, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0728, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0824, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0645, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0781, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0993, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0457, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0666, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0716, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0504, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0512, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0977, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0740, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0695, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0935, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0391, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0775, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0800, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0807, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0638, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0742, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0659, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0646, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0839, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0570, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0516, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0815, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1053, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0332, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0623, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0432, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0845, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0848, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0915, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0740, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0537, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0535, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0631, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0701, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0657, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0892, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1233, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0993, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0432, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0400, grad_fn=<MeanBackward0>)\n",
      "recall list tensor([0.4817, 0.5493, 0.5156, 0.4693, 0.4816, 0.5336, 0.5053, 0.5224, 0.5172,\n",
      "        0.5043, 0.5080, 0.5358, 0.4836, 0.5297, 0.5170, 0.4953, 0.5123, 0.4938,\n",
      "        0.5203, 0.5220, 0.4933, 0.5162, 0.5628, 0.5123, 0.4936, 0.5405, 0.5443,\n",
      "        0.5496, 0.4976, 0.5158, 0.5074, 0.5230, 0.5055, 0.5240, 0.5402, 0.4990,\n",
      "        0.5178, 0.5029, 0.5394, 0.5048, 0.5355, 0.4935, 0.5126, 0.5840, 0.5358,\n",
      "        0.5319, 0.5629, 0.5367, 0.4964, 0.5339, 0.5327, 0.4970, 0.5005, 0.5042,\n",
      "        0.5222, 0.5680, 0.5286, 0.4787, 0.5206, 0.5067, 0.4990, 0.5381, 0.5358,\n",
      "        0.5132, 0.4948, 0.5449, 0.4768, 0.4922, 0.5374, 0.5240, 0.5245, 0.5071,\n",
      "        0.4726, 0.5290, 0.5093, 0.5309, 0.5280, 0.5315, 0.5170, 0.5244, 0.5228,\n",
      "        0.5135, 0.5223, 0.5188, 0.5373, 0.5008, 0.5081, 0.5033, 0.4811, 0.5212,\n",
      "        0.5255, 0.5056, 0.5249, 0.5285, 0.5103, 0.5193, 0.5061, 0.5234, 0.5556,\n",
      "        0.5127], grad_fn=<CatBackward0>)\n",
      "var of recall: tensor(0.0004, grad_fn=<SubBackward0>)\n",
      "mean of recall tensor(0.5174, grad_fn=<MeanBackward0>)\n",
      "meta_loss: tensor(0.0004, grad_fn=<SubBackward0>)\n",
      "recall_true: tensor(0.4907)\n",
      "ENN_loss: tensor(0.0779, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0612, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0871, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0586, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0741, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0589, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0721, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0749, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0661, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0609, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0611, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0967, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0712, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0781, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0726, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0631, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0663, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0636, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0710, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0808, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0679, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0653, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0994, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0442, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0592, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0872, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0638, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0662, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0900, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0666, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0795, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0475, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0533, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1020, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0642, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0583, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0649, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0909, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0589, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0503, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0717, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0719, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0759, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0703, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0864, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0582, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0585, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0777, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0855, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0571, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0322, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1124, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0536, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0756, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0747, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0783, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0448, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0824, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1013, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0556, grad_fn=<MeanBackward0>)\n",
      "recall list tensor([0.5167, 0.5084, 0.5144, 0.5146, 0.5322, 0.5048, 0.5092, 0.5032, 0.5101,\n",
      "        0.4944, 0.5233, 0.5161, 0.5426, 0.5022, 0.4997, 0.5217, 0.5156, 0.5157,\n",
      "        0.5082, 0.5412, 0.5204, 0.5296, 0.5108, 0.5194, 0.4943, 0.5084, 0.4920,\n",
      "        0.5270, 0.4766, 0.4931, 0.5123, 0.5316, 0.5342, 0.5189, 0.5236, 0.5216,\n",
      "        0.4831, 0.5043, 0.5197, 0.5136, 0.5398, 0.5001, 0.4940, 0.5437, 0.4838,\n",
      "        0.5462, 0.5008, 0.5224, 0.5219, 0.5255, 0.5226, 0.5446, 0.5287, 0.5291,\n",
      "        0.5265, 0.5313, 0.4890, 0.5366, 0.5175, 0.5169, 0.5062, 0.5186, 0.5099,\n",
      "        0.5337, 0.5117, 0.5303, 0.4994, 0.5181, 0.5658, 0.5424, 0.5303, 0.5205,\n",
      "        0.5061, 0.5341, 0.5214, 0.5305, 0.4862, 0.5047, 0.5081, 0.5269, 0.4992,\n",
      "        0.5385, 0.5285, 0.5378, 0.5325, 0.5349, 0.5215, 0.5077, 0.5140, 0.5217,\n",
      "        0.5194, 0.4870, 0.5279, 0.4873, 0.5296, 0.4901, 0.4872, 0.5161, 0.5446,\n",
      "        0.5225], grad_fn=<CatBackward0>)\n",
      "var of recall: tensor(0.0003, grad_fn=<SubBackward0>)\n",
      "mean of recall tensor(0.5170, grad_fn=<MeanBackward0>)\n",
      "meta_loss: tensor(0.0003, grad_fn=<SubBackward0>)\n",
      "recall_true: tensor(0.4907)\n",
      "ENN_loss: tensor(0.0479, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0875, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0426, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1078, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0823, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0457, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0480, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0604, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0657, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0525, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0868, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0477, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0608, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0635, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0391, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0496, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0726, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0547, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0524, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0654, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0638, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0578, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0575, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0561, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0621, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0728, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0527, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0413, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0569, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0599, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0743, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0397, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0493, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0329, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0571, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0844, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0516, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0444, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0689, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0687, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0315, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0405, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0606, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1064, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0605, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0408, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0689, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0577, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0631, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0378, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0434, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0808, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0561, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0545, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0505, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0641, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0899, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0641, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0454, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0411, grad_fn=<MeanBackward0>)\n",
      "recall list tensor([0.4859, 0.5071, 0.5713, 0.5293, 0.5347, 0.5348, 0.5237, 0.5093, 0.5087,\n",
      "        0.5277, 0.4877, 0.5921, 0.5346, 0.5408, 0.5267, 0.4968, 0.5573, 0.4933,\n",
      "        0.5757, 0.5553, 0.4780, 0.5351, 0.5255, 0.4827, 0.5178, 0.5084, 0.4728,\n",
      "        0.4946, 0.5055, 0.5464, 0.5270, 0.5402, 0.5248, 0.5189, 0.5023, 0.5461,\n",
      "        0.5541, 0.5061, 0.5148, 0.5201, 0.5335, 0.5436, 0.5033, 0.5163, 0.4782,\n",
      "        0.5166, 0.5559, 0.4787, 0.4844, 0.4570, 0.5464, 0.5041, 0.5249, 0.4773,\n",
      "        0.5232, 0.5355, 0.5502, 0.5313, 0.5445, 0.4765, 0.5244, 0.5229, 0.5075,\n",
      "        0.4989, 0.4776, 0.5356, 0.5143, 0.5049, 0.5114, 0.5045, 0.5571, 0.5217,\n",
      "        0.4961, 0.5161, 0.5506, 0.5179, 0.5171, 0.5242, 0.4766, 0.5229, 0.5572,\n",
      "        0.4853, 0.4471, 0.5413, 0.5161, 0.5230, 0.5450, 0.5222, 0.5324, 0.4646,\n",
      "        0.4804, 0.5156, 0.5049, 0.5579, 0.5890, 0.5259, 0.4839, 0.5414, 0.5226,\n",
      "        0.4905], grad_fn=<CatBackward0>)\n",
      "var of recall: tensor(0.0008, grad_fn=<SubBackward0>)\n",
      "mean of recall tensor(0.5184, grad_fn=<MeanBackward0>)\n",
      "meta_loss: tensor(0.0008, grad_fn=<SubBackward0>)\n",
      "recall_true: tensor(0.4907)\n",
      "ENN_loss: tensor(0.0854, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0663, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0701, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0538, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0441, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0775, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0892, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0751, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0632, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0690, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0646, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1138, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0771, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0556, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0880, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0717, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0570, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0768, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0766, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0696, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0668, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0589, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0605, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0767, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0748, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1048, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0421, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0528, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0651, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0760, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0423, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0800, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0615, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0684, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0866, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0606, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0576, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0515, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0838, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0731, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0872, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0623, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0733, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0570, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0817, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0827, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0919, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0354, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0830, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0780, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0585, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0647, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0687, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0449, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0686, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0858, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0815, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1125, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0471, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0546, grad_fn=<MeanBackward0>)\n",
      "recall list tensor([0.5198, 0.5381, 0.5008, 0.5356, 0.4844, 0.5352, 0.5208, 0.5209, 0.5283,\n",
      "        0.5266, 0.5216, 0.4814, 0.4715, 0.5326, 0.4841, 0.5247, 0.5801, 0.5525,\n",
      "        0.5063, 0.4769, 0.4988, 0.5470, 0.5146, 0.4967, 0.5268, 0.4920, 0.4956,\n",
      "        0.5368, 0.5682, 0.5234, 0.5032, 0.5171, 0.5320, 0.5586, 0.5188, 0.4940,\n",
      "        0.5102, 0.5281, 0.5288, 0.5090, 0.4698, 0.5406, 0.5336, 0.4879, 0.5117,\n",
      "        0.4871, 0.5374, 0.4960, 0.5304, 0.5045, 0.5044, 0.5054, 0.4828, 0.5228,\n",
      "        0.5273, 0.5235, 0.5371, 0.5228, 0.5260, 0.5352, 0.5068, 0.5162, 0.4786,\n",
      "        0.4983, 0.5093, 0.5080, 0.4859, 0.4867, 0.5080, 0.5207, 0.5321, 0.5500,\n",
      "        0.5236, 0.5210, 0.5321, 0.5184, 0.4947, 0.5367, 0.5178, 0.5037, 0.5342,\n",
      "        0.5362, 0.4816, 0.5187, 0.5213, 0.4741, 0.5038, 0.5197, 0.5073, 0.4769,\n",
      "        0.5172, 0.5081, 0.5289, 0.5215, 0.4941, 0.5181, 0.5415, 0.5349, 0.5442,\n",
      "        0.4998], grad_fn=<CatBackward0>)\n",
      "var of recall: tensor(0.0005, grad_fn=<SubBackward0>)\n",
      "mean of recall tensor(0.5156, grad_fn=<MeanBackward0>)\n",
      "meta_loss: tensor(0.0005, grad_fn=<SubBackward0>)\n",
      "recall_true: tensor(0.4907)\n",
      "ENN_loss: tensor(0.0779, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0301, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0806, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0644, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0767, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0635, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0637, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0591, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0624, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0598, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0682, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0740, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0734, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0664, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0508, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0849, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0763, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0752, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0654, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0432, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0530, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0556, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0680, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0739, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0432, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0793, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0742, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0593, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0643, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0397, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0918, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0555, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0811, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0455, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0589, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0712, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0616, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0883, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0521, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0672, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0873, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0672, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0623, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0447, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0874, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0635, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0581, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0459, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0443, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0630, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1045, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0580, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0798, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0725, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0325, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0743, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0562, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0654, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0695, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0727, grad_fn=<MeanBackward0>)\n",
      "recall list tensor([0.5327, 0.5161, 0.5414, 0.5553, 0.5316, 0.5005, 0.5365, 0.5158, 0.4885,\n",
      "        0.5558, 0.5322, 0.5599, 0.5430, 0.5193, 0.5065, 0.4986, 0.5092, 0.4457,\n",
      "        0.4849, 0.5098, 0.5045, 0.5292, 0.5043, 0.5169, 0.5406, 0.5240, 0.5260,\n",
      "        0.5359, 0.5394, 0.5014, 0.5197, 0.5079, 0.5182, 0.4993, 0.5477, 0.5261,\n",
      "        0.5261, 0.5590, 0.5091, 0.5017, 0.5116, 0.5231, 0.4944, 0.4852, 0.5304,\n",
      "        0.5171, 0.4547, 0.4769, 0.4952, 0.4931, 0.5481, 0.5185, 0.4796, 0.4996,\n",
      "        0.5062, 0.5135, 0.5225, 0.5251, 0.5576, 0.5112, 0.5531, 0.4877, 0.4928,\n",
      "        0.5182, 0.5342, 0.5292, 0.5034, 0.5509, 0.5298, 0.4877, 0.5247, 0.5259,\n",
      "        0.4938, 0.5425, 0.5203, 0.5086, 0.4713, 0.5188, 0.5320, 0.5165, 0.4915,\n",
      "        0.5240, 0.5373, 0.4730, 0.4915, 0.5258, 0.5308, 0.5443, 0.5422, 0.5187,\n",
      "        0.5193, 0.4962, 0.5298, 0.4768, 0.5336, 0.5007, 0.5244, 0.4987, 0.5412,\n",
      "        0.5161], grad_fn=<CatBackward0>)\n",
      "var of recall: tensor(0.0005, grad_fn=<SubBackward0>)\n",
      "mean of recall tensor(0.5164, grad_fn=<MeanBackward0>)\n",
      "meta_loss: tensor(0.0005, grad_fn=<SubBackward0>)\n",
      "recall_true: tensor(0.4907)\n",
      "ENN_loss: tensor(0.0925, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0844, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0286, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0569, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0560, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0466, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0640, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0835, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0330, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0605, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0712, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0888, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0326, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0659, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1058, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0446, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0935, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0764, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0487, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0613, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0584, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1140, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0464, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0525, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0851, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0457, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0656, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0610, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0593, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0712, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0314, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0921, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0725, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0665, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0351, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0745, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0571, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0638, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0531, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0609, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0869, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0890, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0408, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0569, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0361, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1004, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0844, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0437, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0574, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0632, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0642, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0662, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0564, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0909, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0500, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0664, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0913, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0589, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0781, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0363, grad_fn=<MeanBackward0>)\n",
      "recall list tensor([0.5057, 0.4793, 0.4938, 0.5000, 0.5159, 0.5114, 0.5114, 0.5195, 0.5517,\n",
      "        0.5832, 0.4632, 0.5200, 0.5563, 0.4989, 0.4720, 0.5200, 0.5306, 0.5160,\n",
      "        0.5106, 0.5023, 0.5623, 0.5486, 0.5277, 0.5367, 0.4803, 0.5222, 0.5289,\n",
      "        0.5016, 0.4925, 0.5373, 0.5083, 0.5217, 0.5219, 0.5458, 0.5422, 0.5210,\n",
      "        0.5511, 0.5296, 0.5022, 0.4884, 0.5090, 0.5112, 0.5153, 0.5330, 0.5047,\n",
      "        0.5309, 0.5172, 0.5104, 0.5195, 0.5186, 0.5071, 0.4854, 0.5320, 0.5314,\n",
      "        0.5468, 0.5021, 0.5412, 0.4717, 0.5400, 0.5267, 0.5498, 0.5120, 0.5326,\n",
      "        0.5430, 0.5018, 0.5720, 0.5423, 0.5640, 0.5301, 0.4900, 0.5269, 0.5011,\n",
      "        0.5427, 0.5321, 0.4968, 0.5207, 0.5342, 0.5171, 0.4901, 0.4946, 0.4727,\n",
      "        0.4998, 0.4996, 0.5219, 0.5277, 0.4931, 0.5071, 0.4938, 0.5260, 0.4700,\n",
      "        0.5288, 0.5451, 0.5538, 0.5101, 0.5713, 0.5076, 0.5014, 0.5197, 0.5103,\n",
      "        0.4953], grad_fn=<CatBackward0>)\n",
      "var of recall: tensor(0.0006, grad_fn=<SubBackward0>)\n",
      "mean of recall tensor(0.5184, grad_fn=<MeanBackward0>)\n",
      "meta_loss: tensor(0.0006, grad_fn=<SubBackward0>)\n",
      "recall_true: tensor(0.4907)\n",
      "meta_loss_list [0.0005658268928527832]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training epoch ends in  1.51 minutes.\n",
      "test starts\n",
      "ENN_loss: tensor(0.0694, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.1142, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0491, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0732, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0876, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0519, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0632, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0796, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0757, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0613, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0394, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0971, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0838, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0686, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0697, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0620, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0495, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0706, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0797, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0795, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0604, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0614, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0940, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0787, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0574, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0823, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0731, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0739, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0854, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0730, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0637, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0733, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0790, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0695, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0654, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0671, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0941, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0469, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0746, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0614, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0629, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0680, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0587, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0865, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0631, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0739, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0674, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0733, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0607, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0942, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0482, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0765, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0766, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0496, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0757, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0763, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0632, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0727, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0525, grad_fn=<MeanBackward0>)\n",
      "ENN_loss: tensor(0.0885, grad_fn=<MeanBackward0>)\n",
      "recall list tensor([0.4913, 0.5248, 0.5612, 0.5303, 0.5065, 0.5053, 0.5353, 0.5079, 0.5033,\n",
      "        0.5164, 0.5365, 0.4867, 0.5016, 0.5211, 0.5111, 0.5304, 0.4995, 0.5159,\n",
      "        0.5316, 0.5097, 0.5337, 0.5431, 0.5191, 0.5280, 0.4833, 0.5084, 0.5121,\n",
      "        0.5039, 0.5115, 0.5118, 0.5013, 0.5120, 0.5106, 0.5199, 0.5067, 0.5125,\n",
      "        0.4909, 0.5317, 0.5221, 0.5077, 0.5051, 0.5030, 0.5131, 0.5082, 0.4998,\n",
      "        0.5788, 0.5586, 0.4711, 0.4771, 0.5441, 0.5370, 0.5150, 0.5098, 0.5184,\n",
      "        0.5148, 0.5219, 0.5078, 0.4881, 0.5155, 0.5055, 0.5013, 0.5193, 0.5096,\n",
      "        0.4848, 0.5571, 0.5082, 0.5379, 0.5256, 0.5031, 0.5284, 0.5302, 0.5459,\n",
      "        0.5340, 0.5095, 0.5165, 0.4879, 0.5100, 0.4852, 0.5292, 0.5052, 0.5375,\n",
      "        0.4981, 0.5228, 0.5025, 0.5507, 0.5002, 0.5106, 0.4948, 0.5026, 0.4877,\n",
      "        0.5119, 0.5109, 0.5628, 0.5055, 0.5363, 0.5211, 0.5052, 0.4815, 0.5437,\n",
      "        0.5552], grad_fn=<CatBackward0>)\n",
      "var of recall: tensor(0.0004, grad_fn=<SubBackward0>)\n",
      "mean of recall tensor(0.5156, grad_fn=<MeanBackward0>)\n",
      "meta_loss: tensor(0.0004, grad_fn=<SubBackward0>)\n",
      "recall_true: tensor(0.4907)\n"
     ]
    }
   ],
   "source": [
    "#data generated from https://github.com/dakshmittal30/Adaptive_sampling/blob/49060b32a7c95ab5f8057ff593629d64ea411c14/src/notebooks/Dataset_generator.ipynb\n",
    "#predictor (a logistic regression) generated from https://github.com/dakshmittal30/Adaptive_sampling/blob/49060b32a7c95ab5f8057ff593629d64ea411c14/src/notebooks/Predictor.ipynb \n",
    "#biased data from https://github.com/dakshmittal30/Adaptive_sampling/blob/7cf3996c786ce33db90fcb7aef8584054169557c/src/notebooks/Selection_bias.ipynb \n",
    "directory = '/shared/share_mala/yuanzhe/adaptive_sampling/pipeline_datasets/'\n",
    "train_csv_name = directory + 'classifier_input_dim_1_train_init_data_mean_0.0ln_1.0sig_0.1no.2000.csv'\n",
    "train_csv_name = directory +'/biased_new/classifier_input_dim_1_train_init_data_mean_0.0ln_1.0sig_0.1no.2000_random_prop_score_selected_2_16.0__.csv'\n",
    "test_csv_name = directory + 'classifier_input_dim_1_test_final_data_mean_0.0ln_1.0sig_0.1no.2000.csv'\n",
    "pool_csv_name = directory + 'classifier_input_dim_1_pool_data_mean_0.0ln_1.0sig_0.1no.2000.csv'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "df_train = pd.read_csv(train_csv_name)\n",
    "print('training data count',df_train.shape)\n",
    "\n",
    "Z_dim = 8\n",
    "\n",
    "dataset_cfg = pipeline.DatasetConfig(train_csv_name, test_csv_name, pool_csv_name, \"EVENT_LABEL\")\n",
    "model_cfg = pipeline.ModelConfig(batch_size_train = 251, batch_size_test = 500, batch_size_query = 100, temp_k_subset = 0.1, hidden_sizes_weight_NN = [50,50], meta_opt_lr = 0.01, n_classes = 2, n_epoch = 1, init_train_lr = 0.05, init_train_weight_decay = 0.01, n_train_init = 100, meta_opt_weight_decay = 0.01)\n",
    "train_cfg = pipeline.TrainConfig(n_train_iter = 100, n_ENN_iter = 15, ENN_opt_lr = 0.01, temp_var_recall = 0.4, z_dim = Z_dim, N_iter = 100, ENN_opt_weight_decay = 0.01) #temp_var_recall is the new variable added here\n",
    "enn_cfg = pipeline.ENNConfig(basenet_hidden_sizes = [50,50],  exposed_layers = [False, True], z_dim = Z_dim, learnable_epinet_hiddens = [15,15], hidden_sizes_prior = [5,5], seed_base = 2, seed_learnable_epinet = 1, seed_prior_epinet = 0, alpha = 1.0)\n",
    " \n",
    "\n",
    "model_predictor = torch.jit.load(directory + 'predictor_0206.pt')\n",
    "model_predictor.eval()\n",
    "\n",
    "# Example usage\n",
    "#need to add ``pipeline.'' in the below command; I didn't add it so that I can debug more easily\n",
    "pipeline.experiment(dataset_cfg, model_cfg, train_cfg, enn_cfg, model_predictor, device = device, if_print = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc28cfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%load_ext line_profiler\n",
    "#profiling code - check which part\n",
    "#%reload_ext line_profiler\n",
    "\n",
    "#%lprun -f experiment experiment(dataset_cfg, model_cfg, train_cfg, enn_cfg, model_predictor, if_print = 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yuanzhe_new",
   "language": "python",
   "name": "yuanzhe_new"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
