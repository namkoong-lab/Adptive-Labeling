{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.init as init"
      ],
      "metadata": {
        "id": "a_b8FD8rgj0S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#METHODOLOGY 1\n",
        "# An implementation that combines basenet, learnable epinet, prior epinet\n",
        "\n",
        "# shape of x in [batch_size,x_dim], z is [z_dim]\n",
        "# assuming input is always included and output is never included\n",
        "# hidden layers and exposed layers same number of entries\n",
        "\n",
        "\n",
        "\n",
        "class basenet_with_learnable_epinet_and_ensemble_prior(nn.Module):\n",
        "    def __init__(self, input_size, basenet_hidden_sizes, n_classes, exposed_layers, z_dim, learnable_epinet_hiddens, hidden_sizes_prior, seed_base, seed_learnable_epinet, seed_prior_epinet, alpha):\n",
        "        super(basenet_with_learnable_epinet_and_ensemble_prior, self).__init__()\n",
        "\n",
        "\n",
        "        self.z_dim = z_dim\n",
        "        self.n_classes = n_classes\n",
        "        self.num_ensemble = z_dim\n",
        "        self.alpha = alpha\n",
        "\n",
        "\n",
        "        # Create a list of all sizes (input + hidden + output)\n",
        "        basenet_all_sizes = [input_size] + basenet_hidden_sizes + [n_classes]\n",
        "\n",
        "        self.basenet_all_sizes = basenet_all_sizes\n",
        "        exposed_layers = [True]+exposed_layers+[False]     # assuming input is always included and output is never included\n",
        "\n",
        "        self.exposed_layers = exposed_layers\n",
        "\n",
        "        torch.manual_seed(seed_base)\n",
        "        # Dynamically create layers\n",
        "        self.basenet_layers = nn.ModuleList()\n",
        "        for i in range(len(basenet_all_sizes) - 1):\n",
        "            self.basenet_layers.append(nn.Linear(basenet_all_sizes[i], basenet_all_sizes[i + 1]))\n",
        "\n",
        "\n",
        "        sum_input_base_epi = sum(basenet_all_size for basenet_all_size, exposed_layer in zip(basenet_all_sizes, exposed_layers) if exposed_layer)\n",
        "\n",
        "        learnable_epinet_all_sizes = [sum_input_base_epi+z_dim]    + learnable_epinet_hiddens + [n_classes*z_dim]\n",
        "\n",
        "        self.learnable_epinet_all_sizes = learnable_epinet_all_sizes\n",
        "\n",
        "        torch.manual_seed(seed_learnable_epinet)\n",
        "        self.learnable_epinet_layers = nn.ModuleList()\n",
        "        for j in range(len(learnable_epinet_all_sizes) - 1):\n",
        "            self.learnable_epinet_layers.append(nn.Linear(learnable_epinet_all_sizes[j], learnable_epinet_all_sizes[j + 1]))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        torch.manual_seed(seed_prior_epinet)\n",
        "        self.ensemble = nn.ModuleList()\n",
        "        for _ in range(self.num_ensemble):\n",
        "            layers = []\n",
        "            all_sizes_prior = [sum_input_base_epi] + hidden_sizes_prior + [n_classes]\n",
        "            for i in range(len(all_sizes_prior) - 1):\n",
        "                layer = nn.Linear(all_sizes_prior[i], all_sizes_prior[i + 1])\n",
        "\n",
        "\n",
        "                # Initialize weights and biases here\n",
        "                init.xavier_uniform_(layer.weight)\n",
        "                init.zeros_(layer.bias)\n",
        "\n",
        "                layers.append(layer)\n",
        "                if i < len(all_sizes_prior) - 2:\n",
        "                    layers.append(nn.ReLU())\n",
        "\n",
        "            mlp = nn.Sequential(*layers)\n",
        "\n",
        "            # Freeze the parameters of this MLP\n",
        "            for param in mlp.parameters():\n",
        "                param.requires_grad = False\n",
        "\n",
        "            self.ensemble.append(mlp)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x, z):\n",
        "        hidden_outputs = []\n",
        "        #concatenate_hidden = x   #assuming x is always input\n",
        "\n",
        "\n",
        "        for i, (basenet_layer, flag) in enumerate(zip(self.basenet_layers, self.exposed_layers)):\n",
        "            if flag:\n",
        "                hidden_outputs.append(x)\n",
        "\n",
        "\n",
        "            x = basenet_layer(x)\n",
        "\n",
        "            if i < len(self.basenet_layers) - 1:  # Apply activation function except for the output layer\n",
        "                x = torch.relu(x)\n",
        "\n",
        "\n",
        "            #if i>0 and flag:\n",
        "                #concatenate_hidden = torch.cat(x,concatenate_hidden, dim=1)\n",
        "\n",
        "        concatenate_hidden = torch.cat(hidden_outputs, dim=1)\n",
        "\n",
        "        detached_concatenate_hidden = concatenate_hidden.detach()                    ###-------NOT SURE IF BACKPROP WILL WORK PROPERLY THROUGH THIS\n",
        "\n",
        "        detached_concatenate_hidden_to_prior = concatenate_hidden.detach()\n",
        "        ###-------NOT SURE IF BACKPROP WILL WORK PROPERLY THROUGH THIS - should we clone and detach\n",
        "\n",
        "\n",
        "        z_repeated = z.unsqueeze(0).repeat(detached_concatenate_hidden.size(0), 1)\n",
        "\n",
        "        combined_output = torch.cat([detached_concatenate_hidden,z_repeated], dim=1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        for j, learnable_epinet_layer in enumerate(self.learnable_epinet_layers):\n",
        "            combined_output = learnable_epinet_layer(combined_output)\n",
        "\n",
        "            if j < len(self.learnable_epinet_layers) - 1:  # Apply activation function except for the output layer\n",
        "                combined_output = torch.relu(combined_output)\n",
        "\n",
        "        #reshaped_output = combined_output_learnable.view(inputs.shape[0], self.num_classes, self.z_dim)\n",
        "        reshaped_epinet_output = torch.reshape(combined_output, (combined_output.shape[0], self.n_classes, self.z_dim))\n",
        "\n",
        "        epinet_output = torch.matmul(reshaped_epinet_output, z)\n",
        "\n",
        "\n",
        "        outputs_prior = [mlp(detached_concatenate_hidden_to_prior) for mlp in self.ensemble]\n",
        "\n",
        "        outputs_prior_tensor = torch.stack(outputs_prior, dim=0)\n",
        "\n",
        "        prior_output = torch.einsum('nbo,n->bo', outputs_prior_tensor, z)\n",
        "\n",
        "        final_output =  x + epinet_output + self.alpha* prior_output\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        return final_output\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.01)\n",
        "\n",
        "# optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=0.01)\n",
        "\n"
      ],
      "metadata": {
        "id": "cm0PS_iyi1Vy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wPWnxTYtgcrr"
      },
      "outputs": [],
      "source": [
        "#METHODOLOGY 1\n",
        "# An implementation that combines basenet, learnable epinet, prior epinet\n",
        "\n",
        "# shape of x in [batch_size,x_dim], z is [z_dim]\n",
        "# assuming input is always included and output is never included\n",
        "# hidden layers and exposed layers same number of entries\n",
        "\n",
        "\n",
        "\n",
        "class basenet_with_learnable_epinet_and_ensemble_prior(nn.Module):\n",
        "    def __init__(self, input_size, basenet_hidden_sizes, n_classes, exposed_layers, z_dim, learnable_epinet_hiddens, hidden_sizes_prior, seed_base, seed_learnable_epinet, seed_prior_epinet, alpha):\n",
        "        super(basenet_with_learnable_epinet_and_ensemble_prior, self).__init__()\n",
        "\n",
        "\n",
        "        self.z_dim = z_dim\n",
        "        self.n_classes = n_classes\n",
        "        self.num_ensemble = z_dim\n",
        "        self.alpha = alpha\n",
        "\n",
        "\n",
        "        # Create a list of all sizes (input + hidden + output)\n",
        "        basenet_all_sizes = [input_size] + basenet_hidden_sizes + [n_classes]\n",
        "        print(\"basenet_all_sizes:\", basenet_all_sizes)\n",
        "        self.basenet_all_sizes = basenet_all_sizes\n",
        "        exposed_layers = [True]+exposed_layers+[False]     # assuming input is always included and output is never included\n",
        "        print(\"exposed_layers:\",exposed_layers)\n",
        "        self.exposed_layers = exposed_layers\n",
        "\n",
        "        torch.manual_seed(seed_base)\n",
        "        # Dynamically create layers\n",
        "        self.basenet_layers = nn.ModuleList()\n",
        "        for i in range(len(basenet_all_sizes) - 1):\n",
        "            self.basenet_layers.append(nn.Linear(basenet_all_sizes[i], basenet_all_sizes[i + 1]))\n",
        "        print(\"basenet_layers:\", self.basenet_layers)\n",
        "\n",
        "        sum_input_base_epi = sum(basenet_all_size for basenet_all_size, exposed_layer in zip(basenet_all_sizes, exposed_layers) if exposed_layer)\n",
        "        print(\"sum_input_base_epi:\", sum_input_base_epi)\n",
        "        learnable_epinet_all_sizes = [sum_input_base_epi+z_dim]    + learnable_epinet_hiddens + [n_classes*z_dim]\n",
        "        print(\"learnable_epinet_all_sizes:\", learnable_epinet_all_sizes)\n",
        "        self.learnable_epinet_all_sizes = learnable_epinet_all_sizes\n",
        "\n",
        "        torch.manual_seed(seed_learnable_epinet)\n",
        "        self.learnable_epinet_layers = nn.ModuleList()\n",
        "        for j in range(len(learnable_epinet_all_sizes) - 1):\n",
        "            self.learnable_epinet_layers.append(nn.Linear(learnable_epinet_all_sizes[j], learnable_epinet_all_sizes[j + 1]))\n",
        "        print(\"learnable_epinet_layers:\", self.learnable_epinet_layers)\n",
        "\n",
        "\n",
        "\n",
        "        torch.manual_seed(seed_prior_epinet)\n",
        "        self.ensemble = nn.ModuleList()\n",
        "        for _ in range(self.num_ensemble):\n",
        "            layers = []\n",
        "            all_sizes_prior = [sum_input_base_epi] + hidden_sizes_prior + [n_classes]\n",
        "            for i in range(len(all_sizes_prior) - 1):\n",
        "                layer = nn.Linear(all_sizes_prior[i], all_sizes_prior[i + 1])\n",
        "\n",
        "\n",
        "                # Initialize weights and biases here\n",
        "                init.xavier_uniform_(layer.weight)\n",
        "                init.zeros_(layer.bias)\n",
        "\n",
        "                layers.append(layer)\n",
        "                if i < len(all_sizes_prior) - 2:\n",
        "                    layers.append(nn.ReLU())\n",
        "\n",
        "            mlp = nn.Sequential(*layers)\n",
        "\n",
        "            # Freeze the parameters of this MLP\n",
        "            for param in mlp.parameters():\n",
        "                param.requires_grad = False\n",
        "\n",
        "            self.ensemble.append(mlp)\n",
        "\n",
        "        print(\"ensemble:\", self.ensemble)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x, z):\n",
        "        hidden_outputs = []\n",
        "        #concatenate_hidden = x   #assuming x is always input\n",
        "        print(\"x:\", x)\n",
        "\n",
        "        for i, (basenet_layer, flag) in enumerate(zip(self.basenet_layers, self.exposed_layers)):\n",
        "            if flag:\n",
        "                hidden_outputs.append(x)\n",
        "                print(\"hidden_outputs:\", hidden_outputs)\n",
        "\n",
        "            x = basenet_layer(x)\n",
        "            print(\"x:\", x)\n",
        "            if i < len(self.basenet_layers) - 1:  # Apply activation function except for the output layer\n",
        "                x = torch.relu(x)\n",
        "                print(\"x:\", x)\n",
        "\n",
        "            #if i>0 and flag:\n",
        "                #concatenate_hidden = torch.cat(x,concatenate_hidden, dim=1)\n",
        "\n",
        "        concatenate_hidden = torch.cat(hidden_outputs, dim=1)\n",
        "        print(\"concatenate_hidden:\", concatenate_hidden)\n",
        "        detached_concatenate_hidden = concatenate_hidden.detach()                    ###-------NOT SURE IF BACKPROP WILL WORK PROPERLY THROUGH THIS\n",
        "        print(\"detached_concatenate_hidden:\", detached_concatenate_hidden)\n",
        "        detached_concatenate_hidden_to_prior = concatenate_hidden.detach()\n",
        "        print(\"detached_concatenate_hidden_to_prior :\", detached_concatenate_hidden_to_prior)    ###-------NOT SURE IF BACKPROP WILL WORK PROPERLY THROUGH THIS - should we clone and detach\n",
        "\n",
        "\n",
        "        z_repeated = z.unsqueeze(0).repeat(detached_concatenate_hidden.size(0), 1)\n",
        "        print(\"z_repeated:\",z_repeated)\n",
        "        combined_output = torch.cat([detached_concatenate_hidden,z_repeated], dim=1)\n",
        "        print(\"combined_output:\", combined_output)\n",
        "\n",
        "\n",
        "\n",
        "        for j, learnable_epinet_layer in enumerate(self.learnable_epinet_layers):\n",
        "            combined_output = learnable_epinet_layer(combined_output)\n",
        "            print(\"combined_output:\", combined_output)\n",
        "            if j < len(self.learnable_epinet_layers) - 1:  # Apply activation function except for the output layer\n",
        "                combined_output = torch.relu(combined_output)\n",
        "                print(\"combined_output:\", combined_output)\n",
        "\n",
        "        print(\"intermediary_check, x:\", x)\n",
        "        print(\"intermediary_check, concatenate_hidden:\", concatenate_hidden)\n",
        "        print(\"intermediary_check, detached_concatenate_hidden:\", detached_concatenate_hidden)\n",
        "        print(\"intermediary_check, detached_concatenate_hidden_to_prior:\", detached_concatenate_hidden_to_prior)\n",
        "\n",
        "\n",
        "        print(\"detached_concatenate_hidden_to_prior:\", detached_concatenate_hidden_to_prior)\n",
        "        #reshaped_output = combined_output_learnable.view(inputs.shape[0], self.num_classes, self.z_dim)\n",
        "        reshaped_epinet_output = torch.reshape(combined_output, (combined_output.shape[0], self.n_classes, self.z_dim))\n",
        "        print(\"reshaped_epinet_output:\",reshaped_epinet_output)\n",
        "        epinet_output = torch.matmul(reshaped_epinet_output, z)\n",
        "        print(\"epinet_output:\", epinet_output)\n",
        "\n",
        "        outputs_prior = [mlp(detached_concatenate_hidden_to_prior) for mlp in self.ensemble]\n",
        "        print(\"outputs_prior:\", outputs_prior)\n",
        "        outputs_prior_tensor = torch.stack(outputs_prior, dim=0)\n",
        "        print(\"outputs_prior_tensor:\", outputs_prior_tensor)\n",
        "        prior_output = torch.einsum('nbo,n->bo', outputs_prior_tensor, z)\n",
        "        print(\"prior_output:\", prior_output)\n",
        "        final_output =  x + epinet_output + self.alpha* prior_output\n",
        "        print(\"final_output:\", final_output)\n",
        "\n",
        "\n",
        "\n",
        "        return final_output\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.01)\n",
        "\n",
        "# optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=0.01)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "basenet_all_sizes= 3\n",
        "print(\"basenet_all_sizes:\", basenet_all_sizes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mTtZUM7ERACg",
        "outputId": "9737c8ac-62e2-4796-8233-75043cf4099d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "basenet_all_sizes: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = 3\n",
        "basenet_hidden_sizes = [5,5]\n",
        "n_classes = 2\n",
        "exposed_layers = [False, True]\n",
        "z_dim = 3\n",
        "learnable_epinet_hiddens = [8,8]\n",
        "hidden_sizes_prior = [2,2]\n",
        "seed_base = 2\n",
        "seed_learnable_epinet = 1\n",
        "seed_prior_epinet = 0\n",
        "alpha = 0.1"
      ],
      "metadata": {
        "id": "vOpRaYrwLERm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = basenet_with_learnable_epinet_and_ensemble_prior(input_size, basenet_hidden_sizes, n_classes, exposed_layers, z_dim, learnable_epinet_hiddens, hidden_sizes_prior, seed_base, seed_learnable_epinet, seed_prior_epinet, alpha)"
      ],
      "metadata": {
        "id": "1Pg-jiSwKHvO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5445d54-17b9-4aa8-bb2c-b2d803bfd6a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "basenet_all_sizes: [3, 5, 5, 2]\n",
            "exposed_layers: [True, False, True, False]\n",
            "basenet_layers: ModuleList(\n",
            "  (0): Linear(in_features=3, out_features=5, bias=True)\n",
            "  (1): Linear(in_features=5, out_features=5, bias=True)\n",
            "  (2): Linear(in_features=5, out_features=2, bias=True)\n",
            ")\n",
            "sum_input_base_epi: 8\n",
            "learnable_epinet_all_sizes: [11, 8, 8, 6]\n",
            "learnable_epinet_layers: ModuleList(\n",
            "  (0): Linear(in_features=11, out_features=8, bias=True)\n",
            "  (1): Linear(in_features=8, out_features=8, bias=True)\n",
            "  (2): Linear(in_features=8, out_features=6, bias=True)\n",
            ")\n",
            "ensemble: ModuleList(\n",
            "  (0-2): 3 x Sequential(\n",
            "    (0): Linear(in_features=8, out_features=2, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=2, out_features=2, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=2, out_features=2, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn(5,3)"
      ],
      "metadata": {
        "id": "EwR2lzfuLlfF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LhtBIWliMHw5",
        "outputId": "c537a31a-ade4-4b45-f315-6652d16905ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-2.1788,  0.5684, -1.0845],\n",
              "        [-1.3986,  0.4033,  0.8380],\n",
              "        [-0.7193, -0.4033, -0.5966],\n",
              "        [ 0.1820, -0.8567,  1.1006],\n",
              "        [-1.0712,  0.1227, -0.5663]])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z=torch.randn(3)"
      ],
      "metadata": {
        "id": "-o5ey6tLLyTb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "z"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rgxkOLT8MJGN",
        "outputId": "a2635ed9-24bd-4f82-d883-c9bdad1de51d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.3731, -0.8920, -1.5091])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z.unsqueeze(0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_V-xFaOMoPr",
        "outputId": "5a31f79d-c64b-4563-dd9d-6bd8a6084104"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.3731, -0.8920, -1.5091]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " z_repeated = z.unsqueeze(0).repeat(x.size(0), 1)"
      ],
      "metadata": {
        "id": "gb44aBJAM5wa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "z_repeated"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pntuieqHM9YK",
        "outputId": "476474d6-3ef4-4fb0-c68b-f20479383da6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.3731, -0.8920, -1.5091],\n",
              "        [ 0.3731, -0.8920, -1.5091],\n",
              "        [ 0.3731, -0.8920, -1.5091],\n",
              "        [ 0.3731, -0.8920, -1.5091],\n",
              "        [ 0.3731, -0.8920, -1.5091]])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "combined_output = torch.cat([x,z_repeated], dim=1)"
      ],
      "metadata": {
        "id": "QBxgKmFDMy1E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OiQObiGlO8mG",
        "outputId": "53c9d018-d1de-4e23-b533-849a6a33799b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-2.1788,  0.5684, -1.0845,  0.3731, -0.8920, -1.5091],\n",
              "        [-1.3986,  0.4033,  0.8380,  0.3731, -0.8920, -1.5091],\n",
              "        [-0.7193, -0.4033, -0.5966,  0.3731, -0.8920, -1.5091],\n",
              "        [ 0.1820, -0.8567,  1.1006,  0.3731, -0.8920, -1.5091],\n",
              "        [-1.0712,  0.1227, -0.5663,  0.3731, -0.8920, -1.5091]])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_2(x,z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZBZi4O9L6FU",
        "outputId": "46de1e35-e7c0-4a2f-f753-49cdde2a7033"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x: tensor([[-2.1788,  0.5684, -1.0845],\n",
            "        [-1.3986,  0.4033,  0.8380],\n",
            "        [-0.7193, -0.4033, -0.5966],\n",
            "        [ 0.1820, -0.8567,  1.1006],\n",
            "        [-1.0712,  0.1227, -0.5663]])\n",
            "hidden_outputs: [tensor([[-2.1788,  0.5684, -1.0845],\n",
            "        [-1.3986,  0.4033,  0.8380],\n",
            "        [-0.7193, -0.4033, -0.5966],\n",
            "        [ 0.1820, -0.8567,  1.1006],\n",
            "        [-1.0712,  0.1227, -0.5663]])]\n",
            "x: tensor([[ 0.7222,  0.8597,  0.6871, -0.7004,  0.9911],\n",
            "        [-0.2459,  0.8626,  0.5041, -0.7706,  0.1663],\n",
            "        [ 0.1831,  0.5312,  0.2006, -0.3632,  0.4415],\n",
            "        [-0.7677,  0.5118, -0.1042, -0.3390, -0.2862],\n",
            "        [ 0.3331,  0.5684,  0.4439, -0.5122,  0.4273]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "x: tensor([[0.7222, 0.8597, 0.6871, 0.0000, 0.9911],\n",
            "        [0.0000, 0.8626, 0.5041, 0.0000, 0.1663],\n",
            "        [0.1831, 0.5312, 0.2006, 0.0000, 0.4415],\n",
            "        [0.0000, 0.5118, 0.0000, 0.0000, 0.0000],\n",
            "        [0.3331, 0.5684, 0.4439, 0.0000, 0.4273]], grad_fn=<ReluBackward0>)\n",
            "x: tensor([[ 0.0713,  0.2672, -0.0404, -0.2463, -0.4645],\n",
            "        [ 0.0314,  0.4035,  0.3974, -0.1937, -0.2295],\n",
            "        [-0.0538,  0.3727,  0.2394, -0.2409, -0.2611],\n",
            "        [-0.0405,  0.4894,  0.4600, -0.3319, -0.1335],\n",
            "        [-0.0370,  0.2956,  0.1616, -0.2230, -0.2431]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "x: tensor([[0.0713, 0.2672, 0.0000, 0.0000, 0.0000],\n",
            "        [0.0314, 0.4035, 0.3974, 0.0000, 0.0000],\n",
            "        [0.0000, 0.3727, 0.2394, 0.0000, 0.0000],\n",
            "        [0.0000, 0.4894, 0.4600, 0.0000, 0.0000],\n",
            "        [0.0000, 0.2956, 0.1616, 0.0000, 0.0000]], grad_fn=<ReluBackward0>)\n",
            "hidden_outputs: [tensor([[-2.1788,  0.5684, -1.0845],\n",
            "        [-1.3986,  0.4033,  0.8380],\n",
            "        [-0.7193, -0.4033, -0.5966],\n",
            "        [ 0.1820, -0.8567,  1.1006],\n",
            "        [-1.0712,  0.1227, -0.5663]]), tensor([[0.0713, 0.2672, 0.0000, 0.0000, 0.0000],\n",
            "        [0.0314, 0.4035, 0.3974, 0.0000, 0.0000],\n",
            "        [0.0000, 0.3727, 0.2394, 0.0000, 0.0000],\n",
            "        [0.0000, 0.4894, 0.4600, 0.0000, 0.0000],\n",
            "        [0.0000, 0.2956, 0.1616, 0.0000, 0.0000]], grad_fn=<ReluBackward0>)]\n",
            "x: tensor([[0.3415, 0.1833],\n",
            "        [0.4612, 0.0674],\n",
            "        [0.4106, 0.1279],\n",
            "        [0.5016, 0.0612],\n",
            "        [0.3625, 0.1485]], grad_fn=<AddmmBackward0>)\n",
            "concatenate_hidden: tensor([[-2.1788,  0.5684, -1.0845,  0.0713,  0.2672,  0.0000,  0.0000,  0.0000],\n",
            "        [-1.3986,  0.4033,  0.8380,  0.0314,  0.4035,  0.3974,  0.0000,  0.0000],\n",
            "        [-0.7193, -0.4033, -0.5966,  0.0000,  0.3727,  0.2394,  0.0000,  0.0000],\n",
            "        [ 0.1820, -0.8567,  1.1006,  0.0000,  0.4894,  0.4600,  0.0000,  0.0000],\n",
            "        [-1.0712,  0.1227, -0.5663,  0.0000,  0.2956,  0.1616,  0.0000,  0.0000]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "detached_concatenate_hidden: tensor([[-2.1788,  0.5684, -1.0845,  0.0713,  0.2672,  0.0000,  0.0000,  0.0000],\n",
            "        [-1.3986,  0.4033,  0.8380,  0.0314,  0.4035,  0.3974,  0.0000,  0.0000],\n",
            "        [-0.7193, -0.4033, -0.5966,  0.0000,  0.3727,  0.2394,  0.0000,  0.0000],\n",
            "        [ 0.1820, -0.8567,  1.1006,  0.0000,  0.4894,  0.4600,  0.0000,  0.0000],\n",
            "        [-1.0712,  0.1227, -0.5663,  0.0000,  0.2956,  0.1616,  0.0000,  0.0000]])\n",
            "detached_concatenate_hidden_to_prior : tensor([[-2.1788,  0.5684, -1.0845,  0.0713,  0.2672,  0.0000,  0.0000,  0.0000],\n",
            "        [-1.3986,  0.4033,  0.8380,  0.0314,  0.4035,  0.3974,  0.0000,  0.0000],\n",
            "        [-0.7193, -0.4033, -0.5966,  0.0000,  0.3727,  0.2394,  0.0000,  0.0000],\n",
            "        [ 0.1820, -0.8567,  1.1006,  0.0000,  0.4894,  0.4600,  0.0000,  0.0000],\n",
            "        [-1.0712,  0.1227, -0.5663,  0.0000,  0.2956,  0.1616,  0.0000,  0.0000]])\n",
            "z_repeated: tensor([[ 0.3731, -0.8920, -1.5091],\n",
            "        [ 0.3731, -0.8920, -1.5091],\n",
            "        [ 0.3731, -0.8920, -1.5091],\n",
            "        [ 0.3731, -0.8920, -1.5091],\n",
            "        [ 0.3731, -0.8920, -1.5091]])\n",
            "combined_output: tensor([[-2.1788,  0.5684, -1.0845,  0.0713,  0.2672,  0.0000,  0.0000,  0.0000,\n",
            "          0.3731, -0.8920, -1.5091],\n",
            "        [-1.3986,  0.4033,  0.8380,  0.0314,  0.4035,  0.3974,  0.0000,  0.0000,\n",
            "          0.3731, -0.8920, -1.5091],\n",
            "        [-0.7193, -0.4033, -0.5966,  0.0000,  0.3727,  0.2394,  0.0000,  0.0000,\n",
            "          0.3731, -0.8920, -1.5091],\n",
            "        [ 0.1820, -0.8567,  1.1006,  0.0000,  0.4894,  0.4600,  0.0000,  0.0000,\n",
            "          0.3731, -0.8920, -1.5091],\n",
            "        [-1.0712,  0.1227, -0.5663,  0.0000,  0.2956,  0.1616,  0.0000,  0.0000,\n",
            "          0.3731, -0.8920, -1.5091]])\n",
            "combined_output: tensor([[-0.1591,  0.3529, -0.1975,  0.2700,  1.1508, -0.3959, -0.6482, -0.4618],\n",
            "        [-0.7546,  0.2308,  0.4023,  0.1698,  1.4332,  0.1128, -0.6153, -0.7316],\n",
            "        [-0.3469, -0.1029,  0.0457,  0.2740,  0.8719, -0.2956, -0.3315, -0.2551],\n",
            "        [-0.8448, -0.3457,  0.5726,  0.1026,  0.9741,  0.1578, -0.1774, -0.4553],\n",
            "        [-0.3037,  0.0663,  0.0190,  0.3156,  1.0392, -0.2440, -0.4658, -0.3857]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "combined_output: tensor([[0.0000, 0.3529, 0.0000, 0.2700, 1.1508, 0.0000, 0.0000, 0.0000],\n",
            "        [0.0000, 0.2308, 0.4023, 0.1698, 1.4332, 0.1128, 0.0000, 0.0000],\n",
            "        [0.0000, 0.0000, 0.0457, 0.2740, 0.8719, 0.0000, 0.0000, 0.0000],\n",
            "        [0.0000, 0.0000, 0.5726, 0.1026, 0.9741, 0.1578, 0.0000, 0.0000],\n",
            "        [0.0000, 0.0663, 0.0190, 0.3156, 1.0392, 0.0000, 0.0000, 0.0000]],\n",
            "       grad_fn=<ReluBackward0>)\n",
            "combined_output: tensor([[-2.6646e-01, -2.1410e-01, -2.0303e-01,  2.4239e-01, -1.2999e-01,\n",
            "         -1.5775e-01,  3.4518e-01, -6.9196e-02],\n",
            "        [-1.4075e-01, -3.6976e-01, -2.1599e-01,  3.4414e-01, -2.1566e-01,\n",
            "         -2.5208e-02,  3.7877e-01, -1.5460e-01],\n",
            "        [-2.6340e-01, -2.4060e-01, -1.9395e-01,  2.5862e-01, -1.9568e-01,\n",
            "         -1.3842e-01,  2.6514e-01, -2.8071e-04],\n",
            "        [-9.9654e-03, -4.1708e-01, -2.3194e-01,  3.0536e-01, -2.9090e-01,\n",
            "          2.3761e-02,  3.0422e-01, -2.4393e-02],\n",
            "        [-3.0150e-01, -2.4052e-01, -1.8460e-01,  2.7878e-01, -1.6948e-01,\n",
            "         -1.4665e-01,  2.9124e-01, -5.0225e-02]], grad_fn=<AddmmBackward0>)\n",
            "combined_output: tensor([[0.0000, 0.0000, 0.0000, 0.2424, 0.0000, 0.0000, 0.3452, 0.0000],\n",
            "        [0.0000, 0.0000, 0.0000, 0.3441, 0.0000, 0.0000, 0.3788, 0.0000],\n",
            "        [0.0000, 0.0000, 0.0000, 0.2586, 0.0000, 0.0000, 0.2651, 0.0000],\n",
            "        [0.0000, 0.0000, 0.0000, 0.3054, 0.0000, 0.0238, 0.3042, 0.0000],\n",
            "        [0.0000, 0.0000, 0.0000, 0.2788, 0.0000, 0.0000, 0.2912, 0.0000]],\n",
            "       grad_fn=<ReluBackward0>)\n",
            "combined_output: tensor([[ 0.1934, -0.1273, -0.0680,  0.4551,  0.2512, -0.3219],\n",
            "        [ 0.2104, -0.1053, -0.0766,  0.4815,  0.2615, -0.3213],\n",
            "        [ 0.2023, -0.0981, -0.0628,  0.4404,  0.2818, -0.3307],\n",
            "        [ 0.2069, -0.0959, -0.0740,  0.4597,  0.2786, -0.3212],\n",
            "        [ 0.2043, -0.0996, -0.0660,  0.4500,  0.2773, -0.3286]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "intermediary_check, x: tensor([[0.3415, 0.1833],\n",
            "        [0.4612, 0.0674],\n",
            "        [0.4106, 0.1279],\n",
            "        [0.5016, 0.0612],\n",
            "        [0.3625, 0.1485]], grad_fn=<AddmmBackward0>)\n",
            "intermediary_check, concatenate_hidden: tensor([[-2.1788,  0.5684, -1.0845,  0.0713,  0.2672,  0.0000,  0.0000,  0.0000],\n",
            "        [-1.3986,  0.4033,  0.8380,  0.0314,  0.4035,  0.3974,  0.0000,  0.0000],\n",
            "        [-0.7193, -0.4033, -0.5966,  0.0000,  0.3727,  0.2394,  0.0000,  0.0000],\n",
            "        [ 0.1820, -0.8567,  1.1006,  0.0000,  0.4894,  0.4600,  0.0000,  0.0000],\n",
            "        [-1.0712,  0.1227, -0.5663,  0.0000,  0.2956,  0.1616,  0.0000,  0.0000]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "intermediary_check, detached_concatenate_hidden: tensor([[-2.1788,  0.5684, -1.0845,  0.0713,  0.2672,  0.0000,  0.0000,  0.0000],\n",
            "        [-1.3986,  0.4033,  0.8380,  0.0314,  0.4035,  0.3974,  0.0000,  0.0000],\n",
            "        [-0.7193, -0.4033, -0.5966,  0.0000,  0.3727,  0.2394,  0.0000,  0.0000],\n",
            "        [ 0.1820, -0.8567,  1.1006,  0.0000,  0.4894,  0.4600,  0.0000,  0.0000],\n",
            "        [-1.0712,  0.1227, -0.5663,  0.0000,  0.2956,  0.1616,  0.0000,  0.0000]])\n",
            "intermediary_check, detached_concatenate_hidden_to_prior: tensor([[-2.1788,  0.5684, -1.0845,  0.0713,  0.2672,  0.0000,  0.0000,  0.0000],\n",
            "        [-1.3986,  0.4033,  0.8380,  0.0314,  0.4035,  0.3974,  0.0000,  0.0000],\n",
            "        [-0.7193, -0.4033, -0.5966,  0.0000,  0.3727,  0.2394,  0.0000,  0.0000],\n",
            "        [ 0.1820, -0.8567,  1.1006,  0.0000,  0.4894,  0.4600,  0.0000,  0.0000],\n",
            "        [-1.0712,  0.1227, -0.5663,  0.0000,  0.2956,  0.1616,  0.0000,  0.0000]])\n",
            "detached_concatenate_hidden_to_prior: tensor([[-2.1788,  0.5684, -1.0845,  0.0713,  0.2672,  0.0000,  0.0000,  0.0000],\n",
            "        [-1.3986,  0.4033,  0.8380,  0.0314,  0.4035,  0.3974,  0.0000,  0.0000],\n",
            "        [-0.7193, -0.4033, -0.5966,  0.0000,  0.3727,  0.2394,  0.0000,  0.0000],\n",
            "        [ 0.1820, -0.8567,  1.1006,  0.0000,  0.4894,  0.4600,  0.0000,  0.0000],\n",
            "        [-1.0712,  0.1227, -0.5663,  0.0000,  0.2956,  0.1616,  0.0000,  0.0000]])\n",
            "reshaped_epinet_output: tensor([[[ 0.1934, -0.1273, -0.0680],\n",
            "         [ 0.4551,  0.2512, -0.3219]],\n",
            "\n",
            "        [[ 0.2104, -0.1053, -0.0766],\n",
            "         [ 0.4815,  0.2615, -0.3213]],\n",
            "\n",
            "        [[ 0.2023, -0.0981, -0.0628],\n",
            "         [ 0.4404,  0.2818, -0.3307]],\n",
            "\n",
            "        [[ 0.2069, -0.0959, -0.0740],\n",
            "         [ 0.4597,  0.2786, -0.3212]],\n",
            "\n",
            "        [[ 0.2043, -0.0996, -0.0660],\n",
            "         [ 0.4500,  0.2773, -0.3286]]], grad_fn=<ViewBackward0>)\n",
            "epinet_output: tensor([[0.2884, 0.4315],\n",
            "        [0.2881, 0.4313],\n",
            "        [0.2577, 0.4120],\n",
            "        [0.2744, 0.4077],\n",
            "        [0.2646, 0.4164]], grad_fn=<UnsafeViewBackward0>)\n",
            "outputs_prior: [tensor([[0.8436, 0.7279],\n",
            "        [0.1174, 0.1013],\n",
            "        [0.2360, 0.2036],\n",
            "        [0.0000, 0.0000],\n",
            "        [0.3915, 0.3378]]), tensor([[0.6673, 0.7475],\n",
            "        [0.2716, 0.3042],\n",
            "        [0.1017, 0.1140],\n",
            "        [0.0000, 0.0000],\n",
            "        [0.2533, 0.2837]]), tensor([[ 2.2873, -1.1757],\n",
            "        [ 0.0000,  0.0000],\n",
            "        [ 0.4448, -0.2286],\n",
            "        [ 0.0000,  0.0000],\n",
            "        [ 1.0032, -0.5157]])]\n",
            "outputs_prior_tensor: tensor([[[ 0.8436,  0.7279],\n",
            "         [ 0.1174,  0.1013],\n",
            "         [ 0.2360,  0.2036],\n",
            "         [ 0.0000,  0.0000],\n",
            "         [ 0.3915,  0.3378]],\n",
            "\n",
            "        [[ 0.6673,  0.7475],\n",
            "         [ 0.2716,  0.3042],\n",
            "         [ 0.1017,  0.1140],\n",
            "         [ 0.0000,  0.0000],\n",
            "         [ 0.2533,  0.2837]],\n",
            "\n",
            "        [[ 2.2873, -1.1757],\n",
            "         [ 0.0000,  0.0000],\n",
            "         [ 0.4448, -0.2286],\n",
            "         [ 0.0000,  0.0000],\n",
            "         [ 1.0032, -0.5157]]])\n",
            "prior_output: tensor([[-3.7323,  1.3791],\n",
            "        [-0.1985, -0.2336],\n",
            "        [-0.6739,  0.3193],\n",
            "        [ 0.0000,  0.0000],\n",
            "        [-1.5938,  0.6512]])\n",
            "final_output: tensor([[0.2567, 0.7528],\n",
            "        [0.7295, 0.4753],\n",
            "        [0.6009, 0.5719],\n",
            "        [0.7760, 0.4688],\n",
            "        [0.4677, 0.6300]], grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.2567, 0.7528],\n",
              "        [0.7295, 0.4753],\n",
              "        [0.6009, 0.5719],\n",
              "        [0.7760, 0.4688],\n",
              "        [0.4677, 0.6300]], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for name, param in model.named_parameters():\n",
        "    if param.requires_grad:\n",
        "        print(name, param.data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lPmqHKdbayH5",
        "outputId": "e59cb772-203f-45de-a42b-0ad58fc553b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "basenet_layers.0.weight tensor([[ 0.1324, -0.1374,  0.1583],\n",
            "        [-0.0295,  0.2466,  0.1375],\n",
            "        [-0.0664, -0.4668,  0.1318],\n",
            "        [-0.5112,  0.0759,  0.0384],\n",
            "        [-0.1270,  0.4721,  0.0385]])\n",
            "basenet_layers.0.bias tensor([ 0.2394,  0.2443, -0.3406, -0.2220,  0.5552])\n",
            "basenet_layers.1.weight tensor([[-0.4380, -0.0304, -0.0354,  0.3172, -0.0425],\n",
            "        [ 0.1178, -0.0215, -0.2504, -0.2535, -0.2173],\n",
            "        [-0.4063, -0.2902,  0.1053,  0.2943,  0.0220],\n",
            "        [-0.2050,  0.1965, -0.1717, -0.0991, -0.2452],\n",
            "        [-0.1404, -0.4144,  0.1908,  0.1739,  0.0888]])\n",
            "basenet_layers.1.bias tensor([0.2196, 0.1895, 0.0198, 0.0474, 0.0341])\n",
            "basenet_layers.2.weight tensor([[ 0.2386,  0.3004,  0.3212,  0.2592, -0.1090],\n",
            "        [-0.0199, -0.0909,  0.2602,  0.0497,  0.4139]])\n",
            "basenet_layers.2.bias tensor([ 0.2268, -0.3822])\n",
            "learnable_epinet_layers.0.weight tensor([[ 0.1554, -0.1331, -0.0585,  0.1415, -0.2839,  0.1808, -0.0620,  0.1534,\n",
            "          0.0419, -0.0369,  0.0836],\n",
            "        [ 0.0149,  0.1101, -0.1175, -0.0220, -0.0271,  0.0437, -0.0012,  0.2636,\n",
            "          0.0938, -0.1123, -0.1821],\n",
            "        [-0.0505, -0.1301, -0.0966,  0.0144,  0.1797,  0.1639, -0.2947,  0.1869,\n",
            "          0.0842,  0.2860,  0.1990],\n",
            "        [-0.2747, -0.2867, -0.1454,  0.2648, -0.0502,  0.1290, -0.1401,  0.2958,\n",
            "         -0.1276,  0.2261,  0.0036],\n",
            "        [-0.1588,  0.1550, -0.1600,  0.0887, -0.0871, -0.0331, -0.2899, -0.1438,\n",
            "          0.1636, -0.0733,  0.3003],\n",
            "        [ 0.2417, -0.0141, -0.2013,  0.1836,  0.0936, -0.1949,  0.1958,  0.1830,\n",
            "          0.2674, -0.1690, -0.0496],\n",
            "        [-0.0058,  0.0440, -0.2288, -0.2140,  0.1640, -0.0707,  0.1473,  0.0172,\n",
            "          0.0990,  0.0663,  0.1096],\n",
            "        [ 0.1495, -0.2792,  0.1518, -0.2120, -0.2275,  0.0183, -0.0514,  0.1771,\n",
            "         -0.1746, -0.2680,  0.2194]])\n",
            "learnable_epinet_layers.0.bias tensor([-0.0447,  0.1696,  0.0969, -0.2261,  0.0606,  0.0724, -0.2019, -0.1431])\n",
            "learnable_epinet_layers.1.weight tensor([[ 0.1206,  0.0633, -0.1504, -0.1070,  0.3238, -0.0654,  0.1993,  0.1531],\n",
            "        [-0.2285, -0.3007,  0.3394,  0.0185,  0.2423,  0.0733,  0.1137,  0.2641],\n",
            "        [ 0.3352, -0.2346,  0.0442,  0.2638,  0.2561,  0.2196, -0.2559, -0.2546],\n",
            "        [-0.2138,  0.0444,  0.3524, -0.2233,  0.1884, -0.1957, -0.3324, -0.0751],\n",
            "        [ 0.2037,  0.3282, -0.2196,  0.0767,  0.3051,  0.2343,  0.2203,  0.2512],\n",
            "        [ 0.2236,  0.0913, -0.2418, -0.2969, -0.1620, -0.0412, -0.2167,  0.1293],\n",
            "        [ 0.1094, -0.0801,  0.1359,  0.1143,  0.2159,  0.2381, -0.1197,  0.3454],\n",
            "        [-0.0409, -0.0121, -0.3337, -0.2276, -0.2065, -0.1512,  0.2514, -0.1155]])\n",
            "learnable_epinet_layers.1.bias tensor([-0.2642,  0.1360,  0.1132,  0.2290, -0.1830,  0.0767, -0.1287, -0.0794])\n",
            "learnable_epinet_layers.2.weight tensor([[-0.2818, -0.1611, -0.1083,  0.1512,  0.0646,  0.0873,  0.3529,  0.3446],\n",
            "        [ 0.2411,  0.0113, -0.2446,  0.2763, -0.0884, -0.0286, -0.3046, -0.0698],\n",
            "        [-0.2280,  0.3249, -0.3057, -0.2756, -0.0120, -0.1912,  0.1265, -0.1361],\n",
            "        [-0.1661,  0.0200,  0.2559, -0.2487,  0.1660,  0.2271,  0.3458, -0.2475],\n",
            "        [ 0.0856, -0.2614,  0.3018, -0.1371,  0.2130,  0.0105, -0.0275, -0.0113],\n",
            "        [ 0.0601,  0.1667,  0.0567,  0.1079, -0.3180,  0.2576,  0.3083,  0.2922]])\n",
            "learnable_epinet_layers.2.bias tensor([ 0.2614, -0.2551, -0.1311,  0.3117, -0.2693,  0.3208])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for name, param in model.named_parameters():\n",
        "        print(name, param.data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yu3KiNxDaz-E",
        "outputId": "9c1d8461-f5e2-40ad-b407-24a4e01dfdfc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "basenet_layers.0.weight tensor([[-0.5181, -0.4985, -0.0903],\n",
            "        [ 0.0075, -0.2623,  0.2175],\n",
            "        [-0.5196, -0.0390,  0.5077],\n",
            "        [-0.2355,  0.5213,  0.2091],\n",
            "        [-0.5210,  0.3653, -0.0666]])\n",
            "basenet_layers.0.bias tensor([-0.2577,  0.4617, -0.4666,  0.0620, -0.1209])\n",
            "basenet_layers.1.weight tensor([[ 0.3194,  0.1248,  0.2149,  0.1579, -0.1075],\n",
            "        [-0.0941, -0.3685,  0.2423,  0.3551,  0.3060],\n",
            "        [-0.3155,  0.0199, -0.3153, -0.2462, -0.2606],\n",
            "        [ 0.1528, -0.2665, -0.0098,  0.0188,  0.2883],\n",
            "        [-0.3381, -0.3070, -0.2597,  0.3130, -0.1608]])\n",
            "basenet_layers.1.bias tensor([ 0.3772,  0.1617,  0.0566, -0.0033, -0.0884])\n",
            "basenet_layers.2.weight tensor([[ 0.0561, -0.1021, -0.0031,  0.0571, -0.3498],\n",
            "        [-0.2344,  0.3611, -0.3629, -0.0321,  0.4424]])\n",
            "basenet_layers.2.bias tensor([0.1616, 0.0127])\n",
            "learnable_epinet_layers.0.weight tensor([[-0.2613,  0.1494, -0.2148, -0.0856, -0.1012, -0.0447,  0.0033,  0.2487,\n",
            "          0.0376,  0.2701,  0.1844],\n",
            "        [-0.1906,  0.1352, -0.2131, -0.1278,  0.0887,  0.0996,  0.2262, -0.0971,\n",
            "          0.0005,  0.1552, -0.2916],\n",
            "        [ 0.2180, -0.2493,  0.0042, -0.0513, -0.1588,  0.0399,  0.2493, -0.0881,\n",
            "         -0.1790, -0.1115, -0.2988],\n",
            "        [ 0.1361, -0.1448, -0.2012, -0.1737,  0.1734,  0.1597,  0.2314,  0.1094,\n",
            "         -0.1007, -0.0843,  0.0891],\n",
            "        [ 0.2479,  0.0820, -0.1427, -0.1417, -0.2851,  0.0651, -0.1692, -0.2688,\n",
            "          0.2644, -0.1958, -0.0343],\n",
            "        [ 0.0864,  0.0096, -0.2029, -0.2437,  0.2403,  0.0491,  0.2501, -0.1011,\n",
            "          0.0888, -0.0689, -0.0134],\n",
            "        [-0.1836,  0.1020,  0.0953, -0.0062, -0.0678, -0.1859,  0.2085, -0.2245,\n",
            "          0.1235, -0.1014, -0.1455],\n",
            "        [ 0.0542, -0.1566,  0.0695,  0.0592, -0.2239,  0.0502,  0.1284,  0.1193,\n",
            "         -0.0380, -0.2472, -0.0465]])\n",
            "learnable_epinet_layers.0.bias tensor([ 0.1047, -0.1100,  0.1144,  0.2008, -0.1574,  0.0030,  0.1247,  0.0236])\n",
            "learnable_epinet_layers.1.weight tensor([[ 0.0295,  0.0441, -0.2779,  0.0278,  0.2448,  0.3186,  0.2078,  0.0474],\n",
            "        [ 0.1651, -0.1720, -0.2930, -0.3040,  0.3527,  0.2244, -0.2444,  0.1383],\n",
            "        [ 0.2670,  0.3534,  0.3091,  0.2739, -0.0811, -0.1241,  0.2903,  0.1981],\n",
            "        [-0.2128,  0.3179,  0.1708,  0.1927, -0.2216,  0.1014, -0.1239,  0.2763],\n",
            "        [-0.0636,  0.1376,  0.0628,  0.1504, -0.1201,  0.1724, -0.2469,  0.0799],\n",
            "        [-0.2392, -0.3488, -0.2839,  0.2791,  0.1913,  0.3317,  0.2832, -0.3157],\n",
            "        [-0.2413, -0.0571, -0.2296,  0.2455, -0.2673, -0.1725, -0.3416, -0.2007],\n",
            "        [ 0.2908,  0.2895,  0.2531,  0.2730,  0.3144, -0.0905,  0.1556,  0.3150]])\n",
            "learnable_epinet_layers.1.bias tensor([ 0.1170,  0.3534,  0.1834,  0.2198, -0.1237,  0.1696,  0.0406, -0.0844])\n",
            "learnable_epinet_layers.2.weight tensor([[-0.1993, -0.1984, -0.2721,  0.2374,  0.2514, -0.0402, -0.2046,  0.2733],\n",
            "        [ 0.2261,  0.0263, -0.1669,  0.3249,  0.1446, -0.2684,  0.3384,  0.2685],\n",
            "        [-0.1289,  0.1988, -0.2009, -0.0554,  0.3002,  0.0146, -0.2500, -0.1182],\n",
            "        [-0.0960, -0.0682,  0.0338,  0.3270,  0.0189, -0.2183,  0.0181,  0.1695],\n",
            "        [ 0.1754, -0.3231, -0.0633, -0.2627, -0.1509,  0.1274, -0.2511,  0.1314],\n",
            "        [ 0.3001,  0.0232, -0.2356, -0.1267,  0.0772, -0.2695,  0.1756, -0.3210]])\n",
            "learnable_epinet_layers.2.bias tensor([-0.3399, -0.3435, -0.0717,  0.2377, -0.3346,  0.2939])\n",
            "ensemble.0.0.weight tensor([[-0.5251, -0.3373,  0.2813,  0.6432, -0.1594,  0.5796, -0.1249,  0.0820],\n",
            "        [ 0.7014, -0.7186, -0.4876, -0.1961, -0.3019,  0.6693, -0.5021, -0.3566]])\n",
            "ensemble.0.0.bias tensor([0., 0.])\n",
            "ensemble.0.2.weight tensor([[ 0.0644, -0.6279],\n",
            "        [ 0.2072, -1.1435]])\n",
            "ensemble.0.2.bias tensor([0., 0.])\n",
            "ensemble.0.4.weight tensor([[0.7833, 1.2176],\n",
            "        [0.4861, 0.1655]])\n",
            "ensemble.0.4.bias tensor([0., 0.])\n",
            "ensemble.1.0.weight tensor([[ 0.3044,  0.6418,  0.6741,  0.6835,  0.1542, -0.6736,  0.0713, -0.4846],\n",
            "        [-0.7219,  0.6882,  0.5890, -0.7727,  0.1450, -0.1305, -0.1275, -0.3546]])\n",
            "ensemble.1.0.bias tensor([0., 0.])\n",
            "ensemble.1.2.weight tensor([[-1.2122, -0.7945],\n",
            "        [ 0.6115,  0.2563]])\n",
            "ensemble.1.2.bias tensor([0., 0.])\n",
            "ensemble.1.4.weight tensor([[-1.1667, -0.0220],\n",
            "        [-0.9223, -0.9447]])\n",
            "ensemble.1.4.bias tensor([0., 0.])\n",
            "ensemble.2.0.weight tensor([[-0.1939, -0.3773, -0.2710, -0.6349, -0.1648,  0.1656, -0.5046, -0.0398],\n",
            "        [ 0.5545, -0.0796,  0.0215, -0.0668,  0.1568,  0.4925,  0.7337,  0.4919]])\n",
            "ensemble.2.0.bias tensor([0., 0.])\n",
            "ensemble.2.2.weight tensor([[-0.6088, -0.9385],\n",
            "        [-1.1462, -1.0337]])\n",
            "ensemble.2.2.bias tensor([0., 0.])\n",
            "ensemble.2.4.weight tensor([[-0.2589, -0.4966],\n",
            "        [-0.2359, -0.2405]])\n",
            "ensemble.2.4.bias tensor([0., 0.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_2 = basenet_with_learnable_epinet_and_ensemble_prior(input_size, basenet_hidden_sizes, n_classes, exposed_layers, z_dim, learnable_epinet_hiddens, hidden_sizes_prior,seed_prior, alpha)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5vqnS85dpdG",
        "outputId": "bac84f32-d5b7-4917-94e6-609c3584daa3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "basenet_all_sizes: [3, 5, 5, 2]\n",
            "exposed_layers: [True, False, True, False]\n",
            "basenet_layers: ModuleList(\n",
            "  (0): Linear(in_features=3, out_features=5, bias=True)\n",
            "  (1): Linear(in_features=5, out_features=5, bias=True)\n",
            "  (2): Linear(in_features=5, out_features=2, bias=True)\n",
            ")\n",
            "sum_input_base_epi: 8\n",
            "learnable_epinet_all_sizes: [11, 8, 8, 6]\n",
            "learnable_epinet_layers: ModuleList(\n",
            "  (0): Linear(in_features=11, out_features=8, bias=True)\n",
            "  (1): Linear(in_features=8, out_features=8, bias=True)\n",
            "  (2): Linear(in_features=8, out_features=6, bias=True)\n",
            ")\n",
            "ensemble: ModuleList(\n",
            "  (0-2): 3 x Sequential(\n",
            "    (0): Linear(in_features=8, out_features=2, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=2, out_features=2, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=2, out_features=2, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for name, param in model_2.named_parameters():\n",
        "        print(name, param.data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DUOuOTRfdvCQ",
        "outputId": "98e9486f-732f-4973-c485-19c796378299"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "basenet_layers.0.weight tensor([[-0.5181, -0.4985, -0.0903],\n",
            "        [ 0.0075, -0.2623,  0.2175],\n",
            "        [-0.5196, -0.0390,  0.5077],\n",
            "        [-0.2355,  0.5213,  0.2091],\n",
            "        [-0.5210,  0.3653, -0.0666]])\n",
            "basenet_layers.0.bias tensor([-0.2577,  0.4617, -0.4666,  0.0620, -0.1209])\n",
            "basenet_layers.1.weight tensor([[ 0.3194,  0.1248,  0.2149,  0.1579, -0.1075],\n",
            "        [-0.0941, -0.3685,  0.2423,  0.3551,  0.3060],\n",
            "        [-0.3155,  0.0199, -0.3153, -0.2462, -0.2606],\n",
            "        [ 0.1528, -0.2665, -0.0098,  0.0188,  0.2883],\n",
            "        [-0.3381, -0.3070, -0.2597,  0.3130, -0.1608]])\n",
            "basenet_layers.1.bias tensor([ 0.3772,  0.1617,  0.0566, -0.0033, -0.0884])\n",
            "basenet_layers.2.weight tensor([[ 0.0561, -0.1021, -0.0031,  0.0571, -0.3498],\n",
            "        [-0.2344,  0.3611, -0.3629, -0.0321,  0.4424]])\n",
            "basenet_layers.2.bias tensor([0.1616, 0.0127])\n",
            "learnable_epinet_layers.0.weight tensor([[-0.2613,  0.1494, -0.2148, -0.0856, -0.1012, -0.0447,  0.0033,  0.2487,\n",
            "          0.0376,  0.2701,  0.1844],\n",
            "        [-0.1906,  0.1352, -0.2131, -0.1278,  0.0887,  0.0996,  0.2262, -0.0971,\n",
            "          0.0005,  0.1552, -0.2916],\n",
            "        [ 0.2180, -0.2493,  0.0042, -0.0513, -0.1588,  0.0399,  0.2493, -0.0881,\n",
            "         -0.1790, -0.1115, -0.2988],\n",
            "        [ 0.1361, -0.1448, -0.2012, -0.1737,  0.1734,  0.1597,  0.2314,  0.1094,\n",
            "         -0.1007, -0.0843,  0.0891],\n",
            "        [ 0.2479,  0.0820, -0.1427, -0.1417, -0.2851,  0.0651, -0.1692, -0.2688,\n",
            "          0.2644, -0.1958, -0.0343],\n",
            "        [ 0.0864,  0.0096, -0.2029, -0.2437,  0.2403,  0.0491,  0.2501, -0.1011,\n",
            "          0.0888, -0.0689, -0.0134],\n",
            "        [-0.1836,  0.1020,  0.0953, -0.0062, -0.0678, -0.1859,  0.2085, -0.2245,\n",
            "          0.1235, -0.1014, -0.1455],\n",
            "        [ 0.0542, -0.1566,  0.0695,  0.0592, -0.2239,  0.0502,  0.1284,  0.1193,\n",
            "         -0.0380, -0.2472, -0.0465]])\n",
            "learnable_epinet_layers.0.bias tensor([ 0.1047, -0.1100,  0.1144,  0.2008, -0.1574,  0.0030,  0.1247,  0.0236])\n",
            "learnable_epinet_layers.1.weight tensor([[ 0.0295,  0.0441, -0.2779,  0.0278,  0.2448,  0.3186,  0.2078,  0.0474],\n",
            "        [ 0.1651, -0.1720, -0.2930, -0.3040,  0.3527,  0.2244, -0.2444,  0.1383],\n",
            "        [ 0.2670,  0.3534,  0.3091,  0.2739, -0.0811, -0.1241,  0.2903,  0.1981],\n",
            "        [-0.2128,  0.3179,  0.1708,  0.1927, -0.2216,  0.1014, -0.1239,  0.2763],\n",
            "        [-0.0636,  0.1376,  0.0628,  0.1504, -0.1201,  0.1724, -0.2469,  0.0799],\n",
            "        [-0.2392, -0.3488, -0.2839,  0.2791,  0.1913,  0.3317,  0.2832, -0.3157],\n",
            "        [-0.2413, -0.0571, -0.2296,  0.2455, -0.2673, -0.1725, -0.3416, -0.2007],\n",
            "        [ 0.2908,  0.2895,  0.2531,  0.2730,  0.3144, -0.0905,  0.1556,  0.3150]])\n",
            "learnable_epinet_layers.1.bias tensor([ 0.1170,  0.3534,  0.1834,  0.2198, -0.1237,  0.1696,  0.0406, -0.0844])\n",
            "learnable_epinet_layers.2.weight tensor([[-0.1993, -0.1984, -0.2721,  0.2374,  0.2514, -0.0402, -0.2046,  0.2733],\n",
            "        [ 0.2261,  0.0263, -0.1669,  0.3249,  0.1446, -0.2684,  0.3384,  0.2685],\n",
            "        [-0.1289,  0.1988, -0.2009, -0.0554,  0.3002,  0.0146, -0.2500, -0.1182],\n",
            "        [-0.0960, -0.0682,  0.0338,  0.3270,  0.0189, -0.2183,  0.0181,  0.1695],\n",
            "        [ 0.1754, -0.3231, -0.0633, -0.2627, -0.1509,  0.1274, -0.2511,  0.1314],\n",
            "        [ 0.3001,  0.0232, -0.2356, -0.1267,  0.0772, -0.2695,  0.1756, -0.3210]])\n",
            "learnable_epinet_layers.2.bias tensor([-0.3399, -0.3435, -0.0717,  0.2377, -0.3346,  0.2939])\n",
            "ensemble.0.0.weight tensor([[-0.5251, -0.3373,  0.2813,  0.6432, -0.1594,  0.5796, -0.1249,  0.0820],\n",
            "        [ 0.7014, -0.7186, -0.4876, -0.1961, -0.3019,  0.6693, -0.5021, -0.3566]])\n",
            "ensemble.0.0.bias tensor([0., 0.])\n",
            "ensemble.0.2.weight tensor([[ 0.0644, -0.6279],\n",
            "        [ 0.2072, -1.1435]])\n",
            "ensemble.0.2.bias tensor([0., 0.])\n",
            "ensemble.0.4.weight tensor([[0.7833, 1.2176],\n",
            "        [0.4861, 0.1655]])\n",
            "ensemble.0.4.bias tensor([0., 0.])\n",
            "ensemble.1.0.weight tensor([[ 0.3044,  0.6418,  0.6741,  0.6835,  0.1542, -0.6736,  0.0713, -0.4846],\n",
            "        [-0.7219,  0.6882,  0.5890, -0.7727,  0.1450, -0.1305, -0.1275, -0.3546]])\n",
            "ensemble.1.0.bias tensor([0., 0.])\n",
            "ensemble.1.2.weight tensor([[-1.2122, -0.7945],\n",
            "        [ 0.6115,  0.2563]])\n",
            "ensemble.1.2.bias tensor([0., 0.])\n",
            "ensemble.1.4.weight tensor([[-1.1667, -0.0220],\n",
            "        [-0.9223, -0.9447]])\n",
            "ensemble.1.4.bias tensor([0., 0.])\n",
            "ensemble.2.0.weight tensor([[-0.1939, -0.3773, -0.2710, -0.6349, -0.1648,  0.1656, -0.5046, -0.0398],\n",
            "        [ 0.5545, -0.0796,  0.0215, -0.0668,  0.1568,  0.4925,  0.7337,  0.4919]])\n",
            "ensemble.2.0.bias tensor([0., 0.])\n",
            "ensemble.2.2.weight tensor([[-0.6088, -0.9385],\n",
            "        [-1.1462, -1.0337]])\n",
            "ensemble.2.2.bias tensor([0., 0.])\n",
            "ensemble.2.4.weight tensor([[-0.2589, -0.4966],\n",
            "        [-0.2359, -0.2405]])\n",
            "ensemble.2.4.bias tensor([0., 0.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = basenet_with_learnable_epinet_and_ensemble_prior(input_size, basenet_hidden_sizes, n_classes, exposed_layers, z_dim, learnable_epinet_hiddens, hidden_sizes_prior, 0, 1, 2, alpha)\n",
        "for name, param in model.named_parameters():\n",
        "        print(name, param.data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vYEIRbQBfCtt",
        "outputId": "fe09bac5-b3d5-4bd2-9666-e419fba6c26b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "basenet_all_sizes: [3, 5, 5, 2]\n",
            "exposed_layers: [True, False, True, False]\n",
            "basenet_layers: ModuleList(\n",
            "  (0): Linear(in_features=3, out_features=5, bias=True)\n",
            "  (1): Linear(in_features=5, out_features=5, bias=True)\n",
            "  (2): Linear(in_features=5, out_features=2, bias=True)\n",
            ")\n",
            "sum_input_base_epi: 8\n",
            "learnable_epinet_all_sizes: [11, 8, 8, 6]\n",
            "learnable_epinet_layers: ModuleList(\n",
            "  (0): Linear(in_features=11, out_features=8, bias=True)\n",
            "  (1): Linear(in_features=8, out_features=8, bias=True)\n",
            "  (2): Linear(in_features=8, out_features=6, bias=True)\n",
            ")\n",
            "ensemble: ModuleList(\n",
            "  (0-2): 3 x Sequential(\n",
            "    (0): Linear(in_features=8, out_features=2, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=2, out_features=2, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=2, out_features=2, bias=True)\n",
            "  )\n",
            ")\n",
            "basenet_layers.0.weight tensor([[-0.0043,  0.3097, -0.4752],\n",
            "        [-0.4249, -0.2224,  0.1548],\n",
            "        [-0.0114,  0.4578, -0.0512],\n",
            "        [ 0.1528, -0.1745, -0.1135],\n",
            "        [-0.5516, -0.3824, -0.2380]])\n",
            "basenet_layers.0.bias tensor([ 0.0214,  0.2282,  0.3464, -0.3914, -0.2514])\n",
            "basenet_layers.1.weight tensor([[ 0.1624,  0.3714, -0.0920,  0.3347, -0.0721],\n",
            "        [ 0.0473,  0.4049, -0.4149, -0.2815, -0.1132],\n",
            "        [-0.1743,  0.3864, -0.2899, -0.2059, -0.3124],\n",
            "        [-0.4188, -0.2611,  0.3844,  0.1996,  0.2168],\n",
            "        [ 0.0235, -0.2293,  0.0757, -0.4176, -0.3231]])\n",
            "basenet_layers.1.bias tensor([-0.2306,  0.2822,  0.2622, -0.1983, -0.0161])\n",
            "basenet_layers.2.weight tensor([[ 0.2860,  0.4446,  0.1775,  0.0604,  0.2999],\n",
            "        [-0.2633,  0.0833, -0.3467, -0.3100, -0.2310]])\n",
            "basenet_layers.2.bias tensor([0.2024, 0.1799])\n",
            "learnable_epinet_layers.0.weight tensor([[ 0.1554, -0.1331, -0.0585,  0.1415, -0.2839,  0.1808, -0.0620,  0.1534,\n",
            "          0.0419, -0.0369,  0.0836],\n",
            "        [ 0.0149,  0.1101, -0.1175, -0.0220, -0.0271,  0.0437, -0.0012,  0.2636,\n",
            "          0.0938, -0.1123, -0.1821],\n",
            "        [-0.0505, -0.1301, -0.0966,  0.0144,  0.1797,  0.1639, -0.2947,  0.1869,\n",
            "          0.0842,  0.2860,  0.1990],\n",
            "        [-0.2747, -0.2867, -0.1454,  0.2648, -0.0502,  0.1290, -0.1401,  0.2958,\n",
            "         -0.1276,  0.2261,  0.0036],\n",
            "        [-0.1588,  0.1550, -0.1600,  0.0887, -0.0871, -0.0331, -0.2899, -0.1438,\n",
            "          0.1636, -0.0733,  0.3003],\n",
            "        [ 0.2417, -0.0141, -0.2013,  0.1836,  0.0936, -0.1949,  0.1958,  0.1830,\n",
            "          0.2674, -0.1690, -0.0496],\n",
            "        [-0.0058,  0.0440, -0.2288, -0.2140,  0.1640, -0.0707,  0.1473,  0.0172,\n",
            "          0.0990,  0.0663,  0.1096],\n",
            "        [ 0.1495, -0.2792,  0.1518, -0.2120, -0.2275,  0.0183, -0.0514,  0.1771,\n",
            "         -0.1746, -0.2680,  0.2194]])\n",
            "learnable_epinet_layers.0.bias tensor([-0.0447,  0.1696,  0.0969, -0.2261,  0.0606,  0.0724, -0.2019, -0.1431])\n",
            "learnable_epinet_layers.1.weight tensor([[ 0.1206,  0.0633, -0.1504, -0.1070,  0.3238, -0.0654,  0.1993,  0.1531],\n",
            "        [-0.2285, -0.3007,  0.3394,  0.0185,  0.2423,  0.0733,  0.1137,  0.2641],\n",
            "        [ 0.3352, -0.2346,  0.0442,  0.2638,  0.2561,  0.2196, -0.2559, -0.2546],\n",
            "        [-0.2138,  0.0444,  0.3524, -0.2233,  0.1884, -0.1957, -0.3324, -0.0751],\n",
            "        [ 0.2037,  0.3282, -0.2196,  0.0767,  0.3051,  0.2343,  0.2203,  0.2512],\n",
            "        [ 0.2236,  0.0913, -0.2418, -0.2969, -0.1620, -0.0412, -0.2167,  0.1293],\n",
            "        [ 0.1094, -0.0801,  0.1359,  0.1143,  0.2159,  0.2381, -0.1197,  0.3454],\n",
            "        [-0.0409, -0.0121, -0.3337, -0.2276, -0.2065, -0.1512,  0.2514, -0.1155]])\n",
            "learnable_epinet_layers.1.bias tensor([-0.2642,  0.1360,  0.1132,  0.2290, -0.1830,  0.0767, -0.1287, -0.0794])\n",
            "learnable_epinet_layers.2.weight tensor([[-0.2818, -0.1611, -0.1083,  0.1512,  0.0646,  0.0873,  0.3529,  0.3446],\n",
            "        [ 0.2411,  0.0113, -0.2446,  0.2763, -0.0884, -0.0286, -0.3046, -0.0698],\n",
            "        [-0.2280,  0.3249, -0.3057, -0.2756, -0.0120, -0.1912,  0.1265, -0.1361],\n",
            "        [-0.1661,  0.0200,  0.2559, -0.2487,  0.1660,  0.2271,  0.3458, -0.2475],\n",
            "        [ 0.0856, -0.2614,  0.3018, -0.1371,  0.2130,  0.0105, -0.0275, -0.0113],\n",
            "        [ 0.0601,  0.1667,  0.0567,  0.1079, -0.3180,  0.2576,  0.3083,  0.2922]])\n",
            "learnable_epinet_layers.2.bias tensor([ 0.2614, -0.2551, -0.1311,  0.3117, -0.2693,  0.3208])\n",
            "ensemble.0.0.weight tensor([[-0.2978,  0.7449, -0.7587, -0.0526, -0.0614,  0.5494, -0.0736,  0.2040],\n",
            "        [-0.0372, -0.4337, -0.4390, -0.3763, -0.7036, -0.5027,  0.1823,  0.5098]])\n",
            "ensemble.0.0.bias tensor([0., 0.])\n",
            "ensemble.0.2.weight tensor([[-0.3846, -1.1348],\n",
            "        [ 0.5226,  0.4762]])\n",
            "ensemble.0.2.bias tensor([0., 0.])\n",
            "ensemble.0.4.weight tensor([[0.6535, 0.8227],\n",
            "        [0.8795, 0.7099]])\n",
            "ensemble.0.4.bias tensor([0., 0.])\n",
            "ensemble.1.0.weight tensor([[-0.5094,  0.2449, -0.0293,  0.1365,  0.0750, -0.7241, -0.1664, -0.4896],\n",
            "        [ 0.6585, -0.0951, -0.7713,  0.1876,  0.3364, -0.3468, -0.0727,  0.3349]])\n",
            "ensemble.1.0.bias tensor([0., 0.])\n",
            "ensemble.1.2.weight tensor([[ 0.7328,  0.6557],\n",
            "        [-0.9439, -0.7634]])\n",
            "ensemble.1.2.bias tensor([0., 0.])\n",
            "ensemble.1.4.weight tensor([[0.6948, 0.3882],\n",
            "        [0.7783, 0.9201]])\n",
            "ensemble.1.4.bias tensor([0., 0.])\n",
            "ensemble.2.0.weight tensor([[-0.2762,  0.5272, -0.7530, -0.6789, -0.5250,  0.2414, -0.3163, -0.6908],\n",
            "        [ 0.3003,  0.3918,  0.2901, -0.6637,  0.7542, -0.0584, -0.7372, -0.1166]])\n",
            "ensemble.2.0.bias tensor([0., 0.])\n",
            "ensemble.2.2.weight tensor([[ 1.2157, -0.7447],\n",
            "        [ 0.2627, -0.1975]])\n",
            "ensemble.2.2.bias tensor([0., 0.])\n",
            "ensemble.2.4.weight tensor([[ 1.1354,  0.4385],\n",
            "        [-0.8149,  0.8448]])\n",
            "ensemble.2.4.bias tensor([0., 0.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_2 = basenet_with_learnable_epinet_and_ensemble_prior(input_size, basenet_hidden_sizes, n_classes, exposed_layers, z_dim, learnable_epinet_hiddens, hidden_sizes_prior, 0, 4, 2, alpha)\n",
        "for name, param in model_2.named_parameters():\n",
        "        print(name, param.data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6EW9OCMJfHAW",
        "outputId": "82ba17bf-d04e-4c45-e7d3-590f42a575d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "basenet_all_sizes: [3, 5, 5, 2]\n",
            "exposed_layers: [True, False, True, False]\n",
            "basenet_layers: ModuleList(\n",
            "  (0): Linear(in_features=3, out_features=5, bias=True)\n",
            "  (1): Linear(in_features=5, out_features=5, bias=True)\n",
            "  (2): Linear(in_features=5, out_features=2, bias=True)\n",
            ")\n",
            "sum_input_base_epi: 8\n",
            "learnable_epinet_all_sizes: [11, 8, 8, 6]\n",
            "learnable_epinet_layers: ModuleList(\n",
            "  (0): Linear(in_features=11, out_features=8, bias=True)\n",
            "  (1): Linear(in_features=8, out_features=8, bias=True)\n",
            "  (2): Linear(in_features=8, out_features=6, bias=True)\n",
            ")\n",
            "ensemble: ModuleList(\n",
            "  (0-2): 3 x Sequential(\n",
            "    (0): Linear(in_features=8, out_features=2, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=2, out_features=2, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=2, out_features=2, bias=True)\n",
            "  )\n",
            ")\n",
            "basenet_layers.0.weight tensor([[-0.0043,  0.3097, -0.4752],\n",
            "        [-0.4249, -0.2224,  0.1548],\n",
            "        [-0.0114,  0.4578, -0.0512],\n",
            "        [ 0.1528, -0.1745, -0.1135],\n",
            "        [-0.5516, -0.3824, -0.2380]])\n",
            "basenet_layers.0.bias tensor([ 0.0214,  0.2282,  0.3464, -0.3914, -0.2514])\n",
            "basenet_layers.1.weight tensor([[ 0.1624,  0.3714, -0.0920,  0.3347, -0.0721],\n",
            "        [ 0.0473,  0.4049, -0.4149, -0.2815, -0.1132],\n",
            "        [-0.1743,  0.3864, -0.2899, -0.2059, -0.3124],\n",
            "        [-0.4188, -0.2611,  0.3844,  0.1996,  0.2168],\n",
            "        [ 0.0235, -0.2293,  0.0757, -0.4176, -0.3231]])\n",
            "basenet_layers.1.bias tensor([-0.2306,  0.2822,  0.2622, -0.1983, -0.0161])\n",
            "basenet_layers.2.weight tensor([[ 0.2860,  0.4446,  0.1775,  0.0604,  0.2999],\n",
            "        [-0.2633,  0.0833, -0.3467, -0.3100, -0.2310]])\n",
            "basenet_layers.2.bias tensor([0.2024, 0.1799])\n",
            "learnable_epinet_layers.0.weight tensor([[ 0.0360,  0.0356, -0.2464, -0.1749, -0.2972, -0.2780,  0.2972,  0.2491,\n",
            "          0.0715,  0.2861, -0.1092],\n",
            "        [-0.1720,  0.2570, -0.0160,  0.0573,  0.1782,  0.1589, -0.1726, -0.1166,\n",
            "         -0.2783,  0.0133, -0.1081],\n",
            "        [ 0.0648,  0.0140,  0.2570,  0.0260,  0.1511,  0.0951,  0.2675, -0.1253,\n",
            "          0.2518,  0.2163, -0.1203],\n",
            "        [ 0.1848,  0.2787, -0.1705, -0.1176,  0.2063,  0.2431,  0.0795,  0.0926,\n",
            "          0.2233,  0.2642, -0.1907],\n",
            "        [-0.1240,  0.2539,  0.1629, -0.1415, -0.1023,  0.2926, -0.1888,  0.1940,\n",
            "          0.1750, -0.2892, -0.3010],\n",
            "        [ 0.1001,  0.1479,  0.2673,  0.0372,  0.2046, -0.2143,  0.1800, -0.2905,\n",
            "          0.1964,  0.0327,  0.1862],\n",
            "        [ 0.1191, -0.2086,  0.0031,  0.0381,  0.0433, -0.2640, -0.1523, -0.1420,\n",
            "         -0.1639,  0.2567,  0.1706],\n",
            "        [ 0.1242, -0.0904, -0.2446,  0.0642,  0.2786,  0.1342, -0.2434, -0.0267,\n",
            "          0.0122,  0.1914,  0.1274]])\n",
            "learnable_epinet_layers.0.bias tensor([-0.2126, -0.2843,  0.0895,  0.1472,  0.1729,  0.2076,  0.2665, -0.1259])\n",
            "learnable_epinet_layers.1.weight tensor([[-0.3439,  0.1731,  0.3410, -0.2575, -0.1780,  0.3027,  0.2761, -0.0338],\n",
            "        [-0.2018,  0.0648, -0.3463, -0.1396, -0.0458, -0.0843,  0.1457,  0.0075],\n",
            "        [-0.2786, -0.0347,  0.0328,  0.2209,  0.0199, -0.1233,  0.1377,  0.1629],\n",
            "        [ 0.0671, -0.1899,  0.0956,  0.0505,  0.1985, -0.0966, -0.0230,  0.1845],\n",
            "        [-0.0470,  0.1845, -0.0568,  0.3105, -0.0027, -0.0746,  0.1226, -0.0179],\n",
            "        [ 0.2830, -0.0496,  0.2377, -0.0914,  0.0311,  0.1147, -0.3318,  0.0680],\n",
            "        [ 0.1923,  0.1396,  0.0087, -0.0365,  0.1113,  0.1070, -0.1703,  0.1380],\n",
            "        [-0.3028,  0.0139, -0.1216, -0.1479, -0.2867,  0.2779,  0.0326,  0.0243]])\n",
            "learnable_epinet_layers.1.bias tensor([-0.0532, -0.1466, -0.2733,  0.0673, -0.2758, -0.1513,  0.1777,  0.2958])\n",
            "learnable_epinet_layers.2.weight tensor([[-0.1130, -0.3483,  0.3458,  0.1914,  0.2551, -0.0645, -0.0729,  0.0346],\n",
            "        [ 0.0865,  0.0091, -0.1835,  0.3158,  0.1651, -0.0319, -0.3012, -0.1741],\n",
            "        [-0.1233, -0.0590,  0.0978, -0.0591,  0.1223, -0.2296, -0.0774,  0.1598],\n",
            "        [ 0.3472, -0.2987,  0.0368,  0.1867, -0.0381,  0.0824,  0.2207, -0.3513],\n",
            "        [ 0.2094, -0.3161,  0.0657,  0.2140, -0.1607,  0.0032, -0.3394, -0.0218],\n",
            "        [ 0.1992,  0.1762,  0.0945, -0.0290, -0.1449,  0.2874,  0.1044,  0.1258]])\n",
            "learnable_epinet_layers.2.bias tensor([ 0.1722, -0.0999, -0.0270,  0.3336,  0.3165, -0.3509])\n",
            "ensemble.0.0.weight tensor([[-0.2978,  0.7449, -0.7587, -0.0526, -0.0614,  0.5494, -0.0736,  0.2040],\n",
            "        [-0.0372, -0.4337, -0.4390, -0.3763, -0.7036, -0.5027,  0.1823,  0.5098]])\n",
            "ensemble.0.0.bias tensor([0., 0.])\n",
            "ensemble.0.2.weight tensor([[-0.3846, -1.1348],\n",
            "        [ 0.5226,  0.4762]])\n",
            "ensemble.0.2.bias tensor([0., 0.])\n",
            "ensemble.0.4.weight tensor([[0.6535, 0.8227],\n",
            "        [0.8795, 0.7099]])\n",
            "ensemble.0.4.bias tensor([0., 0.])\n",
            "ensemble.1.0.weight tensor([[-0.5094,  0.2449, -0.0293,  0.1365,  0.0750, -0.7241, -0.1664, -0.4896],\n",
            "        [ 0.6585, -0.0951, -0.7713,  0.1876,  0.3364, -0.3468, -0.0727,  0.3349]])\n",
            "ensemble.1.0.bias tensor([0., 0.])\n",
            "ensemble.1.2.weight tensor([[ 0.7328,  0.6557],\n",
            "        [-0.9439, -0.7634]])\n",
            "ensemble.1.2.bias tensor([0., 0.])\n",
            "ensemble.1.4.weight tensor([[0.6948, 0.3882],\n",
            "        [0.7783, 0.9201]])\n",
            "ensemble.1.4.bias tensor([0., 0.])\n",
            "ensemble.2.0.weight tensor([[-0.2762,  0.5272, -0.7530, -0.6789, -0.5250,  0.2414, -0.3163, -0.6908],\n",
            "        [ 0.3003,  0.3918,  0.2901, -0.6637,  0.7542, -0.0584, -0.7372, -0.1166]])\n",
            "ensemble.2.0.bias tensor([0., 0.])\n",
            "ensemble.2.2.weight tensor([[ 1.2157, -0.7447],\n",
            "        [ 0.2627, -0.1975]])\n",
            "ensemble.2.2.bias tensor([0., 0.])\n",
            "ensemble.2.4.weight tensor([[ 1.1354,  0.4385],\n",
            "        [-0.8149,  0.8448]])\n",
            "ensemble.2.4.bias tensor([0., 0.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class MyBranchingModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyBranchingModel, self).__init__()\n",
        "        # Define initial layers\n",
        "        self.initial_layer = nn.Linear(in_features=10, out_features=20)\n",
        "\n",
        "        # Define layers for branch 1\n",
        "        self.branch1_layer1 = nn.Linear(in_features=20, out_features=15)\n",
        "\n",
        "        # Define layers for branch 2\n",
        "        self.branch2_layer1 = nn.Linear(in_features=20, out_features=15)\n",
        "\n",
        "        # Define layers after recombining\n",
        "        self.post_combine_layer = nn.Linear(in_features=15, out_features=10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Initial layers\n",
        "        x = self.initial_layer(x)\n",
        "        y=x\n",
        "        z=x\n",
        "\n",
        "        # Branching\n",
        "        branch1_output = F.relu(self.branch1_layer1(y))\n",
        "        branch2_output = F.sigmoid(self.branch2_layer1(z))\n",
        "\n",
        "        combined = branch1_output + branch2_output\n",
        "\n",
        "        # Further processing\n",
        "        output = self.post_combine_layer(combined)\n",
        "        return output\n",
        "\n",
        "# Example usage\n",
        "model = MyBranchingModel()\n",
        "input_tensor = torch.randn(1, 10)\n",
        "output = model(input_tensor)\n"
      ],
      "metadata": {
        "id": "LBw2kIQHgb8Y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}