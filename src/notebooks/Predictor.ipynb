{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d052b3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Define the model class\n",
    "class LinearRegressor(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(LinearRegressor, self).__init__()\n",
    "        self.linear = nn.Linear(input_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "class LogisticRegression(torch.nn.Module):    \n",
    "    # build the constructor\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super().__init__()\n",
    "        self.linear = torch.nn.Linear(input_size, output_size)\n",
    "    # make predictions\n",
    "    def forward(self, x):\n",
    "        y_pred = torch.sigmoid(self.linear(x))\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e93bef7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.8997976779937744\n",
      "Epoch 10, Loss: 0.8880979418754578\n",
      "Epoch 20, Loss: 0.8769005537033081\n",
      "Epoch 30, Loss: 0.8661895394325256\n",
      "Epoch 40, Loss: 0.8559491038322449\n",
      "Epoch 50, Loss: 0.8461632132530212\n",
      "Epoch 60, Loss: 0.8368158340454102\n",
      "Epoch 70, Loss: 0.827890932559967\n",
      "Epoch 80, Loss: 0.8193729519844055\n",
      "Epoch 90, Loss: 0.8112460970878601\n",
      "Epoch 100, Loss: 0.8034953474998474\n",
      "Epoch 110, Loss: 0.7961052656173706\n",
      "Epoch 120, Loss: 0.7890611886978149\n",
      "Epoch 130, Loss: 0.7823488116264343\n",
      "Epoch 140, Loss: 0.7759538888931274\n",
      "Epoch 150, Loss: 0.7698628306388855\n",
      "Epoch 160, Loss: 0.7640624642372131\n",
      "Epoch 170, Loss: 0.7585398554801941\n",
      "Epoch 180, Loss: 0.7532823085784912\n",
      "Epoch 190, Loss: 0.7482782602310181\n"
     ]
    }
   ],
   "source": [
    "# Example Data (Replace with your actual data)\n",
    "# X_train: tensor of shape [n_samples, n_features]\n",
    "# y_train: tensor of shape [n_samples, 1]\n",
    "#data generated from https://github.com/dakshmittal30/Adaptive_sampling/blob/7cf3996c786ce33db90fcb7aef8584054169557c/src/notebooks/Selection_bias.ipynb\n",
    "\n",
    "\n",
    "url = '/shared/share_mala/yuanzhe/adaptive_sampling/pipeline_datasets/'\n",
    "csv_file = 'input_dim_1_train_init_data_mean_0.0ln_1.0sig_0.1no.2000.csv'\n",
    "#below is biased training data\n",
    "csv_file =  '/biased_new/classifier_input_dim_1_train_init_data_mean_0.0ln_1.0sig_0.1no.2000_random_prop_score_selected_2_0.05__.csv'\n",
    "df = pd.read_csv(url + csv_file)\n",
    "X_train = np.array(df[['Column0']])\n",
    "y_train = np.array(df[['EVENT_LABEL']])  \n",
    "y_train = y_train >0 #convert regression into classifier\n",
    "\n",
    "# Convert data to PyTorch tensors if they aren't already\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "\n",
    "# Hyperparameters\n",
    "epochs = 200  # Number of training iterations\n",
    "learning_rate = 0.01\n",
    "\n",
    "# Model, Loss and Optimizer\n",
    "model = LogisticRegression(input_size=X_train.shape[1], output_size=1)\n",
    "criterion = nn.MSELoss()\n",
    "criterion = torch.nn.BCELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    # Forward pass: Compute predicted y by passing X to the model\n",
    "    y_pred = model(X_train)\n",
    "\n",
    "    # Compute and print loss\n",
    "    loss = criterion(y_pred, y_train)\n",
    "    if epoch % 10 == 0:  # Print every 10th epoch\n",
    "        print(f'Epoch {epoch}, Loss: {loss.item()}')\n",
    "\n",
    "    # Zero gradients, perform a backward pass, and update the weights.\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "#torch.save(model, url + 'predictor.pkl')\n",
    "\n",
    "model_scripted = torch.jit.script(model) # Export to TorchScript\n",
    "model_scripted.save(url + 'predictor.pt') # Save\n",
    "\n",
    "#https://stackoverflow.com/questions/55488795/unpickling-saved-pytorch-model-throws-attributeerror-cant-get-attribute-net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2374173a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert reg to classification, no need to run again\n",
    "# url = '/shared/share_mala/yuanzhe/adaptive_sampling/pipeline_datasets/'\n",
    "# train_csv_name = 'input_dim_1_train_init_data_mean_0.0ln_1.0sig_0.1no.2000.csv'\n",
    "# test_csv_name = 'input_dim_1_test_final_data_mean_0.0ln_1.0sig_0.1no.2000.csv'\n",
    "# pool_csv_name = 'input_dim_1_pool_data_mean_0.0ln_1.0sig_0.1no.2000.csv'\n",
    "# file_list  = [train_csv_name, test_csv_name, pool_csv_name]\n",
    "# #convert y into 0/1\n",
    "\n",
    "# for f in file_list:\n",
    "#     df = pd.read_csv(url + f)\n",
    "#     df['EVENT_LABEL'] = df['EVENT_LABEL'] > 0\n",
    "#     df.to_csv(url+'classifier_'+ f, index = False)\n",
    "# #/user/ym2865/Adaptive Sampling/src"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yuanzhe_new",
   "language": "python",
   "name": "yuanzhe_new"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
