{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rRHKkUbVOLAk"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import Tensor\n",
        "import numpy as np\n",
        "\n",
        "EPSILON = np.finfo(np.float32).tiny"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SubsetOperator(torch.nn.Module):\n",
        "    def __init__(self, k, tau=1.0, hard=False):            # k is the number of samples we want, tau is the temperature parameter and hard:denotes if we want hard or soft samples\n",
        "        super(SubsetOperator, self).__init__()\n",
        "        self.k = k\n",
        "        self.hard = hard\n",
        "        self.tau = tau\n",
        "\n",
        "    def forward(self, scores):                                # scores take in log(weights) of each sample -- scores need not be positive (exp(scores)) is actual weight      # scores: Typical shape: [batch_size,n] or [batch_size,n,1]\n",
        "        m = torch.distributions.gumbel.Gumbel(torch.zeros_like(scores), torch.ones_like(scores))\n",
        "        g = m.sample()\n",
        "        scores = scores + g\n",
        "\n",
        "        # continuous top k  (we can later modify this to also output S_WRS, we will just need each onehot_approx to be stored seperately - then it will give k soft vectors)\n",
        "        khot = torch.zeros_like(scores)\n",
        "        onehot_approx = torch.zeros_like(scores)\n",
        "        for i in range(self.k):\n",
        "            khot_mask = torch.max(1.0 - onehot_approx, torch.tensor([EPSILON]))            # we can autodiff through this, there is no issue .\n",
        "            # khot_mask = torch.max(1.0 - onehot_approx, torch.tensor([EPSILON]).cuda())      #CHECK MIGHT NEED TO PUT DEVICE HERE,\n",
        "            scores = scores + torch.log(khot_mask)\n",
        "            onehot_approx = torch.nn.functional.softmax(scores / self.tau, dim=1)\n",
        "            khot = khot + onehot_approx\n",
        "\n",
        "        if self.hard:\n",
        "            # will do straight through estimation if training\n",
        "            khot_hard = torch.zeros_like(khot)\n",
        "            val, ind = torch.topk(khot, self.k, dim=1)             #This line uses the torch.topk function to find the top self.k elements in each row (since dim=1) of the khot tensor.  val will store the values of these top elements, and ind will store their indices.\n",
        "            khot_hard = khot_hard.scatter_(1, ind, 1)              #Here, the scatter_ function is used to take the zero tensor khot_hard and set the indices specified in ind to 1. This effectively creates a \"hard\" version of khot where only the top self.k elements in each row are set to 1, and the rest are 0. The underscore at the end of scatter_ indicates that this operation is done in-place, modifying khot_hard directly.\n",
        "            res = khot_hard - khot.detach() + khot                 #This line is a bit trickier. It's part of a technique called the Straight-Through Estimator (STE). khot.detach() creates a tensor that does not require gradients, effectively a constant in terms of backpropagation.  By subtracting khot.detach() and then adding khot, you replace the gradients of khot_hard with those of khot during backpropagation. This is because khot_hard - khot.detach() stops the gradient from flowing through the hard assignment. The result is that during the forward pass, res acts like the hard assignment (since khot.detach() has no effect), but during the backward pass (gradient computation), it behaves like khot (since khot_hard - khot.detach() has no gradient).\n",
        "        else:\n",
        "            res = khot\n",
        "\n",
        "        return res"
      ],
      "metadata": {
        "id": "rEL6jA8i8uDX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SubsetOperator_Test(torch.nn.Module):\n",
        "    def __init__(self, k, tau=1.0, hard=False):            # k is the number of samples we want, tau is the temperature parameter and hard:denotes if we want hard or soft samples\n",
        "        super(SubsetOperator_Test, self).__init__()\n",
        "        self.k = k\n",
        "        self.hard = hard\n",
        "        self.tau = tau\n",
        "\n",
        "    def forward(self, scores):                                # scores take in weights of each sample      # scores: Typical shape: [batch_size,n] or [batch_size,n,1]\n",
        "        m = torch.distributions.gumbel.Gumbel(torch.zeros_like(scores), torch.ones_like(scores))\n",
        "        g = m.sample()\n",
        "        scores = scores + g\n",
        "\n",
        "        # continuous top k  (we can later modify this to also output S_WRS, we will just need each onehot_approx to be stored seperately - then it will give k soft vectors)\n",
        "        khot = torch.zeros_like(scores)\n",
        "        onehot_approx = torch.zeros_like(scores)\n",
        "        khot_all = []\n",
        "        for i in range(self.k):\n",
        "            khot_mask = torch.max(1.0 - onehot_approx, torch.tensor([EPSILON]))            # we can autodiff through this, there is no issue .\n",
        "            # khot_mask = torch.max(1.0 - onehot_approx, torch.tensor([EPSILON]).cuda())      #CHECK MIGHT NEED TO PUT DEVICE HERE,\n",
        "            scores = scores + torch.log(khot_mask)\n",
        "            onehot_approx = torch.nn.functional.softmax(scores / self.tau, dim=1)\n",
        "            khot = khot + onehot_approx\n",
        "            khot_all.append(onehot_approx)\n",
        "\n",
        "        if self.hard:\n",
        "            # will do straight through estimation if training\n",
        "            khot_hard = torch.zeros_like(khot)\n",
        "            val, ind = torch.topk(khot, self.k, dim=1)             #This line uses the torch.topk function to find the top self.k elements in each row (since dim=1) of the khot tensor.  val will store the values of these top elements, and ind will store their indices.\n",
        "            khot_hard = khot_hard.scatter_(1, ind, 1)              #Here, the scatter_ function is used to take the zero tensor khot_hard and set the indices specified in ind to 1. This effectively creates a \"hard\" version of khot where only the top self.k elements in each row are set to 1, and the rest are 0. The underscore at the end of scatter_ indicates that this operation is done in-place, modifying khot_hard directly.\n",
        "            res = khot_hard - khot.detach() + khot                 #This line is a bit trickier. It's part of a technique called the Straight-Through Estimator (STE). khot.detach() creates a tensor that does not require gradients, effectively a constant in terms of backpropagation.  By subtracting khot.detach() and then adding khot, you replace the gradients of khot_hard with those of khot during backpropagation. This is because khot_hard - khot.detach() stops the gradient from flowing through the hard assignment. The result is that during the forward pass, res acts like the hard assignment (since khot.detach() has no effect), but during the backward pass (gradient computation), it behaves like khot (since khot_hard - khot.detach() has no gradient).\n",
        "        else:\n",
        "            res = khot\n",
        "\n",
        "        return res, khot_all"
      ],
      "metadata": {
        "id": "IrAOPfnbOTs9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# REMIND - scores here are log(weights) that is proability is exp(s_i)/sum_{j=1}^n exp(s_j)\n",
        "\n",
        "# Test 1a  -- k=1  -- aeverage of soft samples -- they will not match exactly because of no. of samples of gumble induces approx and also the temp parameter\n",
        "\n",
        "\n",
        "\n",
        "scores = torch.tensor([[1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0]])\n",
        "temp = 0.00001\n",
        "n=100000\n",
        "k=1\n",
        "subset_operator = SubsetOperator_Test(k, temp, False)\n",
        "res, khot_all = subset_operator(scores)\n",
        "khot_all_1 = khot_all[0]\n",
        "for i in range(n):\n",
        "  res, khot_all = subset_operator(scores)\n",
        "  khot_all_1 += khot_all[0]\n",
        "\n",
        "khot_all_final = khot_all_1/(n+1)\n",
        "\n",
        "print(\"khot_all_final:\", khot_all_final)\n",
        "\n",
        "expected = torch.exp(scores)/(torch.exp(scores)).sum()\n",
        "print(\"expected:\", expected)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6J4Nl7gHzlG",
        "outputId": "f71d868e-088d-4495-bca5-cc0a595c65b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "khot_all_final: tensor([[5.1999e-04, 1.3800e-03, 4.1900e-03, 1.1920e-02, 3.2120e-02, 8.4939e-02,\n",
            "         2.3277e-01, 6.3216e-01]])\n",
            "expected: tensor([[5.7661e-04, 1.5674e-03, 4.2606e-03, 1.1582e-02, 3.1482e-02, 8.5577e-02,\n",
            "         2.3262e-01, 6.3233e-01]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test 1b  -- k=1, true --- aeverage of hard samples - they will not match exactly because of no. of samples of gumble induces approx (although there is no effect of temp)\n",
        "\n",
        "\n",
        "\n",
        "scores = torch.tensor([[1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0]])\n",
        "temp = 0.00001\n",
        "n=100000\n",
        "k=1\n",
        "subset_operator = SubsetOperator_Test(k, temp, True)\n",
        "res, khot_all = subset_operator(scores)\n",
        "khot_all_1 = res\n",
        "for i in range(n):\n",
        "  res, khot_all = subset_operator(scores)\n",
        "  khot_all_1 += res\n",
        "\n",
        "khot_all_final = khot_all_1/(n+1)\n",
        "\n",
        "print(\"khot_all_final:\", khot_all_final)\n",
        "\n",
        "expected = torch.exp(scores)/(torch.exp(scores)).sum()\n",
        "print(\"expected:\", expected)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hn3_Tx7yIMcg",
        "outputId": "4df29353-d863-4766-dc22-b71569f63220"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "khot_all_final: tensor([[5.5999e-04, 1.6700e-03, 4.4200e-03, 1.1540e-02, 3.2030e-02, 8.5059e-02,\n",
            "         2.3305e-01, 6.3167e-01]])\n",
            "expected: tensor([[5.7661e-04, 1.5674e-03, 4.2606e-03, 1.1582e-02, 3.1482e-02, 8.5577e-02,\n",
            "         2.3262e-01, 6.3233e-01]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test 1c  -- comparing the first vector a^(1) -- it should have mean weight exp(s_i)/sum_{j=1}^n exp(s_j)\n",
        "\n",
        "\n",
        "\n",
        "scores = torch.tensor([[1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0]])\n",
        "temp = 0.00001\n",
        "n=100000\n",
        "k=4\n",
        "subset_operator = SubsetOperator_Test(k, temp, False)\n",
        "res, khot_all = subset_operator(scores)\n",
        "khot_all_1 = khot_all[0]\n",
        "for i in range(n):\n",
        "  res, khot_all = subset_operator(scores)\n",
        "  khot_all_1 += khot_all[0]\n",
        "\n",
        "khot_all_final = khot_all_1/(n+1)\n",
        "\n",
        "print(\"khot_all_final:\", khot_all_final)\n",
        "\n",
        "expected = torch.exp(scores)/(torch.exp(scores)).sum()\n",
        "print(\"expected:\", expected)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S7N-49V--C4g",
        "outputId": "7f2047c4-aa9d-4222-d46b-c09f3ab6fc31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[6.2000e+01, 1.4200e+02, 4.0000e+02, 1.1210e+03, 3.2270e+03, 8.6231e+03,\n",
            "         2.3209e+04, 6.3217e+04]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test 2a : can scores be negative? Yes!  k=1, false\n",
        "\n",
        "scores = torch.tensor([[-1.0,-2.0,3.0,-4.0,-5.0,6.0,-7.0,-8.0]])\n",
        "temp = 0.1\n",
        "n=10000\n",
        "k=1\n",
        "subset_operator = SubsetOperator_Test(k, temp, False)\n",
        "res, khot_all = subset_operator(scores)\n",
        "khot_all_1 = khot_all[0]\n",
        "for i in range(n):\n",
        "  res, khot_all = subset_operator(scores)\n",
        "  khot_all_1 += khot_all[0]\n",
        "\n",
        "khot_all_final = khot_all_1/(n+1)\n",
        "\n",
        "print(\"khot_all_final:\", khot_all_final)\n",
        "\n",
        "expected = torch.exp(scores)/(torch.exp(scores)).sum()\n",
        "print(\"expected:\", expected)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_PEisAZOcdi",
        "outputId": "725fcb36-72f8-4867-f9a5-81eac07c887d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "khot_all_final: tensor([[6.0246e-04, 2.0681e-04, 4.7026e-02, 4.6006e-08, 3.8561e-06, 9.5216e-01,\n",
            "         1.0082e-25, 4.5451e-22]])\n",
            "expected: tensor([[8.6755e-04, 3.1915e-04, 4.7367e-02, 4.3193e-05, 1.5890e-05, 9.5138e-01,\n",
            "         2.1504e-06, 7.9110e-07]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test 2b : can scores be negative? Yes! k=1, true\n",
        "\n",
        "scores = torch.tensor([[-1.0,-2.0,3.0,-4.0,-5.0,6.0,-7.0,-8.0]])\n",
        "temp = 0.1\n",
        "n=10000\n",
        "k=1\n",
        "subset_operator = SubsetOperator_Test(k, temp, True)\n",
        "res, khot_all = subset_operator(scores)\n",
        "khot_all_1 = res\n",
        "for i in range(n):\n",
        "  res, khot_all = subset_operator(scores)\n",
        "  khot_all_1 += res\n",
        "\n",
        "khot_all_final = khot_all_1/(n+1)\n",
        "\n",
        "print(\"khot_all_final:\", khot_all_final)\n",
        "\n",
        "expected = torch.exp(scores)/(torch.exp(scores)).sum()\n",
        "print(\"expected:\", expected)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wiYe3wJmOlPO",
        "outputId": "0fe5347a-b824-44f3-8293-a536cd28eea7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "khot_all_final: tensor([[6.9993e-04, 9.9990e-05, 4.6495e-02, 0.0000e+00, 0.0000e+00, 9.5270e-01,\n",
            "         0.0000e+00, 0.0000e+00]])\n",
            "expected: tensor([[8.6755e-04, 3.1915e-04, 4.7367e-02, 4.3193e-05, 1.5890e-05, 9.5138e-01,\n",
            "         2.1504e-06, 7.9110e-07]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test 2c : can scores be negative? Yes!\n",
        "\n",
        "scores = torch.tensor([[-1.0,-2.0,3.0,-4.0,-5.0,6.0,-7.0,-8.0]])\n",
        "temp = 0.1\n",
        "n=10000\n",
        "k=4\n",
        "subset_operator = SubsetOperator_Test(k, temp, False)\n",
        "res, khot_all = subset_operator(scores)\n",
        "khot_all_1 = khot_all[0]\n",
        "for i in range(n):\n",
        "  res, khot_all = subset_operator(scores)\n",
        "  khot_all_1 += khot_all[0]\n",
        "\n",
        "khot_all_final = khot_all_1/(n+1)\n",
        "\n",
        "print(\"khot_all_final:\", khot_all_final)\n",
        "\n",
        "expected = torch.exp(scores)/(torch.exp(scores)).sum()\n",
        "print(\"expected:\", expected)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GH8_nMwaCDOi",
        "outputId": "82e36c6c-3da9-4cb7-84fb-f4f71b19a270"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "khot_all_final: tensor([[1.0291e-03, 4.1546e-04, 4.4834e-02, 9.9992e-05, 5.8321e-07, 9.5362e-01,\n",
            "         8.8493e-25, 3.9025e-26]])\n",
            "expected: tensor([[8.6755e-04, 3.1915e-04, 4.7367e-02, 4.3193e-05, 1.5890e-05, 9.5138e-01,\n",
            "         2.1504e-06, 7.9110e-07]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SubsetOperator_raw(torch.nn.Module):\n",
        "    def __init__(self, k):            # k is the number of samples we want, tau is the temperature parameter and hard:denotes if we want hard or soft samples\n",
        "        super(SubsetOperator_raw, self).__init__()\n",
        "        self.k = k\n",
        "\n",
        "    def forward(self, scores):                                # scores take in weights of each sample      # scores: Typical shape: [batch_size,n] or [batch_size,n,1]\n",
        "        m = torch.distributions.gumbel.Gumbel(torch.zeros_like(scores), torch.ones_like(scores))\n",
        "        g = m.sample()\n",
        "        scores = scores + g\n",
        "        khot_hard = torch.zeros_like(scores)\n",
        "\n",
        "        val, ind = torch.topk(scores, self.k, dim=1)             #This line uses the torch.topk function to find the top self.k elements in each row (since dim=1) of the khot tensor.  val will store the values of these top elements, and ind will store their indices.\n",
        "        khot_hard = khot_hard.scatter_(1, ind, 1)\n",
        "\n",
        "        return khot_hard"
      ],
      "metadata": {
        "id": "x-Fwg2mBFZ1n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test 3\n",
        "\n",
        "scores = torch.tensor([[-1.0,-2.0,3.0,-4.0,-5.0,6.0,-7.0,-8.0]])\n",
        "temp = 0.2\n",
        "n=100000\n",
        "k=4\n",
        "subset_operator = SubsetOperator_Test(k, temp, False)\n",
        "subset_operator_raw = SubsetOperator_raw(k)\n",
        "res, khot_all = subset_operator(scores)\n",
        "res_final = res\n",
        "for i in range(n):\n",
        "  res, khot_all = subset_operator(scores)\n",
        "  res_final += res\n",
        "print(\"res_final:\",res_final/(n+1))\n",
        "\n",
        "exp = subset_operator_raw(scores)\n",
        "for i in range(n):\n",
        "  exp += subset_operator_raw(scores)\n",
        "\n",
        "\n",
        "print(\"exp:\",exp/(n+1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qU7Kj9lIQUX1",
        "outputId": "b761d09e-6540-4d60-bfd8-f127853130a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "res_final: tensor([[0.9001, 0.7137, 1.0810, 0.1107, 0.0426, 1.1441, 0.0057, 0.0021]])\n",
            "exp: tensor([[0.9688, 0.8477, 1.0000, 0.1261, 0.0479, 1.0000, 0.0071, 0.0023]])\n"
          ]
        }
      ]
    }
  ]
}